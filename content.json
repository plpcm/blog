{"meta":{"title":"曹淼的“git博客”","subtitle":"道法自然","description":"混迹互联网圈数载，潜心修行编程之道的码农","author":"曹淼","url":"https://plpcm.github.io/blog"},"pages":[{"title":"","date":"2016-12-02T03:59:48.000Z","updated":"2016-12-02T03:59:48.000Z","comments":true,"path":"404.html","permalink":"https://plpcm.github.io/blog/404.html","excerpt":"","text":"公益404页面 // 曹淼的\"git博客\""},{"title":"关于本人","date":"2016-02-01T10:29:36.000Z","updated":"2017-01-10T03:21:09.000Z","comments":false,"path":"about/index.html","permalink":"https://plpcm.github.io/blog/about/index.html","excerpt":"","text":"资深 openresty 爱好者 资深运维工程师 对开源软件感兴趣 擅长openresty，waf，网络故障排查 来自河北 现居北京 邮箱: caomiao009@gmail.com QQ: 845670248 此博客基于hexo开发，通过markdown语法写作。"},{"title":"分类","date":"2016-01-29T13:13:21.000Z","updated":"2016-12-02T05:32:52.000Z","comments":false,"path":"categories/index.html","permalink":"https://plpcm.github.io/blog/categories/index.html","excerpt":"","text":""},{"title":"Tagcloud","date":"2016-02-01T10:29:36.000Z","updated":"2016-12-02T05:33:01.000Z","comments":false,"path":"tags/index.html","permalink":"https://plpcm.github.io/blog/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"使用Fabric部署代码","slug":"fabric-basic","date":"2018-11-02T02:30:16.000Z","updated":"2018-11-06T07:30:04.000Z","comments":true,"path":"2018/11/02/fabric-basic/","link":"","permalink":"https://plpcm.github.io/blog/blog/2018/11/02/fabric-basic/","excerpt":"","text":"使用Fabric部署代码Fabric是一个用Python开发的部署工具，最大特点是不用登录远程服务器，在本地运行远程命令，几行Python脚本就可以轻松部署。 1. Hello1.1 安装 pip install fabric 1.2 编写脚本vim fabfile.py12def hello(): print(\"Hello world!\") 1.3 运行脚本 fab hello 2. 常见命令1234567fab --helpfab -l # 显示可用的task（命令）fab -H # 指定host，支持多个host，以逗号分开fab -R # 指定role，支持多个rolefab -P # 并发数，默认串行fab -w # warn_only，默认遇到异常直接abort退出fab -f # 指定入口文件，默认fabfile.py 3. 常用函数123456lcd('/tmp') # 切换本地目录cd('/tmp') # 切换远程目录put('tmp.tar.gz') # 上传文件local('pwd') # 执行本地命令run('uname -a') # 执行远程命令sudo('/etc/init.d/nginx start') # 执行远程sudo 4. 错误处理12345def test(): with settings(warn_only=True): result = local('./manage.py test my_app', capture=True) if result.failed and not confirm(\"Tests failed. Continue anyway?\"): abort(\"Aborting at user request.\") 5. 角色定义123456789host1 = 'user@192.168.1.1:22'host2 = 'user@192.168.1.2:22'host3 = 'user@192.168.1.3:22'env.hosts = [ host1, host2, host3 ]env.passwords = &#123; host1: \"pwd_of_host1\", host2: \"pwd_of_host2\", host3: \"pwd_of_host3\",&#125; 或者 123456789env.roledefs = &#123; 'nginx_user': [host1, host2], 'mysql_user': [host3]&#125;env.passwords = &#123; host1: \"pwd_of_host1\", host2: \"pwd_of_host2\", host3: \"pwd_of_host3\",&#125; 6. 简单实例1234567891011121314151617181920212223242526272829303132333435363738394041from __future__ import with_statementfrom fabric.api import *from fabric.contrib.console import confirmhost1 = 'user@192.168.1.1:22'host2 = 'user@192.168.1.2:22'host3 = 'user@192.168.1.3:22'env.passwords = &#123; host1: \"pwd_of_host1\", host2: \"pwd_of_host2\", host3: \"pwd_of_host3\",&#125;env.roledefs = &#123; 'nginx_user': [host1, host2], 'mysql_user': [host3]&#125;def test(): with settings(warn_only=True): result = local('./manage.py test my_app', capture=True) print(\"some processings\") if result.failed and not confirm(\"Tests failed. Continue anyway?\"): abort(\"Aborting at user request.\") print red(\"some error\")def deploy(): test() local(\"git add -p &amp;&amp; git commit\") local(\"git push\")@task@parallel@roles('nginx')def nginx_start(): sudo('/etc/init.d/nginx start')@task@serial@roles('nginx')def nginx_stop(): sudo('/etc/init.d/nginx stop')@task@parallel(pool_size=5)@roles('mysql')def mysql_start() sudo('/etc/init.d/mysql start') 7. 扩展7.1 颜色可以打印颜色，在查看操作结果信息的时候更为醒目和方便 12345from fabric.colors import *def show(): print green('success') print red('fail') print yellow('yellow')","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"fabric","slug":"fabric","permalink":"https://plpcm.github.io/blog/tags/fabric/"}]},{"title":"salt 命令使用入门","slug":"salt-command","date":"2017-01-02T02:30:16.000Z","updated":"2017-01-05T03:55:54.000Z","comments":true,"path":"2017/01/02/salt-command/","link":"","permalink":"https://plpcm.github.io/blog/blog/2017/01/02/salt-command/","excerpt":"","text":"查找目标minion的三种方式1234salt 'shell正则' commandsalt -E 'prel 正则' commangsalt -N $group commandsalt -L 'server1,server2' command 1、根据bash glob来查找：salt ‘*foo.com’ sys.doc 2、根据正则表达式来查找：salt -E ‘.*’ cmd.run ‘ls -l | grep foo’ 3、根据hostname来查找：salt -L foo.bar.baz,quo.qux cmd.run ‘ps aux | grepfoo’ 4、根据grains（机器各种信息）来查找：salt -G ‘os:Redhat’ test.ping 5、综合以上几种模式混合查找：salt -C ‘G@os:Debian and webser or E@db.‘ test.ping 常见grains信息如下：123salt '*' grains.ls 查看grains分类salt '*' grains.items 查看grains所有信息salt '*' grains.item osrelease 查看grains某个信息","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"saltstack","slug":"saltstack","permalink":"https://plpcm.github.io/blog/tags/saltstack/"}]},{"title":"supervisor安装与使用","slug":"supervisor-manual","date":"2016-12-12T02:30:16.000Z","updated":"2016-12-13T08:57:05.000Z","comments":true,"path":"2016/12/12/supervisor-manual/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/12/12/supervisor-manual/","excerpt":"","text":"Supervisor是用 Python 开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。 一、安装首先必须先安装好 python 环境，Linux 已经自带 python，建议安装 python2.7.5. 先在终端输入 python 查看python 版本，能正常显示则表明没问题，输入 exit() 退出 python 环境。Centos下用 easy_instal l安装 1easy_install supervisor Debian / Ubuntu可以直接通过 apt 安装： 1apt-get install supervisor 安装成功后显示 finished ,我们再次进行 python 环境，输入： 1import supervisor 如果没提示错误则表示安装成功。安装之后，会有两个可执行文件： 12/usr/bin/supervisord -- supervisor服务守护进程/usr/bin/supervisorctl -- supervisor控制台进程 Supervisor 有两个可执行程序 – supervisord 和 supervisorctl: Supervisord 是后台管理服务器, 用来依据配置文件的策略管理后台守护进程, 它会随系统自动启动Supervisorctl 用于管理员向后台管理程序发送 启动/重启/停止 等指令; 它们之间的关系就相当于 Apache 的 httpd 和 apachectl. 生成默认配置文件 1echo_supervisord_conf &gt; /etc/supervisord.conf ubuntu下需要使用如下命令创建配置文件 1sudo su - root -c \"echo_supervisord_conf &gt; /etc/supervisord.conf\" 在/etc/supervisor 目录中存放着 supervisor 的配置文件：其中 conf.d 是一个子目录，其中存放着supervisor监管的进程的配置信息，一个进程有一个对应的配置文件；supervisord.conf 是supervisor 的主配置文件，定义服务名称以及接口等等。 二、配置主配置文件 的路径位于 /etc/supervisor/supervisord.conf, 主配置文件中的末尾两行文本: 12[include]files = /etc/supervisor/conf.d/*.conf 指明了 Supervisor 会去 /etc/supervisor/conf.d/ 目录下查找以 .conf结尾的子配置文件, 也就是说, 我们只需在 /etc/supervisor/conf.d/ 目录下为每个后台守护应用新建一个配置文件即可。现在要用 supervisor监控一个脚本进程，在/etc/supervisor/conf.d 中新建一个关于这个脚本进程的配置文件。 12cd /etc/supervisor/conf.dvim script.conf 其中输入： 12345678910[program:script.py] #程序的名字，在supervisor中可以用这个名字来管理该程序command=/home/hadoop/script1.1.py #启动程序的命令autorstart=true #是否随supervisor启动而启动directory=/home/hadoop #执行命令前先cd到此目录autorestart=true #程序停止之后是否需要重新将其启动startsecs=10 #重新启动等待时间startretries=36 #重启程序尝试次数redirect_stderr=true #是否将程序错误信息重定向到文件stdout_logfile=/home/supervisor_log/log.txt #将程序输出重定向到该文件stderr_logfile=/home/supervisor_log/err.txt #将程序错误重定向到该文件 保存文件，便完成配置。 1234567891011121314program其它配置项:process_name=%(program_name)s 进程名称priority=999 进程启动优先级(数值越小优先级越高,即先启动、后关闭)exitcodes=0,2 进程结束代码(默认值0,2)stopsignal=QUIT 停止进程时发送的信号stopwaitsecs=10 结束等待时间，否则使用SIGKILL结束user=root 运行程序的用户stdout_logfile_maxbytes=50MB 日志文件最大值，否则循环写入，默认50MBstdout_logfile_backups=10 标准输出日志备份数目environment=A=\"1\",B=\"2\" 进程附加环境变量group配置项:programs=A,B,C 进程名称,与program进程名称对应，多个逗号分隔priority=1 优先级 三、生效每次修改主配置文件或增改子配置文件都需要执行 supervisorctl update 使新配置生效。或者用supervisorctl reload 重新重新启动 supervisor 程序。每次 修改主配置文件 或 增改子配置文件 都需要执行 supervisorctl update 使新配置生效: 1supervisorctl update 控制命令123456789supervisorctl statussupervisorctl start allsupervisorctl stop allsupervisorctl restart all #定向控制指定进程supervisorctl stop iot-kbsupervisorctl start iot-kbsupervisorctl restart iot-kb #加载和更新supervisorctl reloadsupervisorctl update 四、管理修改主配置文件，开启基于http的UI控制台:添加如下内容： 1234[inet_http_server]port = 172.16.22.39:9001username = adminpassword = 123456 这样，在浏览器中输入配置中写的地址和端口号，输入配置好的用户名和密码，便可以看到基于网页的控制台界面。从中，可以察看 Supervisor 监控的信息，可以察看进程的日志等。 附配置文件一例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[unix_http_server]file = /var/run/supervisor.sockchmod = 0777chown= root:felinx [inet_http_server]# Web管理界面设定port=9001username = adminpassword = yourpassword [supervisorctl]; 必须和'unix_http_server'里面的设定匹配serverurl = unix:///var/run/supervisord.sock [supervisord]logfile=/var/log/supervisord/supervisord.log ; (main log file;default $CWD/supervisord.log)logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB)logfile_backups=10 ; (num of main logfile rotation backups;default 10)loglevel=info ; (log level;default info; others: debug,warn,trace)pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)nodaemon=true ; (start in foreground if true;default false)minfds=1024 ; (min. avail startup file descriptors;default 1024)minprocs=200 ; (min. avail process descriptors;default 200)user=root ; (default is current user, required if root)childlogdir=/var/log/supervisord/ ; ('AUTO' child log dir, default $TEMP) [rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface ; 管理的单个进程的配置，可以添加多个program[program:chatdemon]command=python /home/felinx/demos/chat/chatdemo.pyautostart = truestartsecs = 5user = felinxredirect_stderr = true；这对这个program的log的配置，上面的logfile_maxbytes是supervisord本身的log配置stdout_logfile_maxbytes = 20MBstdoiut_logfile_backups = 20stdout_logfile = /var/log/supervisord/chatdemo.log ; 配置一组进程，对于类似的program可以通过这种方式添加，避免手工一个个添加[program:groupworker]command=python /home/felinx/demos/groupworker/worker.pynumprocs=24process_name=%(program_name)s_%(process_num)02dautostart = truestartsecs = 5user = felinxredirect_stderr = truestdout_logfile = /var/log/supervisord/groupworker.log","categories":[{"name":"supervisor","slug":"supervisor","permalink":"https://plpcm.github.io/blog/categories/supervisor/"}],"tags":[{"name":"supervisor","slug":"supervisor","permalink":"https://plpcm.github.io/blog/tags/supervisor/"}]},{"title":"收藏链接","slug":"hotlink","date":"2016-12-05T09:06:40.000Z","updated":"2016-12-05T09:06:40.000Z","comments":true,"path":"2016/12/05/hotlink/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/12/05/hotlink/","excerpt":"Markdown 语法说明 (简体中文版)http://wowubuntu.com/markdown/ pythonzc.buildout 类似virtualenv 使用buildout管理项目http://www.infoq.com/cn/presentations/manage-projects-using-buildout?utm_source=infoq&amp;utm_medium=videos_homepage&amp;utm_campaign=videos_row2&amp;from=the5fire","text":"Markdown 语法说明 (简体中文版)http://wowubuntu.com/markdown/ pythonzc.buildout 类似virtualenv 使用buildout管理项目http://www.infoq.com/cn/presentations/manage-projects-using-buildout?utm_source=infoq&amp;utm_medium=videos_homepage&amp;utm_campaign=videos_row2&amp;from=the5fire macpowerline fontshttps://github.com/powerline/fonts 一种zsh主题 powerline-shellhttps://github.com/banga/powerline-shell hexohexo主题next使用帮助http://theme-next.iissnan.com/getting-started.html 很不错的hexo介绍文章http://ibruce.info/2013/11/22/hexo-your-blog/ hexo原作者-Hexo 颯爽登場！https://zespia.tw/blog/2012/10/11/hexo-debut/","categories":[{"name":"Collection","slug":"Collection","permalink":"https://plpcm.github.io/blog/categories/Collection/"}],"tags":[]},{"title":"PYTHON FABRIC实现远程操作和部署","slug":"fabric","date":"2016-12-02T02:30:16.000Z","updated":"2017-01-05T03:56:07.000Z","comments":true,"path":"2016/12/02/fabric/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/12/02/fabric/","excerpt":"","text":"Python fabric实现远程操作和部署 fabric 作用 环境配置 hello world 执行本机操作 混搭整合远端操作 多服务器混搭 扩展 fabric官方文档 入口 作用很强大的工具 可以将自动化部署或者多机操作的命令固化到一个脚本里 和某些运维工具很像，用它主要是因为，python….. 简单好用易上手 当然，shell各种命令组合起来也可以，上古神器和现代兵器的区别 环境配置在本机和目标机器安装对应包（注意，都要有） 1sudo easy_install fabric 目前是1.8版本 安装完后，可以查看是否安装成功 12[ken@~$] which fab/usr/local/bin/fab 装完之后，可以浏览下官方文档 然后，可以动手了 hello world先进行本机简单操作，有一个初步认识，例子来源与官网 新建一个py脚本: fabfile.py 12def hello(): print(&quot;Hello world!&quot;) 命令行执行： 1234[ken@~/tmp/fab$] fab helloHello world!Done. 注意，这里可以不用fabfile作为文件名，但是在执行时需指定文件 12345678910111213[ken@~/tmp/fab$] mv fabfile.py test.pyfabfile.py -&gt; test.py[ken@~/tmp/fab$] fab helloFatal error: Couldn&apos;t find any fabfiles!Remember that -f can be used to specify fabfile path, and use -h for help.Aborting.[ken@~/tmp/fab$] fab -f test.py helloHello world!Done. 带参数： 修改fabfile.py脚本： 12def hello(name, value): print(&quot;%s = %s!&quot; % (name, value)) 执行 12345678[ken@~/tmp/fab$] fab hello:name=age,value=20age = 20!Done.[ken@~/tmp/fab$] fab hello:age,20age = 20!Done. 执行本机操作简单的本地操作: 12345from fabric.api import local, lcddef lsfab(): with lcd(&apos;~/tmp/fab&apos;): local(&apos;ls&apos;) 结果： 123456789[ken@~/tmp/fab$] pwd;ls/Users/ken/tmp/fabfabfile.py fabfile.pyc test.py test.pyc[ken@~/tmp/fab$] fab -f test.py lsfab[localhost] local: cd ~/tmp/fab[localhost] local: lsfabfile.py fabfile.pyc test.py test.pycDone. 实战开始： 假设，你每天要提交一份配置文件settings.py到版本库（这里没有考虑冲突的情况） 如果是手工操作： 12345cd /home/project/test/conf/git add settings.pygit commit -m &apos;daily update settings.py&apos;git pull origingit push origin 也就是说，这几个命令你每天都要手动敲一次，所谓daily job，就是每天都要重复的，机械化的工作，让我们看看用fabric怎么实现一键搞定：(其实用shell脚本可以直接搞定，但是fab的优势不是在这里，这里主要位后面本地+远端操作做准备，毕竟两个地方的操作写一种脚本便于维护) 123456from fabric.api import local, lcddef setting_ci(): with lcd(&apos;/home/project/test/conf/&apos;): local(&quot;git add settings.py&quot;) #后面你懂的，懒得敲了….. 混搭整合远端操作这时候，假设，你要到机器A的/home/ken/project对应项目目录把配置文件更新下来 123456789101112131415161718192021#!/usr/bin/env python# encoding: utf-8from fabric.api import local,cd,run, envenv.hosts=[&apos;user@ip:port&apos;,] #ssh要用到的参数env.password = &apos;pwd&apos;def setting_ci(): local(&apos;echo &quot;add and commit settings in local&quot;&apos;) #刚才的操作换到这里，你懂的def update_setting_remote(): print &quot;remote update&quot; with cd(&apos;~/temp&apos;): #cd用于进入某个目录 run(&apos;ls -l | wc -l&apos;) #远程操作用rundef update(): setting_ci() update_setting_remote() 然后，执行之： 1234567891011[ken@~/tmp/fab$] fab -f deploy.py update[user@ip:port] Executing task &apos;update&apos;[localhost] local: echo &quot;add and commit settings in local&quot;add and commit settings in localremote update[user@ip:port] run: ls -l | wc -l[user@ip:port] out: 12[user@ip:port] out:Done. 注意，如果不声明env.password，执行到对应机器时会跳出要求输入密码的交互 多服务器混搭操作多个服务器，需要配置多个host 123456789101112131415161718192021222324#!/usr/bin/env python# encoding: utf-8from fabric.api import *#操作一致的服务器可以放在一组，同一组的执行同一套操作env.roledefs = &#123; &apos;testserver&apos;: [&apos;user1@host1:port1&apos;,], &apos;realserver&apos;: [&apos;user2@host2:port2&apos;, ] &#125;#env.password = &apos;这里不要用这种配置了，不可能要求密码都一致的，明文编写也不合适。打通所有ssh就行了&apos;@roles(&apos;testserver&apos;)def task1(): run(&apos;ls -l | wc -l&apos;)@roles(&apos;realserver&apos;)def task2(): run(&apos;ls ~/temp/ | wc -l&apos;)def dotask(): execute(task1) execute(task2) 结果： 12345678910111213[ken@~/tmp/fab$] fab -f mult.py dotask[user1@host1:port1] Executing task &apos;task1&apos;[user1@host1:port1] run: ls -l | wc -l[user1@host1:port1] out: 9[user1@host1:port1] out:[user2@host2:port2] Executing task &apos;task2&apos;[user2@host2:port2] run: ls ~/temp/ | wc -l[user2@host2:port2] out: 11[user2@host2:port2] out:Done. 扩展1.颜色 可以打印颜色，在查看操作结果信息的时候更为醒目和方便 1234567from fabric.colors import *def show(): print green(&apos;success&apos;) print red(&apos;fail&apos;) print yellow(&apos;yellow&apos;)#fab -f color.py show 2.错误和异常 关于错误处理 默认，一组命令，上一个命令执行失败后，不会接着往下执行 失败后也可以进行不一样的处理， 文档 目前没用到，后续用到再看了 3.密码管理 看文档 更好的密码管理方式，哥比较土，没打通，主要是服务器列表变化频繁，我的处理方式是： 3.1 host,user,port,password配置列表，所有的都写在一个文件 或者直接搞到脚本里，当然这个更…….. 123456789101112131415161718192021env.hosts = [ &apos;host1&apos;, &apos;host2&apos;]# 注意: 要使env.passwords生效, host格式必须是 user@ip:port 端口号一定要显式写出来,即使是使用的默认22端口env.passwords = &#123; &apos;host1&apos;: &quot;pwdofhost1&quot;, &apos;host2&apos;: &quot;pwdofhost2&quot;,&#125;或者env.roledefs = &#123;&apos;testserver&apos;: [&apos;host1:22&apos;, &apos;host2:22&apos;],&apos;realserver&apos;: [&apos;host3:22&apos;, ]&#125;# 注意: 要使env.passwords生效, host格式必须是 user@ip:port 端口号一定要显式写出来,即使是使用的默认22端口env.passwords = &#123; &apos;host1:22&apos;: &quot;pwdofhost1&quot;, &apos;host2:22&apos;: &quot;pwdofhost2&quot;, &apos;host3:22&apos;: &quot;pwdofhost3&quot;,&#125; 3.2 根据key解析成map嵌套，放到deploy中 另外命令其实也可以固化成一个cmds列表的….. 粗略就用到这些，后续有更多需求的时候再去捞文档了，话说文档里好东西真多，就是太多了，看了晕。。。 TODO: 123456789101112131415装饰器作用？@task@parallel命令行常用： fab --helpfab -l -- 显示可用的task（命令）fab -H -- 指定host，支持多host逗号分开fab -R -- 指定role，支持多个fab -P -- 并发数，默认是串行fab -w -- warn_only，默认是碰到异常直接abort退出fab -f -- 指定入口文件，fab默认入口文件是：fabfile/fabfile.py状态确认及错误处理更复杂的操作 update log 12014-10-26 fix error of local/lcd The end!","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"fabric","slug":"fabric","permalink":"https://plpcm.github.io/blog/tags/fabric/"}]},{"title":"浅谈CLOSE_WAIT","slug":"tcp_CLOSE_WAIT","date":"2016-12-02T02:30:16.000Z","updated":"2017-01-05T07:41:44.000Z","comments":true,"path":"2016/12/02/tcp_CLOSE_WAIT/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/12/02/tcp_CLOSE_WAIT/","excerpt":"","text":"发表于2016-01-19 TCP 有很多连接状态，每一个都够聊十块钱儿的，比如我们以前讨论过 TIME_WAIT 和 FIN_WAIT1，最近时不时听人提起 CLOSE_WAIT，感觉有必要梳理一下。 所谓 CLOSE_WAIT，借用某位大牛的话来说应该倒过来叫做 WAIT_CLOSE，也就是说「等待关闭」，如果你还不理解其含义，可以看看 TCP 关闭连接时的图例： TCP Close 不要被图中的 client 和 server 所迷惑，你只要记住：主动关闭的一方发出 FIN 包，被动关闭的一方响应 ACK 包，此时，被动关闭的一方就进入了 CLOSE_WAIT 状态。如果一切正常，稍后被动关闭的一方也会发出 FIN 包，然后迁移到 LAST_ACK 状态。 通常，CLOSE_WAIT 状态在服务器停留时间很短，如果你发现大量的 CLOSE_WAIT 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般有如下几种可能： 程序问题：如果代码层面忘记了 close 相应的 socket 连接，那么自然不会发出 FIN 包，从而导致 CLOSE_WAIT 累积；或者代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。 响应太慢或者超时设置过小：如果连接双方不和谐，一方不耐烦直接 timeout，另一方却还在忙于耗时逻辑，就会导致 close 被延后。响应太慢是首要问题，不过换个角度看，也可能是 timeout 设置过小。 BACKLOG 太大：此处的 backlog 不是 syn backlog，而是 accept 的 backlog，如果 backlog 太大的话，设想突然遭遇大访问量的话，即便响应速度不慢，也可能出现来不及消费的情况，导致多余的请求还在队列里就被对方关闭了。 如果你通过「netstat -ant」或者「ss -ant」命令发现了很多 CLOSE_WAIT 连接，请注意结果中的「Recv-Q」和「Local Address」字段，通常「Recv-Q」会不为空，它表示应用还没来得及接收数据，而「Local Address」表示哪个地址和端口有问题，我们可以通过「lsof -i:」来确认端口对应运行的是什么程序以及它的进程号是多少。 如果是我们自己写的一些程序，比如用 HttpClient 自定义的蜘蛛，那么八九不离十是程序问题，如果是一些使用广泛的程序，比如 Tomcat 之类的，那么更可能是响应速度太慢或者 timeout 设置太小或者 BACKLOG 设置过大导致的故障。 此外还有一点需要说明：按照前面图例所示，当被动关闭的一方处于 CLOSE_WAIT 状态时，主动关闭的一方处于 FIN_WAIT2 状态。 那么为什么我们总听说 CLOSE_WAIT 状态过多的故障，但是却相对少听说 FIN_WAIT2 状态过多的故障呢？这是因为 Linux 有一个「tcp_fin_timeout」设置，控制了 FIN_WAIT2 的最大生命周期。坏消息是 CLOSE_WAIT 没有类似的设置，如果不重启进程，那么 CLOSE_WAIT 状态很可能会永远持续下去；好消息是如果 socket 开启了 keepalive 机制，那么可以通过相应的设置来清理无效连接，不过 keepalive 是治标不治本的方法，还是应该找到问题的症结才对。 本来想多写点的，但是着急回家，就写到这吧，推荐两个案例： PHP升级导致系统负载过高问题分析 又见CLOSE_WAIT 写得都比我好，建议大家仔细阅读。","categories":[{"name":"tcp","slug":"tcp","permalink":"https://plpcm.github.io/blog/categories/tcp/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://plpcm.github.io/blog/tags/tcp/"}]},{"title":"Keepalived+HAProxy实现读写分离discuz论坛","slug":"ansible_haproxy_keepalive","date":"2016-11-02T02:30:16.000Z","updated":"2017-01-11T03:49:49.000Z","comments":true,"path":"2016/11/02/ansible_haproxy_keepalive/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/11/02/ansible_haproxy_keepalive/","excerpt":"","text":"一、测试环境： centos 6.6；使用8台虚拟机（上图）分别对它们设置主机名： 主机名 ip地址 软件包 node1 172.16.16.11 keepalived+haproxy node2 172.16.16.12 keepalived+haproxy php1 172.16.16.2 httpd+php+php-mysql+nfs-utils php2 172.16.16.8 httpd+php+php-mysql+nfs-utils web1 172.16.16.3 httpd web2 172.16.16.4 httpd mysql 172.16.16.5 mariadb-5.5.43-linux-x86_64.tar.gz nfs 172.16.16.252 nfs-utils 上述服务器实现的作用介绍： ①keepalived+haproxy，实现高可用和haproxy的反向代理功能并实现动静分离的效果；请求动态的内容交给后端的动态服务器组（php1或php2）；静态内容交给静态服务器组（web1和web2） ②mysql服务器存储discuz数据库 ③nfs文件共享服务器设置2个目录/mydata和/discuz；前者给mysql服务器用做当datadir使用；后者给web和php服务器使用，共享discuz网页文件 二、准备工作：这里基于ansible的playbook部署1、ansible使用环境为centos 7；设置如下123456789# ssh-keygen -t rsa -P &apos;&apos;# ssh-copy-id -i ~/.ssh/id_rsa.pub node1# ssh-copy-id -i ~/.ssh/id_rsa.pub node2# ssh-copy-id -i ~/.ssh/id_rsa.pub web1# ssh-copy-id -i ~/.ssh/id_rsa.pub web2# ssh-copy-id -i ~/.ssh/id_rsa.pub php1# ssh-copy-id -i ~/.ssh/id_rsa.pub php2# ssh-copy-id -i ~/.ssh/id_rsa.pub mysql# ssh-copy-id -i ~/.ssh/id_rsa.pub nfs 2、ansible设置及管理节点探测：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# vim /etc/ansible/host[haproxy]172.16.16.11172.16.16.12[dynamic_servers]172.16.16.2172.16.16.8[static_servers]172.16.16.3172.16.16.4[db]172.16.16.5[nfs]172.16.16.252# ansible all -m ping172.16.16.12 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.16.3 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.16.11 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.16.4 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.16.5 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.16.2 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.16.8 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;172.16.16.252 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; 3、ansible定义roles如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@localhost ansible_playbooks]# tree.|-- haproxy.yml //playbook剧本`-- roles //定义的角色（7个） |-- haproxy //node1,node2节点用到的haproxy | |-- files | |-- handlers | | `-- main.yml | |-- tasks | | `-- main.yml | |-- templates | | |-- haproxy.cfg.j2 | | `-- rsyslog.conf | `-- vars | `-- main.yml |-- httpd //web1，web2节点用到的httpd | |-- files | | `-- mountnfs.sh | |-- handlers | |-- tasks | | `-- main.yml | `-- templates | `-- httpd.conf.j2 |-- initialization //所有节点用到的系统初始化 | |-- files | |-- handlers | |-- tasks | | `-- main.yml | `-- templates | |-- hosts | |-- resolv.conf | `-- selinux.conf |-- keepalived //keepalived设置 | |-- files | | `-- notify.sh | |-- handlers | | `-- main.yml | |-- tasks | | `-- main.yml | |-- templates | | |-- keepalived.conf.backup.j2 | | `-- keepalived.conf.master.j2 | `-- vars | `-- main.yml |-- mysql //mysql数据库 | |-- files | | |-- mariadb-5.5.43-linux-x86_64.tar.gz | | |-- mariadb-5.5.43.sh | | `-- privilege.sh | |-- handlers | |-- tasks | | `-- main.yml | `-- templates |-- nfs //nfs文件共享 | |-- files | | |-- Discuz_X3.1_SC_UTF8.zip | | `-- discuz.sh | |-- handlers | |-- tasks | | `-- main.yml | `-- templates | `-- exports `-- php //php1,php2节点用到的相关配置 |-- files | |-- install-php.sh | `-- mountnfs.sh |-- handlers |-- tasks | `-- main.yml `-- templates `-- httpd.conf.j2 4、介绍上述roles代表的含义，从上至下进行介绍；4.1、haproxy handlers:main.yml12345678 - name: restart haproxy //重启haproxy服务 service: name=haproxy state=restarted- name: restart rsyslog //重启rsyslog服务 service: name=rsyslog state=restarted tasks:main.yml123456789101112131415161718192021222324- name: install haproxy package yum: name=haproxy state=present- name: configuration haproxy template: src=haproxy.cfg.j2 dest=/etc/haproxy/haproxy.cfg notify: - restart haproxy tags: cfg- name: configuration rsyslog for haproxy template: src=rsyslog.conf dest=/etc/rsyslog.conf notify: - restart rsyslog- name: start haproxy service service: name=haproxy state=started enabled=yes template 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455haproxy.cfg.j2: //只截取了重要的部分，动静分离，后端服务器定义frontend http bind *:80 mode http log global option httpclose option logasap option dontlognull acl url_static path_end -i .jpg .gif .png .css .js .html .ico use_backend static_servers if url_static default_backend dynamic_servers#---------------------------------------------------------------------# static backend for serving up images, stylesheets and such#---------------------------------------------------------------------backend static_servers balance roundrobin cookie WebID insert nocache server web1 &#123;&#123; web1_ip &#125;&#125;:80 check cookie web1 server web2 &#123;&#123; web2_ip &#125;&#125;:80 check cookie web2#---------------------------------------------------------------------# round robin balancing between the various backends#---------------------------------------------------------------------backend dynamic_servers balance uri hash-type consistent server php1 &#123;&#123; php1_ip &#125;&#125;:80 check cookie php1 server php2 &#123;&#123; php2_ip &#125;&#125;:80 check cookie php2rsyslog.conf Vars:main.yml 1234567web1_ip : 172.16.16.3 //静态web1服务器ipweb2_ip : 172.16.16.4 //静态web2服务器ipphp1_ip : 172.16.16.2 //动态php1服务器ipphp2_ip : 172.16.16.8 //动态php2服务器ip 4.2、httpd files：mountnfs.sh12345yum install -y nfs-utils &amp;&gt; /dev/null //挂载nfs共享目录echo &quot; 172.16.16.252:/discuz /var/www/html/ nfs defaults,_netdev 0 0 &quot; &gt;&gt; /etc/fstabmount -a tasks:main.yml123456789101112131415- name: install httpd package yum: name=httpd state=present- name: mount nfs share directory /discuz script: mountnfs.sh- name: set configuration template: src=httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf- name: start httpd service service: name=httpd state=started templates:http.conf.j21LogFormat %&#123;X-Forwarded-For&#125;i combined //将客户端ip记入日志 4.3、initialization tasks：main.yml12345678910111213141516171819202122232425262728293031323334353637383940- name: set selinux shell: sed -i &apos;s@^SELINUX=.*@SELINUX=permissive@&apos; /etc/selinux/config shell: setenforce 0- name: install libselinux-python package yum: name=libselinux-python state=present- name: copy hosts to all node /etc/hosts template: src=hosts dest=/etc/hosts- name: copy resolv.conf to all node /etc/resolv.conf template: src=resolv.conf dest=/etc/resolv.conf- name: install ntpdate package yum: name=ntpdate state=present- name: synctime from ntp.sjtu.edu.cn shell: ntpdate ntp.sjtu.edu.cn- name: set a cron to synctime from ntp.sjtu.edu.cn cron: name=&quot;cron to synctime from ntp.sjtu.edu.cn&quot; minute=&quot;*/5&quot;job=&quot;/usr/sbin/ntpdate ntp.sjtu.edu.cn &amp;&gt; /dev/null&quot;state=present- name: modify selinux configuration template: src=selinux.conf dest=/etc/selinux/conf- name: set selinux permissive shell: setenforce 0 templates:3个文件12345678910111213141516171819202122232425262728293031(1)hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6172.16.16.11 node1172.16.16.12 node2172.16.16.3 web1172.16.16.4 web2172.16.16.2 php1172.16.16.8 php2172.16.16.5 mysql172.16.16.252 nfs(2)resolv.confnameserver 172.16.0.1(3)selinux.confSELINUX=disabledSELINUXTYPE=targeted 4.4、keepalived files:notify.sh1通知机制：当主从发生变化的时候给管理员发邮件 handlers：main.yml12- name: restart keepalived service: name=keepalived state=restarted tasks:main.yml123456789101112131415161718192021222324252627282930- name: install keepalived package yum: name=keepalived state=present- name: copy notify.sh to node1 and node2 copy: src=notify.sh dest=/etc/keepalived/notify.sh- name: configure keepalived on node1-master template: src=keepalived.conf.master.j2 dest=/etc/keepalived/keepalived.conf when: ansible_hostname == &quot;node1&quot; notify: - restart keepalived- name: configure keepalived on node2-backup template: src=keepalived.conf.backup.j2 dest=/etc/keepalived/keepalived.conf when: ansible_hostname == &quot;node2&quot; notify: - restart keepalived- name: start keepalived service service: name=keepalived state=started enabled=yes templates1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495keepalived.conf.master.j2! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_connect_timeout 3 smtp_server 127.0.0.1 router_id LVS_DEVEL&#125;vrrp_script chk_haproxy &#123; script &quot;killall -0 haproxy&quot; interval 1 weight 2&#125;vrrp_script chk_mantaince_down &#123; script &quot;[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0&quot; interval 1 weight 2&#125;vrrp_instance VI_1 &#123; interface eth0 state MASTER # BACKUP for slave routers priority 101 # 100 for BACKUP virtual_router_id 51 garp_master_delay 1 authentication &#123; auth_type PASS auth_pass password12345 &#125; track_interface &#123; eth0 &#125; virtual_ipaddress &#123; &#123;&#123; vip &#125;&#125;/16 dev eth0 label eth0:0 &#125; track_script &#123; chk_haproxy chk_mantaince_down &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;keepalived.conf.backup.j2 state BACKUP priority 100 vars:main.yml1vip : 172.16.16.50 4.5、mysql files:3个文件1234567891011121314151617(1)mariadb-5.5.43.sh: 编译安装配置mariadb的脚本，就不发了，太多(2)privilege.sh#!/bin/bash#! privilege to dzuserecho &quot;create database discuz;grant all on discuz.* to &apos;dzuser&apos;@&apos;172.16.%.%&apos; identified by &apos;dzpasswd&apos;;flush privileges;\\q&quot; | mysql~ tasks:main.yml1234567891011121314151617- name: copy mariadb-5.5.43 package copy: src=mariadb-5.5.43-linux-x86_64.tar.gz dest=/root/mariadb-5.5.43-linux-x86_64.tar.gz- name: install mysql and cofiguration script: mariadb-5.5.43.sh- name: start mysqld service shell: service mysqld start- name: privileges to dzuser script: privilege.sh tags: haha 4.6、nfs files：discuz.sh1234567891011#!/bin/bash# discuz configurationunzip -d /discuz /root/Discuz_X3.1_SC_UTF8.zipchmod -R go+w /discuz/upload/config/chmod -R go+w /discuz/upload/data/chmod -R go+w /discuz/upload/uc_* tasks:main.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445- name: mkdir share directory to mysql and web shell: mkdir -pv /&#123;mydata,discuz&#125;- name: install nfs package yum: name=nfs-utils state=present- name: useradd mysql user: name=mysql state=present system=yes- name: useradd apache user: name=apache state=present system=yes- name: copy exports to nfs node template: src=exports dest=/etc/exports- name: set mysql mode(rwx) to /mydata shell: setfacl -m u:mysql:rwx /mydata- name: set apache mode(rwx) to /discuz shell: setfacl -m u:apache:rwx /discuz- name: copy Discuz_X3.1_SC_UTF8.zip package copy: src=Discuz_X3.1_SC_UTF8.zip dest=/root/Discuz_X3.1_SC_UTF8.zip- name: install unzip package yum: name=unzip state=present - name: configuration discuz script: discuz.sh - name: start rpcbind service service: name=rpcbind state=started- name: start nfs service templates:exports12/mydata 172.16.0.0/16(rw,no_root_squash)//编译安装mysql需要这样设置，安装完可以改成rw权限即可/discuz 172.16.0.0/16(rw) 4.7、php files：2个文件123456789(1)install-php.sh#!/bin/bash# install nfs-utils httpd | php | php-mysqlyum install -y nfs-utils httpd php php-mysql openssl-devel &amp;&gt; /dev/null(2)mountnfs.sh //同httpd使用的脚本 tasks：main.yml1234567891011121314- name: install nfs-utils | httpd | php | php-mysql package script: install-php.sh- name: mount nfs share directory /discuz script: mountnfs.sh- name: set configuration template: src=httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf- name: start httpd service service: name=httpd state=started templates:httpd.conf.j21这个模板也同httpd使用的！ 三、执行过程如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242[root@localhost ansible_playbooks]# ansible-playbook haproxy.yml //执行ansible剧本PLAY [nfs] ********************************************************************GATHERING FACTS ***************************************************************ok: [172.16.16.252]TASK: [initialization | set selinux] ******************************************changed: [172.16.16.252] //设置selinuxTASK: [initialization | install libselinux-python package] ********************changed: [172.16.16.252] //需要安装libselinux-pythonTASK: [initialization | copy hosts to all node /etc/hosts] ********************changed: [172.16.16.252] //复制主机名解析文件TASK: [initialization | copy resolv.conf to all node /etc/resolv.conf] ********changed: [172.16.16.252] //复制域名文件TASK: [initialization | install ntpdate package] ******************************changed: [172.16.16.252] //安装ntpdateTASK: [initialization | synctime from ntp.sjtu.edu.cn] ************************changed: [172.16.16.252] //同步时间TASK: [initialization | set a cron to synctime from ntp.sjtu.edu.cn] ********** //设置计划任务changed: [172.16.16.252]TASK: [initialization | modify selinux configuration] *************************changed: [172.16.16.252] //修改selinuxTASK: [initialization | set selinux permissive] *******************************changed: [172.16.16.252]TASK: [nfs | mkdir share directory to mysql and web] **************************changed: [172.16.16.252] //创建nfs的共享目录/mydata和/discuzTASK: [nfs | install nfs package] *********************************************changed: [172.16.16.252] //安装nfs-utilsTASK: [nfs | useradd mysql] ***************************************************changed: [172.16.16.252] //添加mysql用户TASK: [nfs | useradd apache] **************************************************changed: [172.16.16.252] //添加apache用户TASK: [nfs | copy exports to nfs node] ****************************************changed: [172.16.16.252] //设置nfs导出的共享目录TASK: [nfs | set mysql mode(rwx) to /mydata] **********************************changed: [172.16.16.252] //给mysql对/mydata的rwx权限TASK: [nfs | set apache mode(rwx) to /discuz] *********************************changed: [172.16.16.252] //给apache对/discuz的rwx权限TASK: [nfs | copy Discuz_X3.1_SC_UTF8.zip package] ****************************changed: [172.16.16.252] //复制discuz安装包到nfs服务器TASK: [nfs | install unzip package] *******************************************changed: [172.16.16.252] //解压discuzTASK: [nfs | configuration discuz] ********************************************changed: [172.16.16.252] //配置discuz网页文件（给其对应访问权限）TASK: [nfs | start rpcbind service] *******************************************changed: [172.16.16.252] //启动rpcbind服务TASK: [nfs | start nfs service] ***********************************************changed: [172.16.16.252] //启动nfs服务PLAY [db] ********************************************************************* //安装及配置mysqlGATHERING FACTS ***************************************************************ok: [172.16.16.5]TASK: [initialization | set selinux] ******************************************changed: [172.16.16.5]TASK: [initialization | install libselinux-python package] ********************changed: [172.16.16.5]TASK: [initialization | copy hosts to all node /etc/hosts] ********************changed: [172.16.16.5]TASK: [initialization | copy resolv.conf to all node /etc/resolv.conf] ********changed: [172.16.16.5]TASK: [initialization | install ntpdate package] ******************************changed: [172.16.16.5]TASK: [initialization | synctime from ntp.sjtu.edu.cn] ************************changed: [172.16.16.5]TASK: [initialization | set a cron to synctime from ntp.sjtu.edu.cn] **********changed: [172.16.16.5]TASK: [initialization | modify selinux configuration] *************************changed: [172.16.16.5]TASK: [initialization | set selinux permissive] *******************************changed: [172.16.16.5]TASK: [mysql | copy mariadb-5.5.43 package] ***********************************changed: [172.16.16.5] //复制mariadb到mysql服务器TASK: [mysql | install mysql and cofiguration] ********************************changed: [172.16.16.5] //脚本执行mysql安装，配置TASK: [mysql | start mysqld service] ******************************************changed: [172.16.16.5] //启动mysqld服务TASK: [mysql | privileges to dzuser] ******************************************changed: [172.16.16.5] //使用脚本创建discuz数据库，并给dzuser授权PLAY [static_servers] ********************************************************* //静态服务器设置 web1和web2节点GATHERING FACTS ***************************************************************ok: [172.16.16.3]ok: [172.16.16.4]TASK: [initialization | set selinux] ******************************************changed: [172.16.16.3]changed: [172.16.16.4]TASK: [initialization | install libselinux-python package] ********************changed: [172.16.16.3]changed: [172.16.16.4]TASK: [initialization | copy hosts to all node /etc/hosts] ********************changed: [172.16.16.4]changed: [172.16.16.3]TASK: [initialization | copy resolv.conf to all node /etc/resolv.conf] ********changed: [172.16.16.3]changed: [172.16.16.4]TASK: [initialization | install ntpdate package] ******************************changed: [172.16.16.3]changed: [172.16.16.4]TASK: [initialization | synctime from ntp.sjtu.edu.cn] ************************changed: [172.16.16.4]changed: [172.16.16.3]TASK: [initialization | set a cron to synctime from ntp.sjtu.edu.cn] **********changed: [172.16.16.3]changed: [172.16.16.4]TASK: [initialization | modify selinux configuration] *************************changed: [172.16.16.3]changed: [172.16.16.4]TASK: [initialization | set selinux permissive] *******************************changed: [172.16.16.4]changed: [172.16.16.3]TASK: [httpd | install httpd package] *****************************************changed: [172.16.16.3] //安装httpd软件包changed: [172.16.16.4]TASK: [httpd | mount nfs share directory /discuz] *****************************changed: [172.16.16.3] //挂载nfs服务器共享的discuz目录至/var/www/htmlchanged: [172.16.16.4]TASK: [httpd | set configuration] *********************************************changed: [172.16.16.4] //配置httpd.confchanged: [172.16.16.3]TASK: [httpd | start httpd service] *******************************************changed: [172.16.16.3] //启动httpd服务changed: [172.16.16.4]PLAY [dynamic_servers] ******************************************************** //设置动态服务器php1和php2节点GATHERING FACTS ***************************************************************ok: [172.16.16.2]ok: [172.16.16.8]TASK: [initialization | set selinux] ******************************************changed: [172.16.16.2]changed: [172.16.16.8]TASK: [initialization | install libselinux-python package] ********************changed: [172.16.16.2]changed: [172.16.16.8]TASK: [initialization | copy hosts to all node /etc/hosts] ********************changed: [172.16.16.8]changed: [172.16.16.2]TASK: [initialization | copy resolv.conf to all node /etc/resolv.conf] ********changed: [172.16.16.8]changed: [172.16.16.2]TASK: [initialization | install ntpdate package] ******************************changed: [172.16.16.2]changed: [172.16.16.8]TASK: [initialization | synctime from ntp.sjtu.edu.cn] ************************changed: [172.16.16.2]changed: [172.16.16.8]TASK: [initialization | set a cron to synctime from ntp.sjtu.edu.cn] **********changed: [172.16.16.8]changed: [172.16.16.2]TASK: [initialization | modify selinux configuration] *************************changed: [172.16.16.8]changed: [172.16.16.2]TASK: [initialization | set selinux permissive] *******************************changed: [172.16.16.8]changed: [172.16.16.2]TASK: [php | install nfs-utils | httpd | php | php-mysql package] *************changed: [172.16.16.8] //安装php软件包（使用的是centos 6系统自带的）changed: [172.16.16.2]TASK: [php | mount nfs share directory /discuz] *******************************changed: [172.16.16.8] //挂载discuz目录至/var/www/htmlchanged: [172.16.16.2]TASK: [php | set configuration] ***********************************************changed: [172.16.16.8] //配置httpd.conf，给日志加入客户端访问的ip地址changed: [172.16.16.2]TASK: [php | start httpd service] *********************************************changed: [172.16.16.8] //启用php功能changed: [172.16.16.2]PLAY [haproxy] **************************************************************** //安装设置keepalived+haproxy（node1和node2）GATHERING FACTS ***************************************************************ok: [172.16.16.12]ok: [172.16.16.11]TASK: [initialization | set selinux] ******************************************changed: [172.16.16.12]changed: [172.16.16.11]TASK: [initialization | install libselinux-python package] ********************changed: [172.16.16.12]changed: [172.16.16.11]TASK: [initialization | copy hosts to all node /etc/hosts] ********************changed: [172.16.16.12]changed: [172.16.16.11]TASK: [initialization | copy resolv.conf to all node /etc/resolv.conf] ********changed: [172.16.16.11]changed: [172.16.16.12]TASK: [initialization | install ntpdate package] ******************************ok: [172.16.16.12]ok: [172.16.16.11]TASK: [initialization | synctime from ntp.sjtu.edu.cn] ************************changed: [172.16.16.12]changed: [172.16.16.11]TASK: [initialization | set a cron to synctime from ntp.sjtu.edu.cn] **********changed: [172.16.16.11]changed: [172.16.16.12]TASK: [initialization | modify selinux configuration] *************************changed: [172.16.16.11]changed: [172.16.16.12]TASK: [initialization | set selinux permissive] *******************************changed: [172.16.16.11]changed: [172.16.16.12]TASK: [keepalived | install keepalived package] *******************************changed: [172.16.16.11] //安装keepalivedchanged: [172.16.16.12]TASK: [keepalived | copy notify.sh to node1 and node2] ************************changed: [172.16.16.12] //复制通知脚本给node1和node2changed: [172.16.16.11]TASK: [keepalived | configure keepalived on node1-master] *********************skipping: [172.16.16.12] //设置node1为MASTER节点changed: [172.16.16.11]TASK: [keepalived | configure keepalived on node2-backup] *********************skipping: [172.16.16.11] //设置node2为BACKUP节点changed: [172.16.16.12]TASK: [keepalived | start keepalived service] *********************************changed: [172.16.16.12] //启动keepalived服务changed: [172.16.16.11]TASK: [haproxy | install haproxy package] *************************************changed: [172.16.16.12] //安装haproxy软件包changed: [172.16.16.11]TASK: [haproxy | configuration haproxy] ***************************************changed: [172.16.16.12] //配置haproxy，实现动静分离changed: [172.16.16.11]TASK: [haproxy | configuration rsyslog for haproxy] ***************************changed: [172.16.16.11] //记录haproxy的日志changed: [172.16.16.12]TASK: [haproxy | start haproxy service] ***************************************changed: [172.16.16.12] //启动haproxy服务changed: [172.16.16.11]NOTIFIED: [keepalived | restart keepalived] ***********************************changed: [172.16.16.12] //配置文件发生变化，重启keepalived服务changed: [172.16.16.11]NOTIFIED: [haproxy | restart haproxy] *****************************************changed: [172.16.16.11] //配置文件发生变化，重启haproxy服务changed: [172.16.16.12]NOTIFIED: [haproxy | restart rsyslog] *****************************************changed: [172.16.16.12] //配置文件发生变化，重启rsyslog服务changed: [172.16.16.11]PLAY RECAP ********************************************************************172.16.16.11 : ok=21 changed=19 unreachable=0 failed=0172.16.16.12 : ok=21 changed=19 unreachable=0 failed=0172.16.16.2 : ok=14 changed=13 unreachable=0 failed=0172.16.16.252 : ok=22 changed=21 unreachable=0 failed=0172.16.16.3 : ok=14 changed=13 unreachable=0 failed=0172.16.16.4 : ok=14 changed=13 unreachable=0 failed=0172.16.16.5 : ok=14 changed=13 unreachable=0 failed=0172.16.16.8 : ok=14 changed=13 unreachable=0 failed=0 四、安装discuz论坛 具体步骤略，无非是下一步下一步。安装完成，使用vip：172.16.16.50测试正常！！如下图： 五、额外测试过程：（1）测试keepalived是否工作正常，在master出现问题的时候，是否可以切换到backup上： 1[root@node1 keepalived]# tail /var/log/messages //通过下面的日志可看出node1成为BACKUPOct 24 20:08:19 node1 Keepalived_vrrp[2644]: VRRP_Script(chk_mantaince_down) failedOct 24 20:08:21 node1 Keepalived_vrrp[2644]: VRRP_Instance(VI_1) Received higher prio advertOct 24 20:08:21 node1 Keepalived_vrrp[2644]: VRRP_Instance(VI_1) Entering BACKUP STATEOct 24 20:08:21 node1 Keepalived_vrrp[2644]: VRRP_Instance(VI_1) removing protocol VIPs.Oct 24 20:08:21 node1 Keepalived_healthcheckers[2643]: Netlink reflector reports IP 172.16.16.50 removed[root@node2 ~]# tail /var/log/messages //通过下面的日志可看出node2成为MASTEROct 24 20:08:22 node2 Keepalived_vrrp[2442]: VRRP_Instance(VI_1) Transition to MASTER STATEOct 24 20:08:23 node2 Keepalived_vrrp[2442]: VRRP_Instance(VI_1) Entering MASTER STATEOct 24 20:08:23 node2 Keepalived_vrrp[2442]: VRRP_Instance(VI_1) setting protocol VIPs.Oct 24 20:08:23 node2 Keepalived_healthcheckers[2441]: Netlink reflector reports IP 172.16.16.50 addedOct 24 20:08:23 node2 Keepalived_vrrp[2442]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 172.16.16.50 这个时候访问discuz论坛仍然没有问题；说明keepalived发挥了作用！ （2）测试haproxy是否可以实现读写分离 方法：将所有static_servers的httpd服务停止，测试只提供php的功能，显示效果如下图： 12[root@web1 ~]# service httpd stop //停止web1和web2的httpd服务，提供静态内容显示[root@web2 ~]# service httpd stop # 可以看到上面的效果，图片都已经不再显示，将web2加回来，然后再查看效果，并查看http的访问日志 1234[root@web2 ~]# service httpd start //启动其中的一台[root@web2 ~]# tail /var/log/httpd/access_log172.16.0.3 - - [24/Oct/2015:20:46:54 +0800] &quot;GET /static/image/common/user_online.gif HTTP/1.1&quot; 200 868 &quot;http://172.16.16.50/data/cache/style_1_common.css?SFA&quot; &quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36&quot;172.16.0.3 - - [24/Oct/2015:20:46:54 +0800] &quot;GET /static/image/common/arrwd.gif HTTP/1.1&quot; 200 51 &quot;http://172.16.16.50/data/cache/style_1_common.css?SFA&quot; &quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36&quot; 本篇自自于51cto bengbengtu的文章，实现haproxy+keepalived的方案属于一个比较成熟的方案并无太多新意，之所以将该篇拿过来看备忘下无法看到是通过ansible+haproxy+keepalived做了一个简单的整合，还是有点意思的。而且实的步骤也相对详尽，还是值得一看的。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"},{"name":"haproxy","slug":"haproxy","permalink":"https://plpcm.github.io/blog/tags/haproxy/"},{"name":"keepalive","slug":"keepalive","permalink":"https://plpcm.github.io/blog/tags/keepalive/"},{"name":"discuz","slug":"discuz","permalink":"https://plpcm.github.io/blog/tags/discuz/"}]},{"title":"yaml在python上的使用","slug":"yaml","date":"2016-10-25T02:30:16.000Z","updated":"2017-01-11T08:23:34.000Z","comments":true,"path":"2016/10/25/yaml/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/25/yaml/","excerpt":"","text":"一、YAML的格式YAML的格式及特点如下： YAML使用可打印的Unicode字元，可使用UTF-8或UTF-16。 使用空白字元为文件缩排来表示结构；不过不能使用跳格字元(TAB)。 注解由井字号（ # ）开始，可以出现在一行中的任何位置，而且范围只有一行（也就是一般所谓的单行注解） 每个清单成员以单行表示，并用短杠+空白（ - ）起始。或使用方括号（ [ ] ），并用逗号+空白（ , ）分开成员。 每个杂凑表的成员用冒号+空白（ : ）分开键值和内容。或使用大括号（ { } ），并用逗号+空白（ , ）分开。杂凑表的键值可以用问号 ( ? )起始，用来明确的表示多个词汇组成的键值。 字串平常并不使用引号，但必要的时候可以用双引号 ( “ )或单引号 ( ‘ )框住。使用双引号表示字串时，可用倒斜线（ \\ ）开始的跳脱字元（这跟C语言类似）表示特殊字元。 区块的字串用缩排和修饰词（非必要）来和其他资料分隔，有新行保留（preserve）（使用符号 | ）或新行折叠（flod）（使用符号 &gt; ）两种方式。 在单一档案中，可用连续三个连字号（—）区分多个档案。另外，还有选择性的连续三个点号（ … ）用来表示档案结尾。 重复的内容可使从参考标记星号 ( * )复制到锚点标记（ &amp; ）。 指定格式可以使用两个惊叹号 ( !! )，后面接上名称。 档案中的单一文件可以使用指导指令，使用方法是百分比符号( % )。有两个指导指令在YAML1.1版中被定义： %YAML 指导指令，用来识别文件的YAML版本。 %TAG 指导指令，被用在URI的字首标记。这个方法在标记节点的型态时相当有用。 YAML再使用逗号及冒号时，后面都必须接一个空白字元。 二、PyYAML的使用1、安装python下安装PyYAML模块可以使用YAML ，打开https://pypi.python.org/pypi/PyYAML下载，当前版本3.11 。pypi 站点上对该模块的描述如下：PyYAML features a complete YAML 1.1 parser, Unicode support, pickle support, capable extension API, and sensible error messages 。 可以连网的主机也可以通过pip install pyyaml 或easy_install pyymal 进行安装。 2、yaml.load与yaml.dump方法该模块提供了一些方法，不过常用的方法只有两个yaml.load和yaml.dump ，以下是一个版本相关的yaml 格式文件12345678910[root@361way yaml]# cat tree.yamltreeroot: branch1: name: Node 1 branch1-1: name: Node 1-1 branch2: name: Node 2 branch2-1: name: Node 2-1 yaml.load方法：12345678910# 脚本内容[root@361way yaml]# cat load.pyimport yamlf = open(&apos;tree.yaml&apos;)dataMap = yaml.load(f)f.close()print dataMap# 执行结果如下[root@361way yaml]# python load.py&#123;&apos;treeroot&apos;: &#123;&apos;branch2&apos;: &#123;&apos;branch2-1&apos;: &#123;&apos;name&apos;: &apos;Node 2-1&apos;&#125;, &apos;name&apos;: &apos;Node 2&apos;&#125;, &apos;branch1&apos;: &#123;&apos;branch1-1&apos;: &#123;&apos;name&apos;: &apos;Node 1-1&apos;&#125;, &apos;name&apos;: &apos;Node 1&apos;&#125;&#125;&#125; yuml.dump方法： 这里还承接上面的脚本，调用里面的dataMap 数据，将其保存一直新的yaml 文件，如下：12345678910111213# 代码如下：f = open(&apos;newtree.yaml&apos;, &quot;w&quot;)yaml.dump(dataMap, f)f.close()#newtree.yaml 的结果如下[root@361way yaml]# cat newtree.yamltreeroot: branch1: branch1-1: &#123;name: Node 1-1&#125; name: Node 1 branch2: branch2-1: &#123;name: Node 2-1&#125; name: Node 2 除此之外，还有safe_load、safe_dump、 load_all 等主法，具体可以通过pydoc yaml 进行查看。 ###三、yaml、xml与json ####1、yaml 与xml 以下是同一内容，分别使用xml 语言标记与 yaml 语言标记：1234567891011121314151617181920212223# xml标记两个site&lt;site&gt; &lt;name&gt;sina&lt;/name&gt; &lt;url&gt;http://www.361way.com&lt;/url&gt;&lt;/site&gt;&lt;site&gt; &lt;name&gt;google&lt;/name&gt; &lt;url&gt;http://www.91it.org&lt;/url&gt;&lt;/site&gt;# 使用yaml标记两个site---site: name: sina url : http://www.361way.com---site: name: google url : http://www.91it.org# 使用yaml标记两个site---site: &#123;name: sina, url: http://www.361way.com&#125;---site: &#123;name: google, url: http://www.91it.org&#125; 从读取查看的角度来看，有没有发现yaml 相对xml 语言的优势。 ####2、yaml 与 json 准确的说json 应该算是yaml 标准下的一个字集，通过python语句可以很方面的在两者之间进行转换。 a、转换YAML到JSON1234567891011# python -c &apos;import sys, yaml, json; json.dump(yaml.load(sys.stdin), sys.stdout, indent=4)&apos; &lt; file.yaml &gt; file.json或#!/usr/bin/env pythonimport yaml,jsonyml = &quot;&quot;&quot;--- foo: bar&quot;&quot;&quot;data = yaml.load(yml)json = json.dumps(data)print(json) b、转换JSON到YAML12345678# python -c &apos;import sys, yaml, json; yaml.dump(json.load(sys.stdin), sys.stdout, default_flow_style=False)&apos; &lt; file.json &gt; file.yaml或#!/usr/bin/env pythonimport json,yamlstr = &apos;&#123; &quot;foo&quot;: &quot;bar&quot; &#125;&apos;data = json.loads(str)yml = yaml.safe_dump(data)print(yml) 四、yaml 在python语言中的应用yaml 语言在很多优秀的python 程序中都有使用，比如运维工程师经常使用的两个自动化工作saltstack 与 Ansible 。更多PyYAML 模块的用法，也可以查看其官方wiki 页面：http://pyyaml.org/wiki/PyYAMLDocumentation 。","categories":[{"name":"python","slug":"python","permalink":"https://plpcm.github.io/blog/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://plpcm.github.io/blog/tags/python/"},{"name":"yaml","slug":"yaml","permalink":"https://plpcm.github.io/blog/tags/yaml/"}]},{"title":"ansible小结（十 二）磁盘使用率筛选","slug":"ansible_12","date":"2016-10-22T02:55:16.000Z","updated":"2017-01-11T01:49:03.000Z","comments":true,"path":"2016/10/22/ansible_12/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_12/","excerpt":"","text":"一、实现目标将所有主机的磁盘大于75%的主机获取到，并输出为下面的格式： 1主机IP 主机名 磁盘挂载点信息 磁盘使用率 假如 host1上有多个分区都大于75% ，则写多条。当主机上没有一台符合时，则什么都不输出。 注：现网主机上有两个 bond 网卡，其中一个配置的是10段的IP，另一个配置的是192段的IP。这里要获取的是10段的IP。 二、 ansible + awk 简单输出该问题我处理的结果是使用ansible api 写的一个python脚本实现的。先看下我在一个技术群和一个大牛的讨论的结果(点击图片看大图)。 如上图，大牛的做法用的是awk 的next方法进行的处理，awk 的next功能我也做过记录，具体参看awk next多行合并 。 这里有几个注意点需要说明下： 1、大牛的写法中在筛选上写的不严谨，$5前应该有int转化，不过不能正确的取到值 12345[root@361way ~]# df -hP|awk &apos;NR&gt;1 &amp;&amp; $5 &gt; 20&apos;/dev/xvda1 20G 4.6G 15G 25% //dev/xvdb 20G 645M 18G 4% /data1[root@361way ~]# df -hP|awk &apos;NR&gt;1 &amp;&amp; int($5) &gt; 20&apos;/dev/xvda1 20G 4.6G 15G 25% / 有没有看到，如果不做int格式转换取的结果是所有分区的信息，而加上int后获取的才是我们想要的结果 2、在ansible执行时$5前面要加上转义 123456# ansible all -m shell -a &quot;df -hP|awk &apos;NR&gt;1 &amp;&amp; int($5) &gt; 50&apos;&quot;10.212.52.252 | FAILED | rc=2 &gt;&gt;awk: fatal: 0 is invalid as number of arguments for int[root@361way ~]# df -hP|awk &apos;NR&gt;1 &amp;&amp; int(\\$5) &gt; 20&apos;awk: NR&gt;1 &amp;&amp; int(\\$5) &gt; 20awk: ^ backslash not last character on line 如上面的结果，如果在ansible执行时不加转义时会有报错提示，如果加上转义在主机端执行时会自动是将转义符去掉的结果。而在主机端执行时，如果加上了转义也会报错。所以主机端一定不能加上转义。 3、在实际应用时，输出结果可能和大牛的输出有差距 12345678910[root@localhost ~]# ansible all -m shell -a &quot;df -hP|awk &apos;NR&gt;1 &amp;&amp; int(\\$5) &gt; 30&apos;&quot;|awk &apos;/success/&#123;ip=$1;next&#125;&#123;print ip,$0&#125;&apos;10.212.52.252 /dev/sda9 9.9G 2.9G 6.5G 31% /opt10.212.52.252 /dev/sda6 5.0G 1.9G 2.8G 41% /tmp10.212.52.252 /dev/sda5 9.9G 3.9G 5.5G 42% /usr10.212.52.25210.212.52.14 /dev/cciss/c0d0p5 9.9G 3.2G 6.3G 34% /usr10.212.52.1410.212.52.16 /dev/cciss/c0d0p7 9.9G 4.0G 5.4G 43% /tmp10.212.52.16 /dev/cciss/c0d0p5 9.9G 2.9G 6.5G 31% /usrdf: `/root/.gvfs&apos;: Permission denied10.212.52.16 上面的结果是我在自己的测试环境上执行的结果。可以看到多出的空行也打印了主机的IP 。还会需要注意的，我这里ansible输出的success是小写的。 不知道以上的问题是不是使用的环境不同造成的。我运行的环境是ansible主机为redhat6，ansible版本为1.9，被取数据主机有redhat6和suse11 。不过这都是小问题，同样可以通过处理获取到正常的结果。 4、ansible api 执行 上面的大牛的结果，我使用ansible api 执行，如下，可以对比下： 123456789101112131415161718192021222324252627[root@localhost ~]# cat /tmp/test.py#!/usr/bin/env python# coding=utf-8# author ： www.361way.com# mail : itybku@139.comimport ansible.runner#import jsonrunner = ansible.runner.Runner( module_name=&apos;shell&apos;, module_args=&quot;df -hP|awk &apos;NR&gt;1 &amp;&amp; int($5)&gt;30&apos;&quot;, pattern=&apos;all&apos;, forks=10 )results = runner.run()#print resultsfor (hostname, result) in results[&apos;contacted&apos;].items(): if not &apos;failed&apos; in result: for line in result[&apos;stdout&apos;].split(&apos;\\n&apos;): print &quot;%s %s&quot; % (hostname, line)# 执行结果如下[root@localhost ~]# python /tmp/test.py10.212.52.16 /dev/cciss/c0d0p7 9.9G 4.0G 5.4G 43% /tmp10.212.52.16 /dev/cciss/c0d0p5 9.9G 2.9G 6.5G 31% /usr10.212.52.252 /dev/sda9 9.9G 2.9G 6.5G 31% /opt10.212.52.252 /dev/sda6 5.0G 1.9G 2.8G 41% /tmp10.212.52.252 /dev/sda5 9.9G 3.9G 5.5G 42% /usr10.212.52.14 /dev/cciss/c0d0p5 9.9G 3.2G 6.3G 34% /usr 三、还是ansible api 获取磁盘信息上面的方法中实际执行时，比我们预期需要的效果少了主机名一项。这里我换做执行脚本实现，实现效果如下： 123456789101112#/bin/bash# author : www.361way.comIP=`ip add show|grep inet|grep 10|awk &apos;&#123;print $2&#125;&apos;`df -hl|grep &apos;^/&apos;|sed &apos;s/%//g&apos;|awk &apos;&#123;if($5&gt;30) print $0&#125;&apos;|while read linedo echo $IP `hostname` $linedone# 执行结果如下# sh aa.sh10.212.52.253/24 localhost /dev/sda3 9.5G 5.7G 3.4G 64 /10.212.52.253/24 localhost /dev/sda2 39G 19G 18G 52 /home10.212.52.253/24 localhost /dev/sda6 9.5G 7.1G 2.0G 78 /usr 使用ansible api 执行该脚本的结果如下： 123456789# python dfscript.pydf: `/root/.gvfs&apos;: Permission denieddf: `/root/.gvfs&apos;: Permission denied10.212.52.16/24 linux /dev/cciss/c0d0p7 9.9G 4.0G 5.4G 43 /tmp10.212.52.16/24 linux /dev/cciss/c0d0p5 9.9G 2.9G 6.5G 31 /usr10.212.52.252/24 zjhz-bmc-test /dev/sda9 9.9G 2.9G 6.5G 31 /opt10.212.52.252/24 zjhz-bmc-test /dev/sda6 5.0G 1.9G 2.8G 41 /tmp10.212.52.252/24 zjhz-bmc-test /dev/sda5 9.9G 3.9G 5.5G 42 /usr10.212.52.14/24 linux /dev/cciss/c0d0p5 9.9G 3.2G 6.3G 34 /usr dfscript.py脚本内容如下 1234567891011121314151617181920# cat dfscript.py#!/usr/bin/env python# coding=utf-8# author ： www.361way.com# mail : itybku@139.comimport ansible.runner#import jsonrunner = ansible.runner.Runner( module_name=&apos;script&apos;, module_args=&quot;aa.sh&quot;, pattern=&apos;all&apos;, forks=10 )results = runner.run()#print resultsfor (hostname, result) in results[&apos;contacted&apos;].items(): if not &apos;failed&apos; in result: for line in result[&apos;stdout&apos;].split(&apos;\\r\\n&apos;): #print &quot;%s %s&quot; % (hostname, line) print line 直接对该脚本执行后的结果进行grep 标准输出时，会发现其行与行之间是以\\r\\n这样的方式分行的。 所以在数据获取方面，尽量以ansible api 的方式进行获取，而api 的使用非常简单，无法是几个参数的替换后面再调用run方法，最终在对结果进行处理。而涉及多项信息获取时，建议使用自定义模块的方法，先将所需数据取回来，以json方式返回－－－ansible自定义模块所要求的格式。返回后可以再以api 或其他方式处理返回的数据即可。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（十一）ansible普通用户su切换问题","slug":"ansible_11","date":"2016-10-22T02:50:16.000Z","updated":"2017-01-11T01:49:01.000Z","comments":true,"path":"2016/10/22/ansible_11/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_11/","excerpt":"","text":"一、ansible hosts配置文件在之前的系列文章中我们提到，可以把密码写到hosts配置文件，通过查询官网的相关信息了解了，其除了ansible_ssh_user、ansible_ssh_pass变量外，还为su切换提供了ansible_su_pass变量，通过该变量我们可以把root密码直接写到配置文件中。具体如下： 12345[root@361way.com ~]# cat /etc/ansible/hosts[test01]10.212.52.14 ansible_ssh_user=test ansible_ssh_pass=111111 ansible_su_pass=*I214510.212.52.16 ansible_ssh_user=test ansible_ssh_pass=xyz123 ansible_su_pass=mn1Pokm10.212.52.252 ansible_ssh_user=amos ansible_ssh_pass=asdf ansible_su_pass=xyzp)okm 注：我测试使用的ansible版本是1.9版的，在新的2.0版本中，变量也做了变化ansible_become_pass替换了之前的ansible_sudo_pass or ansible_su_pass ，具体可以参看官方文档。 二、ansible命令参数在执行ansible -h查看时，会看到如下条目： 1234-S, --su run operations with su (deprecated, use become)-R SU_USER, --su-user=SU_USER run operations with su as this user (default=root) (deprecated, use become) 三、su切换执行所以结合上面两块，我们做下简单的测试： 1234567[root@361way.com ~]# ansible all -S -R root -m shell -a &quot;uptime&quot;10.212.52.252 | success | rc=0 &gt;&gt; 16:13pm up 34 days 5:40, 2 users, load average: 0.08, 0.21, 0.3010.212.52.16 | success | rc=0 &gt;&gt; 16:26pm up 538 days 23:17, 2 users, load average: 0.00, 0.01, 0.0510.212.52.14 | success | rc=0 &gt;&gt; 16:24pm up 538 days 22:39, 2 users, load average: 0.00, 0.01, 0.05 这里需要注意的是，普通用户的家目录是要存在，并切该普通用户要有写的权限的，不然会出现类似如下的报错： 1234510.212.52.252 | FAILED =&gt; Authentication or permission failure.In some cases, you may have been able to authenticate and did not have permissions on the remote directory.Consider changing the remote temp path in ansible.cfg to a path rooted in &quot;/tmp&quot;.Failed command was: mkdir -p $HOME/.ansible/tmp/ansible-tmp-1449456070.96-212322517029279 &amp;&amp; echo $HOME/.ansible/tmp/ansible-tmp-1449456070.96-212322517029279,exited with result 1: mkdir: cannot create directory `/home/amos/.ansible&apos;: Permission denied 当然，如果这个普通用户没有家目录或者家目录没有写权限在不修改远端主机也有办法可以搞定，修改ansible主机的ansible.cfg配置文件，如下： 12345[root@361way.com ~]# vim /etc/ansible/ansible.cfg找到如下行：remote_tmp = $HOME/.ansible/tmp修改为remote_tmp = /tmp/.ansible/tmp tmp目录一般都有写的权限吧，改成临时目录为/tmp下即可。 再下为我们再看看远程主机的message日志文件确认下是否真的是通过普通用户切换的： 12Dec 3 11:36:20 linux su: (to root) test on /dev/pts/1 //由普通用户test切换为su切换为root的日志Dec 3 11:36:20 linux ansible-command: Invoked with creates=None executable=None chdir=None args=uptime removes=None NO_LOG=None shell=True warn=True //ansible执行的内容 功能实现了，最后要说的是，由于该配置文件中涉及到多台主机的用户名密码，所以该文件的安全工作一定要做好。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（十）ansible api","slug":"ansible_10","date":"2016-10-22T02:40:16.000Z","updated":"2017-01-11T01:48:55.000Z","comments":true,"path":"2016/10/22/ansible_10/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_10/","excerpt":"","text":"一、ansible apiansible api 的使用非常强大，也非常简单，只不过把模块需要使用的参数写到了脚本中，这里先来看下官方给的示例，不过同于官方的是，我这里增我将结果进行了json美化输出。 1234567891011121314[root@361way api]# cat test_api.py#!/usr/bin/env python# coding=utf-8import ansible.runnerimport jsonrunner = ansible.runner.Runner( module_name=&apos;ping&apos;, module_args=&apos;&apos;, pattern=&apos;all&apos;, forks=10 )datastructure = runner.run()data = json.dumps(datastructure,indent=4)print data 其输出结果如下： 注：如果主机是不通或失败的，结果将会输出到dark部分里，一个含有失败主机的结果类似如下： 12345678&#123; &quot;dark&quot; : &#123; &quot;web1.example.com&quot; : &quot;failure message&quot; &#125;, &quot;contacted&quot; : &#123; &quot;web2.example.com&quot; : 1 &#125;&#125; 再为看下第二个示例： 12345678910111213141516171819202122#!/usr/bin/pythonimport ansible.runnerimport sys# construct the ansible runner and execute on all hostsresults = ansible.runner.Runner( pattern=&apos;*&apos;, forks=10, module_name=&apos;command&apos;, module_args=&apos;/usr/bin/uptime&apos;,).run()if results is None: print &quot;No hosts found&quot; sys.exit(1)print &quot;UP ***********&quot;for (hostname, result) in results[&apos;contacted&apos;].items(): if not &apos;failed&apos; in result: print &quot;%s &gt;&gt;&gt; %s&quot; % (hostname, result[&apos;stdout&apos;])print &quot;FAILED *******&quot;for (hostname, result) in results[&apos;contacted&apos;].items(): if &apos;failed&apos; in result: print &quot;%s &gt;&gt;&gt; %s&quot; % (hostname, result[&apos;msg&apos;])print &quot;DOWN *********&quot;for (hostname, result) in results[&apos;dark&apos;].items(): print &quot;%s &gt;&gt;&gt; %s&quot; % (hostname, result) 上面的示例中对主机的输出结果进行了判断，并且结果的输出进行了定制化，上面执行的结果你可以和ansible all -m command -a ‘uptime’ 的结果进行下比对，看下有什么不同。 上面的示例基本上都是参照官方页面进行执行的，更多用法可以通过pydoc ansible或者通过python里的help(ansible)查看。另外在多主机执行时，可以使用async(异部)方式运行。 二、ansible_playbook apiansible_playbook api 部分在官方文档上并没有提，不过通过查看ansible模块的帮助信息可以看到其是支持的。在ansible google论坛里（需翻墙），有老外也给出里代码，其实它和执行ansible的api方式一样，只是多了个几个参数： 123456789101112131415161718import ansible.playbookfrom ansible import callbacksfrom ansible import utilsstats = callbacks.AggregateStats()playbook_cb = callbacks.PlaybookCallbacks(verbose=utils.VERBOSITY)runner_cb = callbacks.PlaybookRunnerCallbacks(stats, verbose=utils.VERBOSITY)pb = ansible.playbook.PlayBook( playbook=&quot;nseries.yml&quot;, stats=stats, callbacks=playbook_cb, runner_callbacks=runner_cb, check=True)for (play_ds, play_basedir) in zip(pb.playbook, pb.play_basedirs): import ipdb ipdb.set_trace() # Can play around here to see what&apos;s going on.pb.run() 大致看了下代码，在用api的方式执行playbook的时候，playbook，stats，callbacks，runner_callbacks这几个参数是必须的。不使用的时候会报错。 1234567891011arguments = []if playbook is None: arguments.append(&apos;playbook&apos;)if callbacks is None: arguments.append(&apos;callbacks&apos;)if runner_callbacks is None: arguments.append(&apos;runner_callbacks&apos;)if stats is None: arguments.append(&apos;stats&apos;)if arguments: raise Exception(&apos;PlayBook missing required arguments: %s&apos; % &apos;, &apos;.join(arguments)) playbook用来指定playbook的yaml文件 stats用来收集playbook执行期间的状态信息，最后会进行汇总 callbacks用来输出playbook执行的结果 runner_callbacks用来输出playbook执行期间的结果。但是它返回的结果太简单，我想让它详细点，如果用自定义callback的方法插入到mongo里面的话也行，或者是直接输出，但是我想所有task都执行完后，把每个task的详细信息输出到终端上，最后发现结果输出都是靠callbacks.py里的AggregateStats这个类，在每执行完一个task后，都会调用AggregateStats进行计算，汇总。 1234567891011121314151617181920212223242526272829303132333435363738394041[root@361way api]# cat playbook_api.py#!/usr/bin/env python# coding=utf-8import ansible.playbookfrom ansible import callbacksfrom ansible import utilsimport jsonstats = callbacks.AggregateStats()playbook_cb = callbacks.PlaybookCallbacks(verbose=utils.VERBOSITY)runner_cb = callbacks.PlaybookRunnerCallbacks(stats,verbose=utils.VERBOSITY)res=ansible.playbook.PlayBook( playbook=&apos;/etc/ansible/playbooks/user.yml&apos;, stats=stats, callbacks=playbook_cb, runner_callbacks=runner_cb ).run()data = json.dumps(res,indent=4)print data# 执行结果如下：[root@361way api]# python playbook_api.pyPLAY [create user] ************************************************************TASK: [create test &quot;&#123;&#123; user &#125;&#125;&quot;] **********************************************changed: [10.212.52.16]changed: [10.212.52.14]&#123; &quot;10.212.52.16&quot;: &#123; &quot;unreachable&quot;: 0, &quot;skipped&quot;: 0, &quot;ok&quot;: 1, &quot;changed&quot;: 1, &quot;failures&quot;: 0 &#125;, &quot;10.212.52.14&quot;: &#123; &quot;unreachable&quot;: 0, &quot;skipped&quot;: 0, &quot;ok&quot;: 1, &quot;changed&quot;: 1, &quot;failures&quot;: 0 &#125;&#125;[root@361way api]# 三、总结从上面的例子来看，感觉作用似乎有点鸡肋。多条ansible shell 指令的执行可以写成playbook 来执行，ansbile-playbook 也可以通过include 调用子playbook ，似乎API 部分用处并不大 。咋一听深感有理，不过细究一下， 1、当需要先对前一次作任务执行的结果进行处理，并将相应的结果对应的作为输入再在一次任务传入时，这里使用api 更方便； 2、需要对结果输出进行整形时，也比较api 方便； 3、playbook 之间进行调用或都playbook比较复杂时，想要理清任务之间的关系势必累显麻烦，而通过api，从上一层任务到下一层任务之间的调用关系明子。而且playbook之间可以是平行的关系。方便小的功能模块的复用。 4、方便二次开发及和其他程序之间的耦合调用－－－－目前感觉这条是最实用的。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（九）playbook进阶","slug":"ansible_09","date":"2016-10-22T02:39:16.000Z","updated":"2017-01-11T01:48:48.000Z","comments":true,"path":"2016/10/22/ansible_09/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_09/","excerpt":"","text":"到目前为止,我们只是简单的运行了几个模块.其实ansible运行更多控制去执行playbook.使用这些技术,你能够执行更加复杂的部署. 并发运行ansible默认只会创建5个进程,所以一次任务只能同时控制5台机器执行.那如果你有大量的机器需要控制,或者你希望减少进程数,那你可以采取异步执行.ansible的模块可以把task放进后台,然后轮询它.这使得在一定进程数下能让大量需要的机器同时运作起来. 使用async和poll这两个关键字便可以并行运行一个任务. async这个关键字触发ansible并行运作任务,而async的值是ansible等待运行这个任务的最大超时值,而poll就是ansible检查这个任务是否完成的频率时间. 如果你希望在整个集群里面平行的执行一下updatedb这个命令.使用下面的配置 123456789- hosts: all tasks: - name: Install mlocate yum: name=mlocate state=installed - name: Run updatedb command: /usr/bin/updatedb async: 300 poll: 10 你会发现当你使用上面的例子控制超过5台机器的时候,command.在上面yum模块会先在5台机器上跑,完成后再继续下面的机器.而上面command模块的任务会一次性在所有机器上都执行了,然后监听它的回调结果 如果你的command是控制机器开启一个进程放到后台,那就不需要检查这个任务是否完成了.你只需要继续其他的动作,最后再使用wait_for这个模块去检查之前的进程是否按预期中开启了便可.只需要把poll这个值设置为0,便可以按上面的要求配置ansible不等待job的完成. 最后,或者你还有一种需求是有一个task它是需要运行很长的时间,那你需要设置一直等待这个job完成.这个时候你把async的值设成0便可. 总结来说,大概有以下的一些场景你是需要使用到ansible的polling特性的 你有一个task需要运行很长的时间,这个task很可能会达到timeout. 你有一个任务需要在大量的机器上面运行 你有一个任务是不需要等待它完成的 当然也有一些场景是不适合使用polling特性的 你的这个任务是需要运行完后才能继续另外的任务的 你的这个任务能很快的完成 Looping在ansible你能够通过不同的输入去重复的执行同一个模块,举个例子,你需要管理几个具有相同权限的文件.你能够用一个for循环迭代一个facts或者variables去减少你的重复劳动. 使用with_items这个关键字就可以完成迭代一个列表.列表里面的每个变量都叫做item.有一些模块譬如yum,它就支持使用with_items去安装一列表的包,而不需要写好多个yum的task 下面来一个with_items的例子 1234567tasks: - name: Secure config files file: path=/etc/&#123;&#123; item &#125;&#125; mode=0600 owner=root group=root with_items: - my.cnf - shadow - fstab 除了使用items轮训,ansible还有一种方式是lookup插件.这些插件可以让ansible从外部取得数据,例如,你或许希望可以通过一种特定模式去上传你的文件. 在这个例子里面,我们会上传所有的public keys到一个目录,然后聚合它们到一个authorized_keys文件 123456789101112tasks: #1 - name: Make key directory #2 file: path=/root/.sshkeys ensure=directory mode=0700 owner=root group=root #3 - name: Upload public keys #4 copy: src=&#123;&#123;item&#125;&#125; dest=/root/.sshkeys mode=0600 owner=root group=root #5 with_fileglob: #6 - keys/*.pub #7 - name: Assemble keys into authorized_keys file #8 assemble: src=/root/.sshkeys dest=/root/.ssh/authorized_keys mode=0600 owner=root group=root #9 loop模块一般在下面的场景中使用 类似的配置模块重复了多遍 fact是一个列表 创建多个文件,然后使用assemble聚合成一个大文件 使用with_fileglob匹配特定的文件管理 条件语句有一些模块,例如copy这个模块有一些机制能跳过本次模块的运行.其实我们也可以使用自己的条件语句去配置跳过模块,这样方便你服务能够选择使用不同的包管理(apt,yum)和不同的文件系统.并且你还可以使用set_fact这个模块做成更多的差异配置 你能够使用when这个关键字去达到跳过本次模块运行的效果,when关键字后面跟着的是python的表达式,在表达式中你能够使用任何的变量或者fact,当表达式的结果返回的是false,便会跳过本次的模块 下面一段配置就说明了如何在debian和redhat系统中选择apt还是yum包管理,并且如果不是以上两个系统,会用debug模块把系统打印出来 12345678910111213---- name: Install VIM hosts: all tasks: - name: Install VIM via yum yum: name=vim-enhanced state=installed when: ansible_os_family == &quot;RedHat&quot; - name: Install VIM via apt apt: name=vim state=installed when: ansible_os_family == &quot;Debian&quot; - name: Unexpected OS family debug: msg=&quot;OS Family &#123;&#123; ansible_os_family &#125;&#125; is not supported&quot; fail=yes when: not ansible_os_family == &quot;RedHat&quot; or ansible_os_family == &quot;Debian&quot; 条件语句还有一种用法,它还可以让你当达到一定的条件的时候暂停下来,等待你的输入确认.一般情况下,当ansible遭遇到error时,它会直接结束运行.那其实你可以当遭遇到不是预期的情况的时候给使用pause模块,这样可以让用户自己决定是否继续运行任务 123name: pause for unexpected conditionspause: prompt=&quot;Unexpected OS&quot;when: ansible_os_family != &quot;RedHat&quot; 下面一些情景建议你使用条件语句做跳过动作 job里面有不同操作系统的机器 提示用户,然后再执行操作请求 提高性能,避免运行一个需要执行一段时间模块,而且你知道这个模块不会返回changed task委托默认ansible的所有task是在我们的配置的管理机器上面运行的,当在一个独立的群集里面配置,那是适用的.而有一些情况是,某些任务运行的状态是需要传递给其他机器的,在同一个任务你需要在其他机器上执行,这时候你就许多要用task委托 使用delegate_to关键字便可以配置任务在其他机器上执行.其他模块还是在所有配置的管理机器上运行的,当到了这个关键字的任务就是使用委托的机器上运行.而facts还是适用于当前的host,下面我们演示一个例子,使用get_url模块去下载一个web集群的配置 1234567--- - name: Fetch configuration from all webservers￼￼￼￼hosts: webservers tasks: - name: Get config get_url: dest=configs/&#123;&#123; ansible_hostname &#125;&#125; force=yes url=http://&#123;&#123; ansible_hostname &#125;&#125;/diagnostic/config delegate_to: localhost 如果需要委托loaclhost执行任务,这里提供一个快捷的方式,只要使用local_action作为task的key便行.我们尝试使用这种方式来配置上面的例子,会更加简洁. 123456--- #1 - name: Fetch configuration from all webservers #2 hosts: webservers #3 tasks: #4￼ - name: Get config local_action: get_url dest=configs/&#123;&#123; ansible_hostname &#125;&#125;.cfg url=http://&#123;&#123; ansible_hostname &#125;&#125;/diagnostic/config 委托不限于localhost,可以在你的inventory里面的任何host.下列一些场景适用使用委托 部署之前你希望从负载均衡里面把host移除 更改你的server时候更改dns的指向 创建一个iSCSI卷存储设备 使用一个外部服务器去检测一下服务 额外的变量大家应该在之前的章节的例子里面有看到group_names这个变量.这个是ansible提供的一个很神奇变量.直至写本书的时候,有7个这样的变量,我会在下面的章节介绍 a.hostvars变量hostvars允许你在当前的任务中应用所有host的变量.当setup模块没有运行的时候,只有这些变量将是可用.例如你配置 ${hostvars.hostname.fact}可以访问其他复杂的变量.例如你可以配置${hostvars.ns1.ansible_ distribution}得到ns1这个server的linux发型版本. 下面的例子设置了一个dns_master变量,这是ns1 server的ip.然后这个变量能够在所有机器上调用 1234567891011121314---- name: Setup DNS Servers hosts: allnameservers tasks: - name: Install BIND yum: name=named state=installed- name: Setup Slaves #7 hosts: slavenamesservers #8 tasks: #9 - name: Get the masters IP set_fact: dns_master=&quot;&#123;&#123; hostvars.ns1.ansible_default_ipv4.address &#125;&#125;&quot; - name: Configure BIND template: dest=/etc/named.conf src/templates/named.conf.j2 b.groups变量groups变量是inventory里面的group分组列表.这个是一个非常强大的工具,能够让你迭代你配置的所有的hosts.看下面的例子. 12345678910111213141516---- name: Configure the database hosts: dbservers user: root tasks: - name: Install mysql yum: name=&#123;&#123; item &#125;&#125; state=installed￼￼ with_items: - mysql-server - MySQL-python - name: Start mysql service: name=mysqld state=started enabled=true - name: Create a user for all app servers with_items: groups.appservers mysql_user: name=kate password=test host=&#123;&#123; hostvars[item].ansible_eth0.ipv4.address &#125;&#125; state=present groups变量实际不是你的hosts变量的列表.它只是你hosts的name的列表.如果你需要调用host里面的变量还需要配合hostvars使用 下面的例子配置创建known_hosts文件 playbook配置 12345678--- hosts: all tasks: - name: Setup known hosts hosts: all tasks: - name: Create known_hosts template: src=templates/known_hosts.j2 dest=/etc/ssh/ssh_known_hosts owner=root group=root mode=0644 template模板 1234&#123;% for host in groups[&apos;all&apos;] %&#125;&#123;&#123; hostvars[host][&apos;ansible_hostname&apos;] &#125;&#125;&#123;&#123; hostvars[host][&apos;ansible_ssh_host_key_rsa_public&apos;] &#125;&#125;&#123;% endfor %&#125; c.group_names变量group_names是当前host所属的组的列表.这可以用于在条件语句中调用成员的group关系,或者用于debugging.通常来说这变量大部分用于跳过一些task或者在模板中用于条件语句的变量.在下面的例子中,如果你有两套sshd的配置文件,一套用于安全性更加严谨的,一个安全性普通的.然后我们根据group名来配分host到哪个sshd配置下. 123456789101112---- name: Setup SSH hosts: sshservers tasks: - name: For secure machines set_fact: sshconfig=files/ssh/sshd_config_secure when: &quot;&apos;secure&apos; in group_names&quot; - name: For non-secure machines set_fact: sshconfig=files/ssh/sshd_config_default when: &quot;&apos;secure&apos; not in group_names&quot; - name: Copy over the config copy: src=&#123;&#123; sshconfig &#125;&#125; dest=/tmp/sshd_config d.inventory_hostname变量inventory_hostname是机器的hostname,当你没有使用setup模块,或者由于各种原因导致setup的变量是错误的,你可以选择使用这个变量.此变量可以帮助你初始化你的机器和改变hostname e.inventory_hostname_shortinventory_hostname_short类似与上面的inventory_hostname变量,只是它是截取第一个句点的前面的字符,例如hostname是host.example.com,就会只截取到host f.inventory_dir此变量是inventory文件的路径,包括目录与文件名 g.inventory_file类似上面的变量,只是它只有文件名 使用变量来查找文件所有的模块都可以把变量作为参数的一部分,通过使用””符号扩起来.譬如变量test就是””.这样你就可以通过变量加载特定的文件.例如,你希望根据不同的机器architecture选择不同的NRPE(nagios的客户端)配置文件,那可以像这样的配置 1234567---- name: Configure NRPE for the right architecture hosts: ansibletest user: root tasks: - name: Copy in the correct NRPE config file copy: src=files/nrpe.&#123;&#123; ansible_architecture &#125;&#125;.conf dest=/etc/nagios/nrpe.cfg 在copy和tempalate模块里面,你能够使用ansible去查找一组的文件.然后默认使用第一个文件.这能够让你达到效果是,当第一个文件不存在时,会查找第二个文件,如此类推知道最后一个文件还不存在就报fail.使用first_available_file这个关键字便可以到上述效果. 1234567891011---- name: Install an Apache config file hosts: ansibletest user: root tasks: - name: Get the best match for the machine copy: dest=/etc/apache.conf src=&#123;&#123; item &#125;&#125; first_available_file: - files/apache/&#123;&#123; ansible_os_family &#125;&#125;-&#123;&#123; ansible_architecture &#125;&#125;.cfg - files/apache/default-&#123;&#123; ansible_architecture &#125;&#125;.cfg - files/apache/default.cfg 环境变量unix命令经常需要依赖环境变量,例如C makefiles,installers,和aws cli工具.很幸运,ansible很容易实现,譬如你现在需要控制远程的机器一个文件到s3,那你许多要配置aws的access key.下面我们的例子演示,安装pip,用pip安装aws cli,并且通过cli上传文件到s3 12345678910111213141516---- name: Upload a remote file via S3 hosts: ansibletest user: root tasks: - name: Setup EPEL command: rpm -ivh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm creates=/etc/yum.repos.d/epel.repo - name: Install pip yum: name=python-pip state=installed - name: Install the AWS tools pip: name=awscli state=present - name: Upload the file shell: aws s3 put-object --bucket=my-test-bucket --key=&#123;&#123; ansible_hostname &#125;&#125;/fstab --body=/etc/fstab --region=eu-west-1 environment: AWS_ACCESS_KEY_ID: XXXXXXXXXXXXXXXXXXX AWS_SECRET_ACCESS_KEY: XXXXXXXXXXXXXXXXXXXXX 一些模块例如get_url,yum,和apt是需要使用环境变量配置proxy的.下面一些场景也是需要配置环境变量的 运行application installers 当运行shell的时候需要添加一些额外的的变量在path里 需要load的一些库不在系统的library路径中 在运行模块时使用LD_PRELOAD hack External data lookupsansible在0.9版本开始引进了lookup插件,这些插件运行ansible在外围获取数据.ansible已经提供了几个插件,但它还是支持自己编写插件.这真的让你使用ansible配置更加伸缩自如 lookup是在master机器运行的python程序.下面一个例子是使用lookup插件获取环境变量里面的http_proxy,然后配置在远端机器,确保远端机器使用相同的proxy下载文件 12345678--- #1- name: Downloads a file using the same proxy as the controlling machine hosts: all tasks: - name: Download file get_url: dest=/var/tmp/file.tar.gz url=http://server/file.tar.gz environment: http_proxy: &quot;&#123;&#123; lookup(&apos;env&apos;, &apos;http_proxy&apos;) &#125;&#125;&quot; 使用with_*能够使用lookup插件迭代出特别的东西.您可以使用任何这样的插件,但最好是返回一个列表.下面的例子让你自动注册webapp,使用下面的例子会创建出虚拟机并配置它 12345678910---- name: Registers the app server farm hosts: localhost connection: local vars: hostcount: 5 tasks: - name: Register the webapp farm local_action: add_host name=&#123;&#123; item &#125;&#125; groupname=webapp with_sequence: start=1 end=&#123;&#123; hostcount &#125;&#125; format=webapp%02x 在下面的场景,lookup非常有用 复制整个目录的apache配置到conf.d 使用环境变量调整playbook的运行 从DNS TXT记录中获取配置 获取一个命令的输出到一个变量中 保存结果几乎所有的模块都是会outputs一些东西,甚至debug模块也会.大多数我们会使用的结果变量是changed.这个changed变量决定了是否要直接handlers和输出的颜色是什么.然而,结果变量还有其他的用途,譬如我需要保存我的结果变量,然后咋我的playbook的其他地方给使用.在下面的例子我们创建了一个/tmp目录,然后在后面我们创建一个/tmp/subtmp使用和前面目录一样的权限 12345678910---- name: Using register hosts: ansibletest user: root tasks: - name: Get /tmp info file: dest=/tmp state=directory register: tmp - name: Set mode on /var/tmp file: dest=/tmp/subtmp mode=&#123;&#123; tmp.mode &#125;&#125; state=directory 一些模块,例如上面的file模块,是能够获取到一些简单的信息.结合register这个功能,可以让你在playbook里面检查你的环境和计算如何进行 register对于数多场景是很有用的 在一台远端的服务器获取一个目录下的一列表的文件,然后下载这些文件 在handler执行之前,发现前面一个task发生了changed,然后执行一个指定的task 获取远端服务器的ssh key的内容,构建出known_hosts文件 debugging playbook有好几种方法去debug我们的playbook.ansible有verbose模式和debug模式,也可以使用例如fetch和get_url模块来协助debug.当你想学习怎样使用一些模块时,这些debugging技术能够帮助你. a.debug模块debug模块使用很简单.它具有两个参数,msg和fail.msg就是打印出来的信息,而当fail参数设置为yes时,会发送失败通知给ansible,然后ansible会停止运行任务. 在下面的例子,配置了使用debug模块去显示远端机器所有的network interface. 12345678910---- name: Demonstrate the debug module hosts: ansibletest user: root vars: hostcount: 5 tasks: - name: Print interface debug: msg=&quot;&#123;&#123; item &#125;&#125;&quot; with_items: ansible_interfaces 运行上面的配置会出现这样的输出 12345678PLAY [Demonstrate the debug module] *********************************GATHERING FACTS *****************************************************ok: [ansibletest]TASK: [Print IP address] ********************************************ok: [ansibletest] =&gt; (item=lo) =&gt; &#123;&quot;item&quot;: &quot;lo&quot;, &quot;msg&quot;: &quot;lo&quot;&#125;ok: [ansibletest] =&gt; (item=eth0) =&gt; &#123;&quot;item&quot;: &quot;eth0&quot;, &quot;msg&quot;: &quot;eth0&quot;&#125;PLAY RECAP **********************************************************ansibletest : ok=2 changed=0 unreachable=0 failed=0 如你说见,debug模块可以让你很容易看到在playbook运行期间一些变量 b.verbose模式另外的debug选择是verbose模式.当运行verbose模式时,会打印出所有模块运行后的变量.这对于你要使用register功能时候很重要.只需要在执行playbook命令时加上参数–verbose便可以.ansible-playbook –verbose playbook.yml c.check模式除了verbose模式外,ansible还提供了check模式和diff模式.只需要执行playbook时添加参数–check和–diff.check模式运行时,ansible不会真正控制远程机器发生变更.这能够让你获得这次playbook任务中,将会发生changed事件的列表. 很重要的一点是check模式不是完美的.有一些模块是会跳过check模式的.尤其明显的限制是在运行command和shell模块 在diff模式下,当文件发现更变,会打印出变更文件的变更部分.配合check模式使用效果更好 d.pause模块另外一个debug技巧是使用pause模块,它可以让你需要在某个地方需要检查远程机器的配置的时候暂停playbook的执行.这样可以让先观察一下运行到这里为止的效果,再判断是否继续运行下去. 总结在这个章节我们更加深入探索了编写playbook的一些细节.现在你应该可以使用一些ansible的特性.例如delegation,looping,conditionals,和fact,registration等等,让你能够更容易的编写和维护你的playbook.我们也看到了如何获取其他host的信息,如何配置环境变量,如何从外围获取到数据.最后我们展示了一些debug技巧,让playbook能按你的预期来执行. 下一章节,我们会学习如何在大规模环境中使用ansible,也会讲到一些方法让你在一些需要运行很久的任务中提高你的性能.我们也会介绍一些特性让你的playbook如何更加可维护,更加解藕,让它们按目的分配到不同的地方.","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（八）ansible-playbook简单使用","slug":"ansible_08","date":"2016-10-22T02:38:16.000Z","updated":"2017-01-11T01:39:57.000Z","comments":true,"path":"2016/10/22/ansible_08/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_08/","excerpt":"","text":"playbook通过ansible-playbook命令使用,它的参数和ansible命令类似,如参数-k(–ask-pass) 和 -K (–ask-sudo) 来询问ssh密码和sudo密码,-u指定用户,这些指令也可以通过规定的单元写在playbook 。ansible-playbook的简单使用方法: ansible-playbook example-play.yml 。 一、一个简单的示例下面给出一个简单的ansible-playbook示例，了解下其构成。 12345678910# cat user.yml- name: create user hosts: all user: root gather_facts: false vars: - user: &quot;test&quot; tasks: - name: create user user: name=&quot;&#123;&#123; user &#125;&#125;&quot; 上面的playbook 实现的功能是新增一个用户： name参数对该playbook实现的功能做一个概述，后面执行过程中，会打印 name变量的值 ； hosts参数指定了对哪些主机进行参作； user参数指定了使用什么用户登录远程主机操作； gather_facts参数指定了在以下任务部分执行前，是否先执行setup模块获取主机相关信息，这在后面的task会使用到setup获取的信息时用到； vars参数，指定了变量，这里指字一个user变量，其值为test ，需要注意的是，变量值一定要用引号引住； task指定了一个任务，其下面的name参数同样是对任务的描述，在执行过程中会打印出来。user提定了调用user模块，name是user模块里的一个参数，而增加的用户名字调用了上面user变量的值。具体执行结果如下： 12345678910[root@361way playbooks]# ansible-playbook user.ymlPLAY [create user] ************************************************************TASK: [create user ] **********************************************changed: [10.212.52.252]changed: [10.212.52.14]changed: [10.212.52.16]PLAY RECAP ********************************************************************10.212.52.14 : ok=1 changed=1 unreachable=0 failed=010.212.52.16 : ok=1 changed=1 unreachable=0 failed=010.212.52.252 : ok=1 changed=1 unreachable=0 failed=0 同样，如果想实现把这个新增的用户删除，只需将该playbook文件的最后一行替换为如下行再执行相应的playbook即可： 1user: name=&quot;&#123;&#123; user &#125;&#125;&quot; state=absent remove=yes 二、一键修补bash shellcode示例再给出一个稍微复杂的示例，通过ansible-playbook实现对N台主机同时修补bash shellcode 漏洞。需要注意的是，可能现网主机分布着不同的系统版本。这里假设现网同时存在centos5和6版本，具体playbook内容如下： 1234567891011# cat update_bash.yml- hosts: all remote_user: root gather_facts: True tasks: - name: update bash in redhat 6 version yum: name=http://mirrors.aliyun.com/centos/6.6/os/x86_64/Packages/bash-4.1.2-29.el6.x86_64.rpm.rpm state=present when: ansible_os_family == &quot;RedHat&quot; and ansible_distribution_version|int &gt;=6 - name: update bash in redhat 5 version yum: name=http://mirrors.hustunique.com/centos/5/updates/x86_64/RPMS/bash-3.2-33.el5.1.x86_64.rpm state=present when: ansible_os_family == &quot;RedHat&quot; and ansible_distribution_version|int &lt;=5 上面使用了when语句，同时也开启了gather_facts setup模块，这里的ansible_os_family变量和ansible_distribution_version变量就是直接使用的setup模块获取的信息。 如果有大量主机，就在运行的时候加上-f然后选择一个合适的并发主机数量即可，我这里使用了这个，很快的就升级完成bash了。 三、playbook的构成playbook是由一个或多个“play”组成的列表。play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中即可以让它们联同起来按事先编排的机制同唱一台大戏。其主要有以下四部分构成 12345playbooks组成： Target section： 定义将要执行 playbook 的远程主机组 Variable section： 定义 playbook 运行时需要使用的变量 Task section： 定义将要在远程主机上执行的任务列表 Handler section： 定义 task 执行完成以后需要调用的任务 而其对应的目录层为五个，如下： 123456一般所需的目录层有：(视情况可变化) vars 变量层 tasks 任务层 handlers 触发条件 files 文件 template 模板 下面介绍下构成playbook 的四层结构。 1、Hosts和Usersplaybook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务。 hosts 用于指定要执行指定任务的主机其可以是一个或多个由冒号分隔主机组。 remote_user 则用于指定远程主机上的执行任务的用户。不过remote_user也可用于各task中。也可以通过指定其通过sudo的方式在远程主机上执行任务其可用于play全局或某任务。此外甚至可以在sudo时使用sudo_user指定sudo时切换的用户。 示例： 12345- hosts: webnodes tasks: - name: test ping connection: remote_user: test sudo: yes 2、任务列表和actionplay的主体部分是task list。 task list中的各任务按次序逐个在hosts中指定的所有主机上执行即在所有主机上完成第一个任务后再开始第二个。在运行自下而下某playbook时如果中途发生错误所有已执行任务都将回滚因此在更正playbook后重新执行一次即可。 task的目的是使用指定的参数执行模块而在模块参数中可以使用变量。模块执行是幂等的这意味着多次执行是安全的因为其结果均一致。每个task都应该有其name用于playbook的执行结果输出建议其内容尽可能清晰地描述任务执行步骤。如果未提供name则action的结果将用于输出。 定义task的可以使用“action: module options”或“module: options”的格式推荐使用后者以实现向后兼容。如果action一行的内容过多也中使用在行首使用几个空白字符进行换行。 123456789101112131415tasks: - name: make sure apache is running service: name=httpd state=running在众多模块中只有command和shell模块仅需要给定一个列表而无需使用“key=value”格式例如tasks: - name: disable selinux command: /sbin/setenforce 0 如果命令或脚本的退出码不为零可以使用如下方式替代tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true或者使用ignore_errors来忽略错误信息tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True 3、handlers用于当关注的资源发生变化时采取一定的操作。“notify”这个action可用于在每个play的最后被触发这样可以避免多次有改变发生时每次都执行指定的操作取而代之仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler也即notify中调用 handler中定义的操作。 注意：在 notify 中定义内容一定要和tasks中定义的 - name 内容一样，这样才能达到触发的效果，否则会不生效。 1234567891011- name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: - restart memcached - restart apachehandler是task列表这些task与前述的task并没有本质上的不同。handlers: - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted 4、tagstags用于让用户选择运行或略过playbook中的部分代码。ansible具有幂等性因此会自动跳过没有变化的部分即便如此有些代码为测试其确实没有发生变化的时间依然会非常地长。此时如果确信其没有变化就可以通过tags跳过此些代码片断。 5、示例下面再给出一个安装httpd web服务的示例： 1234567891011121314151617181920212223242526# cat /etc/ansible/playbook/install_web.yml- hosts: webservers remote_user: root gather_fasks: False vars: packages: httpd tasks: - name: Install httpd yum: name=&#123;&#123; packages &#125;&#125; state=present - name: Cofiguration httpd copy: src=/root/httpd.conf dest=/etc/httpd/conf/httpd.conf tags: httpd_conf notify: - restart httpd - name: Start httpd service: name=httpd state=started enabled=no tags: start - name:Add centos user user: name=&#123;&#123; item &#125;&#125; state=absent tags: adduser with_items: - centos - admin handlers: - name: restart httpd service: name=httpd state=restart 注：上面的代码没有考虑ubuntu平台，仅仅考虑centos/redhat平台。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（七）常用模块","slug":"ansible_07","date":"2016-10-22T02:37:16.000Z","updated":"2017-01-13T06:27:59.000Z","comments":true,"path":"2016/10/22/ansible_07/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_07/","excerpt":"","text":"ansible常用模块用法官方页面。这里从官方分类的模块里选择最常用的一些模块进行介绍（commands模块上一篇已经介绍，这里不再提）。 ansible 默认提供了很多模块来供我们使用。在 Linux 中，我们可以通过 ansible-doc -l 命令查看到当前 ansible 都支持哪些模块，通过 ansible-doc -s 模块名 又可以查看该模块有哪些参数可以使用。模块按功能分类为：云模块、命令模块、数据库模块、文件模块、资产模块、消息模块、监控模块、网络模块、通知模块、包管理模块、源码控制模块、系统模块、单元模块、web设施模块、windows模块 ，具体可以参看官方页面。这里从官方分类的模块里选择最常用的一些模块进行介绍。 下面介绍比较常用的模块：一、ping模块测试主机是否是通的，用法很简单，不涉及参数： 12345[root@plpcm ~]# ansible 10.212.52.252 -m ping10.212.52.252 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; 二、setup模块setup模块，主要用于获取主机信息，在playbooks里经常会用到的一个参数gather_facts就与该模块相关。setup模块下经常使用的一个参数是filter参数，具体使用示例如下： 123ansible test -m setup -a &apos;filter=ansible_*_mb&apos; //查看主机内存信息ansible test -m setup -a &apos;filter=ansible_eth[0-2]&apos; //查看地接口为eth0-2的网卡信息ansible test -m setup --tree /tmp/facts //将所有主机的信息输入到/tmp/facts目录下，每台主机的信息输入到主机名文件中（/etc/ansible/hosts里的主机名） 三、file模块file模块主要用于远程主机上的文件操作，file模块包含如下选项： force：需要在两种情况下强制创建软链接，一种是源文件不存在但之后会建立的情况下；另一种是目标软链接已存在,需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no group：定义文件/目录的属组 mode：定义文件/目录的权限 owner：定义文件/目录的属主 path：必选项，定义文件/目录的路径 recurse：递归的设置文件的属性，只对目录有效 src：要被链接的源文件的路径，只应用于state=link的情况 dest：被链接到的路径，只应用于state=link的情况 state： directory：如果目录不存在，创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 使用示例： 123 ansible test -m file -a &quot;src=/etc/fstab dest=/tmp/fstab state=link&quot; ansible test -m file -a &quot;path=/tmp/fstab state=absent&quot; ansible test -m file -a &quot;path=/tmp/test state=touch&quot; 四、copy模块复制文件到远程主机，copy模块包含如下选项： backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no content：用于替代”src”,可以直接设定指定文件的值 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 directory_mode：递归的设定目录的权限，默认为系统默认权限 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes others：所有的file模块里的选项都可以在这里使用 src：要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用”/“来结尾，则只复制目录里的内容，如果没有使用”/“来结尾，则包含目录在内的整个内容全部复制，类似于rsync。 validate ：The validation command to run before copying into place. The path to the file to validate is passed in via ‘%s’ which must be present as in the visudo example below. 示例如下： 123ansible test -m copy -a &quot;src=/srv/myfiles/foo.conf dest=/etc/foo.conf owner=foo group=foo mode=0644&quot;ansible test -m copy -a &quot;src=/mine/ntp.conf dest=/etc/ntp.conf owner=root group=root mode=644 backup=yes&quot;ansible test -m copy -a &quot;src=/mine/sudoers dest=/etc/sudoers validate=&apos;visudo -cf %s&apos;&quot; 五、service模块用于管理服务该模块包含如下选项： arguments：给命令行提供一些选项 enabled：是否开机启动 yes|no name：必选项，服务名称 pattern：定义一个模式，如果通过status指令来查看服务的状态时，没有响应，就会通过ps指令在进程中根据该模式进行查找，如果匹配到，则认为该服务依然在运行 runlevel：运行级别 sleep：如果执行了restarted，在则stop和start之间沉睡几秒钟 state：对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） 使用示例： 123ansible test -m service -a &quot;name=httpd state=started enabled=yes&quot;asnible test -m service -a &quot;name=foo pattern=/usr/bin/foo state=started&quot;ansible test -m service -a &quot;name=network state=restarted args=eth0&quot; 六、cron模块用于管理计划任务包含如下选项： backup：对远程主机上的原任务计划内容修改之前做备份 cron_file：如果指定该选项，则用该文件替换远程主机上的cron.d目录下的用户的任务计划 day：日（1-31，，/2,……） hour：小时（0-23，，/2，……） minute：分钟（0-59，，/2，……） month：月（1-12，，/2，……） weekday：周（0-7，*，……） job：要执行的任务，依赖于state=present name：该任务的描述 special_time：指定什么时候执行，参数：reboot,yearly,annually,monthly,weekly,daily,hourly state：确认该任务计划是创建还是删除 user：以哪个用户的身份执行 示例： 12345ansible test -m cron -a &apos;name=&quot;a job for reboot&quot; special_time=reboot job=&quot;/some/job.sh&quot;&apos;ansible test -m cron -a &apos;name=&quot;yum autoupdate&quot; weekday=&quot;2&quot; minute=0 hour=12 user=&quot;rootansible test -m cron -a &apos;backup=&quot;True&quot; name=&quot;test&quot; minute=&quot;0&quot; hour=&quot;5,2&quot; job=&quot;ls -alh &gt; /dev/null&quot;&apos;ansilbe test -m cron -a &apos;cron_file=ansible_yum-autoupdate state=absent&apos;ansible test -m cron -a &apos;name=&quot;custom job&quot; minute=/3 hour= day=* month=* weekday=* job=&quot;/usr/sbin/ntpdate 172.16.254.139&quot;&apos; 七、yum模块使用yum包管理器来管理软件包，其选项有： config_file：yum的配置文件 disable_gpg_check：关闭gpg_check disablerepo：不启用某个源 enablerepo：启用某个源 name：要进行操作的软件包的名字，也可以传递一个url或者一个本地的rpm包的路径 state：状态（present，absent，latest） 示例如下： 123ansible test -m yum -a &apos;name=httpd state=latest&apos;ansible test -m yum -a &apos;name=&quot;@Development tools&quot; state=present&apos;ansible test -m yum -a &apos;name=http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm state=present&apos; 八、user模块与group模块user模块是请求的是useradd, userdel, usermod三个指令，goup模块请求的是groupadd, groupdel, groupmod 三个指令。 1、user模块 home：指定用户的家目录，需要与createhome配合使用 groups：指定用户的属组 uid：指定用的uid password：指定用户的密码 name：指定用户名 createhome：是否创建家目录 yes|no system：是否为系统用户 remove：当state=absent时，remove=yes则表示连同家目录一起删除，等价于userdel -r state：是创建还是删除|present创建|absent删除 shell：指定用户的shell环境 1234567使用示例： user: name=johnd comment=&quot;John Doe&quot; uid=1040 group=admin user: name=james shell=/bin/bash groups=admins,developers append=yes user: name=johnd state=absent remove=yes user: name=james18 shell=/bin/zsh groups=developers expires=1422403387 user: name=test generate_ssh_key=yes ssh_key_bits=2048 ssh_key_file=.ssh/id_rsa #生成密钥时，只会生成公钥文件和私钥文件，和直接使用ssh-keygen指令效果相同，不会生成authorized_keys文件。 注：指定password参数时，不能使用明文密码，因为后面这一串密码会被直接传送到被管理主机的/etc/shadow文件中，所以需要先将密码字符串进行加密处理。然后将得到的字符串放到password中即可。 1234echo &quot;123456&quot; | openssl passwd -1 -salt $(&lt; /dev/urandom tr -dc &apos;[:alnum:]&apos; | head -c 32) -stdin$1$4P4PlFuE$ur9ObJiT5iHNrb9QnjaIB0#使用上面的密码创建用户ansible all -m user -a &apos;name=foo password=&quot;$1$4P4PlFuE$ur9ObJiT5iHNrb9QnjaIB0&quot;&apos; 不同的发行版默认使用的加密方式可能会有区别，具体可以查看/etc/login.defs文件确认，centos 6.5版本使用的是SHA512加密算法。 2、group示例创建一个组名为nolinux，gid为2014的组 1ansible test -m group -a &apos;gid=2014 name=somegroup state=present&apos; 九、synchronize模块使用rsync同步文件，其参数如下： archive: 归档，相当于同时开启recursive(递归)、links、perms、times、owner、group、-D选项都为yes ，默认该项为开启 checksum: 跳过检测sum值，默认关闭 compress:是否开启压缩 copy_links：复制链接文件，默认为no ，注意后面还有一个links参数 delete: 删除不存在的文件，默认no dest：目录路径 dest_port：默认目录主机上的端口 ，默认是22，走的ssh协议 rsync_path # 指定 rsync 命令来在远程服务器上运行。这个参考rsync命令的–rsync-path参数，–rsync-path=PATH # 指定远程服务器上的rsync命令所在路径信息 rsync_timeout # 指定 rsync 操作的 IP 超时时间，和rsync命令的 –timeout 参数效 dirs：传速目录不进行递归，默认为no，即进行目录递归 rsync_opts：rsync参数部分 –exclude=.Git 忽略同步.git结尾的文件 set_remote_user：主要用于/etc/ansible/hosts中定义或默认使用的用户与rsync使用的用户不同的情况 mode: push或pull 模块，push模的话，一般用于从本机向远程主机上传文件，pull 模式用于从远程主机上取文件 使用示例： 1234 src=some/relative/path dest=/some/absolute/path rsync_path=&quot;sudo rsync&quot; src=some/relative/path dest=/some/absolute/path archive=no links=yes src=some/relative/path dest=/some/absolute/path checksum=yes times=no src=/tmp/helloworld dest=/var/www/helloword rsync_opts=--no-motd,--exclude=.git mode=pull 十、filesystem模块在块设备上创建文件系统选项： dev：目标块设备 force：在一个已有文件系统 的设备上强制创建 fstype：文件系统的类型 opts：传递给mkfs命令的选项 示例： ansible test -m filesystem -a ‘fstype=ext2 dev=/dev/sdb1 force=yes’ ansible test -m filesystem -a ‘fstype=ext4 dev=/dev/sdb1 opts=”-cc”‘ 十一、mount模块配置挂载点选项： dump fstype：必选项，挂载文件的类型 name：必选项，挂载点 opts：传递给mount命令的参数 src：必选项，要挂载的文件 state：必选项 present：只处理fstab中的配置 absent：删除挂载点 mounted：自动创建挂载点并挂载之 umounted：卸载 示例： 12345678 name=/mnt/dvd src=/dev/sr0 fstype=iso9660 opts=ro state=present name=/srv/disk src=&apos;LABEL=SOME_LABEL&apos; state=present name=/home src=&apos;UUID=b3e48f45-f933-4c8e-a700-22a159ec9077&apos; opts=noatime state=present ansible test -a &apos;dd if=/dev/zero of=/disk.img bs=4k count=1024&apos; ansible test -a &apos;losetup /dev/loop0 /disk.img&apos; ansible test -m filesystem &apos;fstype=ext4 force=yes opts=-F dev=/dev/loop0&apos; ansible test -m mount &apos;name=/mnt src=/dev/loop0 fstype=ext4 state=mounted opts=rw&apos; 十二、get_url 模块该模块主要用于从http、ftp、https服务器上下载文件（类似于wget），主要有如下选项： sha256sum：下载完成后进行sha256 check； timeout：下载超时时间，默认10s url：下载的URL url_password、url_username：主要用于需要用户名密码进行验证的情况 use_proxy：是事使用代理，代理需事先在环境变更中定义 示例： 12get_url: url=http://example.com/path/file.conf dest=/etc/foo.conf mode=0440get_url: url=http://example.com/path/file.conf dest=/etc/foo.conf sha256sum=b5bb9d8014a0f9b1d61e21e796d78dccdf1352f23cd32812f4850b878ae4944c 十三、unarchive模块用于解压文件，模块包含如下选项： copy：在解压文件之前，是否先将文件复制到远程主机，默认为yes。若为no，则要求目标主机上压缩包必须存在。 creates：指定一个文件名，当该文件存在时，则解压指令不执行 dest：远程主机上的一个路径，即文件解压的路径 grop：解压后的目录或文件的属组 list_files：如果为yes，则会列出压缩包里的文件，默认为no，2.0版本新增的选项 mode：解决后文件的权限 src：如果copy为yes，则需要指定压缩文件的源路径 owner：解压后文件或目录的属主 示例如下： 123- unarchive: src=foo.tgz dest=/var/lib/foo- unarchive: src=/tmp/foo.zip dest=/usr/local/bin copy=no- unarchive: src=https://example.com/example.zip dest=/usr/local/bin copy=no 十四、script模块：脚步在主控端，但需要在客户机上执行，可以用script模块，命令如下： 命令：ansible test -m script -a &apos;/root/local.sh&apos; 请注意，你主控端/root/下必须有local.sh脚本。 十五、shell模块： 需要执行客户机上的脚本，可以用shell模块，命令如下： ansible webservers -m shell -a ‘/root/run.sh’ 十六、command模块： 在远程主机上执行命令 相关选项如下： creates：一个文件名，当该文件存在，则该命令不执行 free_form：要执行的linux指令 chdir：在执行指令之前，先切换到该目录 removes：一个文件名，当该文件不存在，则该选项不执行 executable：切换shell来执行指令，该执行路径必须是一个绝对路径 示例： ansible test -m command -a “free -m” 十七、raw模块：123ansible-doc raw&gt; RAW Executes a low-down and dirty SSH command, not going through the module subsystem............ 第一句就说明了问题，raw模块是靠底层ssh的通讯，不依靠python的模块，所以如果碰到低版本的系统，如果command和shell模块无法使用，可以先用这条命令安装完需要的包。 目的：在test节点上运行hostname命令 命令：ansible test -m raw-a &apos;hostname|tee&apos; 模块部分就先介绍到这里吧，官方提供的可能用到模块有git、svn版本控制模块，sysctl 、authorized_key_module系统模块，apt、zypper、pip、gem包管理模块，find、template文件模块，mysql_db、redis数据库模块，url 网络模块等。具体可以参看官方手册模块部分。 更多模块可以参考：ansible-doc –l ansible test -m stat -a “path=/etc/passwd”","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（六）Ad-hoc与commands模块","slug":"ansible_06","date":"2016-10-22T02:35:16.000Z","updated":"2017-01-11T01:39:37.000Z","comments":true,"path":"2016/10/22/ansible_06/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_06/","excerpt":"","text":"一、Ad-hoc1、直接执行这里还是先来一个上几篇幅经常用到的一个例子： 1[root@361way ~]# ansible 10.212.52.252 -a &apos;uptime&apos; -kSSH password:10.212.52.252 | success | rc=0 &gt;&gt; 10:10am up 27 days 19:33, 2 users, load average: 0.39, 0.34, 0.33 一个ad-hoc命令的执行，需要按以下格式进行执行： 1ansible 主机或组 -m 模块名 -a &apos;模块参数&apos; ansible参数 主机和组，是在/etc/ansible/hosts 里进行指定的部分，当然动态Inventory 使用的是脚本从外部应用里获取的主机，这部分具体可以参考ansible小结（五）Dynamic Inventory ； 模块名，可以通过ansible-doc -l 查看目前安装的模块，默认不指定时，使用的是command模块，具体可以查看/etc/ansible/ansible.cfg 的“#module_name = command ” 部分，默认模块可以在该配置文件中进行修改； 模块参数，可以通过 “ansible-doc 模块名” 查看具体的用法及后面的参数； ansible参数，可以通过ansible命令的帮忙信息里查看到，这里有很多参数可以供选择，如是否需要输入密码、是否sudo等。 2、后台执行当命令执行时间比较长时，也可以放到后台执行，这里会用到-B、-P参数，如下： 1ansible all -B 3600 -a &quot;/usr/bin/long_running_operation --do-stuff&quot; \\\\后台执行命令 3600s，-B 表示后台执行的时间ansible all -m async_status -a &quot;jid=123456789&quot; \\\\检查任务的状态ansible all -B 1800 -P 60 -a &quot;/usr/bin/long_running_operation --do-stuff&quot; \\\\后台执行命令最大时间是 1800s 即 30 分钟，-P 每 60s 检查下状态默认 15s 示例如下： 1[root@361way ~]# ansible 10.212.52.252 -B 3600 -P 0 -a &apos;watch ls&apos;background launch...10.212.52.252 | success &gt;&gt; &#123; &quot;ansible_job_id&quot;: &quot;411650646689.13501&quot;, &quot;results_file&quot;: &quot;/root/.ansible_async/411650646689.13501&quot;, &quot;started&quot;: 1&#125;[root@361way ~]# ansible 10.212.52.252 -m async_status -a &apos;jid=411650646689.13501&apos;10.212.52.252 | success &gt;&gt; &#123; &quot;ansible_job_id&quot;: &quot;411650646689.13501&quot;, &quot;changed&quot;: false, &quot;finished&quot;: 0, &quot;results_file&quot;: &quot;/root/.ansible_async/411650646689.13501&quot;, &quot;started&quot;: 1&#125; 不指定-P或-P参数为非0时，该任务就会按-P直接的参数一直刷新下去，直到超出-B参数指定的时间或命令执行完成： 1[root@361way ~]# ansible 10.212.52.252 -B 3600 -a &apos;watch ls&apos;background launch...10.212.52.252 | success &gt;&gt; &#123; &quot;ansible_job_id&quot;: &quot;397200656414.15008&quot;, &quot;results_file&quot;: &quot;/root/.ansible_async/397200656414.15008&quot;, &quot;started&quot;: 1&#125;10.212.52.252 | success &gt;&gt; &#123; &quot;ansible_job_id&quot;: &quot;397200656414.15008&quot;, &quot;changed&quot;: false, &quot;finished&quot;: 0, &quot;results_file&quot;: &quot;/root/.ansible_async/397200656414.15008&quot;, &quot;started&quot;: 1&#125;&lt;job 397200656414.15008&gt; polling on 10.212.52.252, 3585s remaining…………………………………………略 二、commands模块上面已经提到，ansbile自身已经自带了很多模块，可以通过ansible-doc -l 进行查看。这里就结合command、shell、raw、script模块了解下其用法。 上面四个模块都属于commands 类。 command模块，该模块通过-a跟上要执行的命令可以直接执行，不过命令里如果有带有如下字符部分则执行不成功 “ so variables like $HOME and operations like “&lt;”, “&gt;”, “|”, and “&amp;” will not work (use the shell module if you need these features).”； shell 模块，用法其本和command一样，不过的是其是通过/bin/sh进行执行，所以shell 模块可以执行任何命令，就像在本机执行一样，“ It is almost exactly like the command module but runs the command through a shell (/bin/sh) on the remote node.”； raw模块，用法和shell 模块一样 ，其也可以执行任意命令，就像在本机执行一样，“Executes a low-down and dirty SSH command, not going through the module subsystem. There is no change handler support for this module. This module does not require python on the remote system” script模块，其是将管理端的shell 在被管理主机上执行，其原理是先将shell 复制到远程主机，再在远程主机上执行，原理类似于raw模块，“This module does not require python on the remote system, much like the raw module.” 。 注：raw模块和comand、shell 模块不同的是其没有chdir、creates、removes参数，chdir参数的作用就是先切到chdir指定的目录后，再执行后面的命令，这在后面很多模块里都会有该参数 。 command模块包含如下选项： creates：一个文件名，当该文件存在，则该命令不执行 free_form：要执行的linux指令 chdir：在执行指令之前，先切换到该指定的目录 removes：一个文件名，当该文件不存在，则该选项不执行 executable：切换shell来执行指令，该执行路径必须是一个绝对路径 command模块、raw模块、shell模块示例： 1234567891011121314151617181920212223242526272829303132333435[root@361way ~]# ansible 10.212.52.252 -m command -a &apos;ps auxf|grep snmp&apos;10.212.52.252 | FAILED | rc=1 &gt;&gt;ERROR: Unsupported option (BSD syntax)********* simple selection ********* ********* selection by list *********-A all processes -C by command name-N negate selection -G by real group ID (supports names)-a all w/ tty except session leaders -U by real user ID (supports names)-d all except session leaders -g by session OR by effective group name-e all processes -p by process IDT all processes on this terminal -s processes in the sessions givena all w/ tty, including other users -t by ttyg OBSOLETE -- DO NOT USE -u by effective user ID (supports names)r only running processes U processes for specified usersx processes w/o controlling ttys t by tty*********** output format ********** *********** long options ***********-o,o user-defined -f full --Group --User --pid --cols --ppid-j,j job control s signal --group --user --sid --rows --info-O,O preloaded -o v virtual memory --cumulative --format --deselect-l,l long u user-oriented --sort --tty --forest --version-F extra full X registers --heading --no-heading --context ********* misc options *********-V,V show version L list format codes f ASCII art forest-m,m,-L,-T,H threads S children in sum -y change -l format-M,Z security data c true command name -c scheduling class-w,w wide output n numeric WCHAN,UID -H process hierarchy[root@361way ~]# ansible 10.212.52.252 -m raw -a &apos;ps auxf|grep snmp&apos;10.212.52.252 | success | rc=0 &gt;&gt;root 5580 25.0 0.0 12876 1792 pts/2 Ss+ 12:36 0:00 \\_ bash -c ps auxf|grep snmproot 5607 0.0 0.0 5720 832 pts/2 S+ 12:36 0:00 \\_ grep snmproot 24364 0.0 0.0 70416 6696 ? SNl May15 0:22 /usr/sbin/snmpd -r -A -LF i /var/log/net-snmpd.log -p /var/run/snmpd.pid[root@361way ~]# ansible 10.212.52.252 -m shell -a &apos;ps auxf|grep snmp&apos;10.212.52.252 | success | rc=0 &gt;&gt;root 5803 0.0 0.0 11308 1308 pts/2 S+ 12:36 0:00 \\_ /bin/sh -c ps auxf|grep snmproot 5805 0.0 0.0 4260 572 pts/2 S+ 12:36 0:00 \\_ grep snmproot 24364 0.0 0.0 70416 6696 ? SNl May15 0:22 /usr/sbin/snmpd -r -A -LF i /var/log/net-snmpd.log -p /var/run/snmpd.pid 上面的执行结果可以看到，我这里加了管道，command模块执行时出错，而使用raw模块和shell 模块都正常。 使用chdir的示例： 123456[root@361way ~]# ansible 10.212.52.252 -m command -a &apos;chdir=/tmp/361way touch test.file&apos;10.212.52.252 | success | rc=0 &gt;&gt;[root@361way ~]# ansible 10.212.52.252 -m shell -a &apos;chdir=/tmp/361way touch test2.file&apos;10.212.52.252 | success | rc=0 &gt;&gt;[root@361way ~]# ansible 10.212.52.252 -m raw -a &apos;chdir=/tmp/361way touch test3.file&apos;10.212.52.252 | success | rc=0 &gt;&gt; 从上面执行结果来看，三个命令都执行成功了。不过通过在远程主机上查看，前两个文件被成功创建： 12linux-wdh1:/tmp/361way # ls /tmp/361waytest.file test2.file 使用raw模块的执行的结果文件也被正常创建了，不过不是在chdir 指定的目录，而是在当前执行用户的家目录。 12linux-wdh1:~ # ls ~/test3.file/root/test3.file creates与removes示例： 这里我在测试主机上创建/tmp/361way/server.txt文件，执行结果如下： 123456[root@361way ~]# ansible 10.212.52.252 -a &apos;creates=/tmp/361way/server.txt uptime&apos;10.212.52.252 | success | rc=0 &gt;&gt;skipped, since /tmp/361way/server.txt exists[root@361way ~]# ansible 10.212.52.252 -a &apos;removes=/tmp/361way/server.txt uptime&apos;10.212.52.252 | success | rc=0 &gt;&gt; 15:11pm up 28 days 0:34, 2 users, load average: 0.75, 0.46, 0.39 script模块示例： 1234567891011121314[root@361way ~]# cat script.sh#!/bin/bashdf -hlifconfigps auxf|grep snmp[root@361way ~]# ansible 10.212.52.252 -m script -a &apos;scrip.sh&apos;10.212.52.252 | FAILED =&gt; file or module does not exist: /root/scrip.sh[root@361way ~]# ansible 10.212.52.252 -m script -a &apos;script.sh&apos;10.212.52.252 | success &gt;&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;OpenSSH_5.3p1, OpenSSL 1.0.1e-fips 11 Feb 2013\\ndebug1: Reading configuration data /etc/ssh/ssh_config\\r\\ndebug1: Applying options for *\\r\\ndebug1: auto-mux: Trying existing master\\r\\nControl socket connect(/root/.ansible/cp/ansible-ssh-10.212.52.252-22-root): Connection refused\\r\\ndebug1: Connecting to 10.212.52.252 [10.212.52.252] port 22.\\r\\ndebug1: fd 3 clearing O_NONBLOCK\\r\\ndebug1: Connection established.\\r\\ndebug1: permanently_set_uid: 0/0\\r\\ndebug1: identity file /root/.ssh/identity type -1\\r\\ndebug1: identity file /root/.ssh/identity-cert type -1\\r\\ndebug1: identity file /root/.ssh/id_rsa type -1\\r\\ndebug1: identity file /root/.ssh/id_rsa-cert type -1\\r\\ndebug1: identity file /root/.ssh/id_dsa type -1\\r\\ndebug1: identity file /root/.ssh/id_dsa-cert type -1\\r\\ndebug1: identity file /root/.ssh/id_ecdsa type -1\\r\\ndebug1: identity file /root/.ssh/id_ecdsa-cert type -1\\r\\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_6.2\\r\\ndebug1: match: OpenSSH_6.2 pat OpenSSH*\\r\\ndebug1: Enabling compatibility mode for protocol 2.0\\r\\ndebug1: Local version string SSH-2.0-OpenSSH_5.3\\r\\ndebug1: SSH2_MSG_KEXINIT sent\\r\\ndebug1: SSH2_MSG_KEXINIT received\\r\\ndebug1: kex: server-&gt;client aes128-ctr hmac-md5 zlib@openssh.com\\r\\ndebug1: kex: client-&gt;server aes128-ctr hmac-md5 zlib@openssh.com\\r\\ndebug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024&lt;1024&lt;8192) sent\\r\\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP\\r\\ndebug1: SSH2_MSG_KEX_DH_GEX_INIT sent\\r\\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_REPLY\\r\\ndebug1: Host &apos;10.212.52.252&apos; is known and matches the RSA host key.\\r\\ndebug1: Found key in /root/.ssh/known_hosts:1\\r\\ndebug1: ssh_rsa_verify: signature correct\\r\\ndebug1: SSH2_MSG_NEWKEYS sent\\r\\ndebug1: expecting SSH2_MSG_NEWKEYS\\r\\ndebug1: SSH2_MSG_NEWKEYS received\\r\\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\\r\\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\\r\\ndebug1: Authentications that can continue: publickey,password,keyboard-interactive\\r\\ndebug1: Next authentication method: keyboard-interactive\\r\\ndebug1: Enabling compression at level 6.\\r\\ndebug1: Authentication succeeded (keyboard-interactive).\\r\\ndebug1: setting up multiplex master socket\\r\\nControlSocket /root/.ansible/cp/ansible-ssh-10.212.52.252-22-root already exists, disabling multiplexing\\r\\ndebug1: channel 0: new [client-session]\\r\\ndebug1: Requesting no-more-sessions@openssh.com\\r\\ndebug1: Entering interactive session.\\r\\ndebug1: Sending environment.\\r\\ndebug1: Sending env LANG = en_US.UTF-8\\r\\ndebug1: Sending command: LANG=C LC_CTYPE=C /root/.ansible/tmp/ansible-tmp-1431924855.88-242473611260231/script.sh \\r\\ndebug1: client_input_channel_req: channel 0 rtype exit-status reply 0\\r\\ndebug1: client_input_channel_req: channel 0 rtype eow@openssh.com reply 0\\r\\ndebug1: channel 0: free: client-session, nchannels 1\\r\\ndebug1: fd 1 clearing O_NONBLOCK\\r\\ndebug1: fd 2 clearing O_NONBLOCK\\r\\nConnection to 10.212.52.252 closed.\\r\\nTransferred: sent 1928, received 3920 bytes, in 0.1 seconds\\r\\nBytes per second: sent 37017.0, received 75262.7\\r\\ndebug1: Exit status 0\\r\\ndebug1: compress outgoing: raw data 537, compressed 375, factor 0.70\\r\\ndebug1: compress incoming: raw data 1837, compressed 1019, factor 0.55\\r\\n&quot;, &quot;stdout&quot;: &quot;Filesystem Size Used Avail Use% Mounted on\\r\\n/dev/sda2 9.9G 872M 8.5G 10% /\\r\\nudev 3.9G 128K 3.9G 1% /dev\\r\\ntmpfs 3.9G 76K 3.9G 1% /dev/shm\\r\\n/dev/sda3 5.0G 219M 4.5G 5% /boot\\r\\n/dev/sda8 40G 15G 23G 40% /home\\r\\n/dev/sda9 9.9G 5.2G 4.3G 55% /opt\\r\\n/dev/sda6 5.0G 2.7G 2.1G 57% /tmp\\r\\n/dev/sda5 9.9G 3.4G 6.0G 36% /usr\\r\\n/dev/sda7 9.9G 823M 8.6G 9% /var\\r\\neth0 Link encap:Ethernet HWaddr 00:50:56:A8:65:7E \\r\\n inet addr:10.212.52.252 Bcast:10.212.52.255 Mask:255.255.255.0\\r\\n inet6 addr: fe80::250:56ff:fea8:657e/64 Scope:Link\\r\\n UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1\\r\\n RX packets:24112135 errors:0 dropped:792372 overruns:0 frame:0\\r\\n TX packets:10697339 errors:0 dropped:0 overruns:0 carrier:0\\r\\n collisions:0 txqueuelen:1000 \\r\\n RX bytes:17137233328 (16343.3 Mb) TX bytes:13390377826 (12770.0 Mb)\\r\\n\\r\\nlo Link encap:Local Loopback \\r\\n inet addr:127.0.0.1 Mask:255.0.0.0\\r\\n inet6 addr: ::1/128 Scope:Host\\r\\n UP LOOPBACK RUNNING MTU:16436 Metric:1\\r\\n RX packets:3407332 errors:0 dropped:0 overruns:0 frame:0\\r\\n TX packets:3407332 errors:0 dropped:0 overruns:0 carrier:0\\r\\n collisions:0 txqueuelen:0 \\r\\n RX bytes:262675450 (250.5 Mb) TX bytes:262675450 (250.5 Mb)\\r\\n\\r\\nroot 25332 0.0 0.0 4260 568 pts/2 S+ 12:54 0:00 \\\\_ grep snmp\\r\\nroot 24364 0.0 0.0 70416 6696 ? SNl May15 0:22 /usr/sbin/snmpd -r -A -LF i /var/log/net-snmpd.log -p /var/run/snmpd.pid\\r\\n&quot;&#125; 输出结果很多，看起来也很乱，不过查下stdout部分，这个部分是实际上执行后的结果。这里可以配合管道一起使用，可以如下使用： 1[root@361way ~]# ansible 10.212.52.252 -m script -a &apos;script.sh&apos; |egrep &apos;&gt;&gt;|stdout&apos; 篇幅所限，本来想把常用模块都放在该篇来写，感觉太冗长，后面再单独分开相应的篇幅做模块的介绍。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（五）Dynamic Inventory","slug":"ansible_05","date":"2016-10-22T02:32:16.000Z","updated":"2017-01-11T10:57:47.000Z","comments":true,"path":"2016/10/22/ansible_05/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_05/","excerpt":"","text":"Ansible Inventory实际上是包含静态Inventory和动态Inventory两部分，静态Inventory指的是在文件/etc/ansible/hosts中指定的主机和组，Dynamic Inventory指通过外部脚本获取主机列表，并按照ansible 所要求的格式返回给ansilbe命令的。这部分一般会结合CMDB资管系统、zabbix 监控系统、crobble安装系统、云计算平台等获取主机信息。由于主机资源一般会动态的进行增减，而这些系统一般会智能更新。我们可以通过这些工具提供的API 或者接入库查询等方式返回主机列表。 一、最简单示例由于Ansible在接受脚本动态获取主机信息时支持的是json格式，这里我也不从其他系统中取了，向通过一段代码打印一个段json格式的主机信息： 123456789#!/usr/bin/env python# coding=utf-8import jsonhost1ip = [&apos;10.212.52.252&apos;,&apos;10.212.52.14&apos;]host2ip = [&apos;10.212.52.16&apos;]group = &apos;test1&apos;group2 = &apos;test2&apos;hostdata = &#123;group:&#123;&quot;hosts&quot;:host1ip&#125;,group2:&#123;&quot;hosts&quot;:host2ip&#125;&#125;print json.dumps(hostdata,indent=4) 注： 1、主机部分必须是列表格式的； 2、hostdata行，其中的”hosts” 部分可以省略，但如果使用时，必须是”hosts” ，不能是其他如‘‘hostlist’’ 等字符串。 省略后可以这样写： 1hostdata = &#123;group:host1ip,group2:host2ip&#125; 直接执行该段代码结果如下： 1234567891011121314[root@361way.com ~]# python twogroup.py&#123; &quot;test1&quot;: &#123; &quot;hosts&quot;: [ &quot;10.212.52.252&quot;, &quot;10.212.52.14&quot; ] &#125;, &quot;test2&quot;: &#123; &quot;hosts&quot;: [ &quot;10.212.52.16&quot; ] &#125;&#125; 上面定义了两个主机组，test1组内包含主机10.212.52.252、10.212.52.14，test2组内包含主机10.212.52.16 。ansible可以通过如下方法调用： 12345678910[root@361way.com ~]# ansible -i twogroup.py test1 -m command -a &apos;uptime&apos; -kSSH password:10.212.52.252 | success | rc=0 &gt;&gt; 23:01pm up 24 days 8:24, 2 users, load average: 0.21, 0.35, 0.3910.212.52.14 | success | rc=0 &gt;&gt; 23:08pm up 332 days 5:23, 2 users, load average: 0.00, 0.01, 0.05[root@361way.com ~]# ansible -i twogroup.py test2 -m command -a &apos;uptime&apos; -kSSH password:10.212.52.16 | success | rc=0 &gt;&gt; 23:09pm up 332 days 6:00, 2 users, load average: 0.08, 0.06, 0.05 二、复杂示例在静态主机配置文件示例中，会有组变量（vars），组之间的包含，如下图（点击图片看大图）： 如果以上部分想要，通过脚本获取实现，实现后返回的json格式应该如下图： 像上面这种复杂的返回格式，一般不会用在ad-hoc环境中，多数会用在ansible-playbook 中，应为playbook文件中有时假会涉及到vars 参数的传参。 三、从第三方平台获取主机示例这个在本篇一开头就提到了，我们从如cobbler、cmdb等平台上获取的示例。由于ansible 的发起者（作者）同时又是cobbler软件的创建者，所以官方文档给了我们cobbler的示例，同时给出了一个从AWS 去上获取主机信息的示例 。如下： cobbler 上获取主机信息代码 aws 云上获取主机信息代码 关于如何从aws上获取主机信息并入库，这个我之前也写过相关的篇章，具体也可以参看我之前的博文－－－－AWS主机资产管理 （该篇也是纯python实现的）。 四、其他1、ansible -i 参数后调用的脚本并非一定是py文件，也可以是其他脚本输出的结果，这里做了个简单的测试： 12345678910111213141516171819202122[root@361way.com yaml]# ansible -i group.sh test1 -m command -a &apos;uptime&apos; -kSSH password:10.212.52.16 | success | rc=0 &gt;&gt; 00:18am up 332 days 7:10, 2 users, load average: 0.00, 0.01, 0.0510.212.52.14 | success | rc=0 &gt;&gt; 00:17am up 332 days 6:32, 2 users, load average: 0.01, 0.03, 0.0510.212.52.252 | success | rc=0 &gt;&gt; 00:11am up 24 days 9:33, 2 users, load average: 0.49, 0.42, 0.41[root@localhost yaml]# cat group.sh#!/bin/bashgroups=&apos;&apos;&apos;&#123; &quot;test1&quot;: &#123; &quot;hosts&quot;: [ &quot;10.212.52.252&quot;, &quot;10.212.52.14&quot;, &quot;10.212.52.16&quot; ] &#125;&#125;&apos;&apos;&apos;echo $groups 2、-i 参数指定的脚本需要有可执行权限 ，不然会报错，如下： 12[root@361way.com yaml]# ansible -i hostjson.py AA -a &apos;uptime&apos;ERROR: The file hostjson.py looks like it should be an executable inventory script, but is not marked executable. Perhaps you want to correct this with `chmod +x hostjson.py`?","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（四）ansible.cfg与默认配置","slug":"ansible_04","date":"2016-10-22T02:30:16.000Z","updated":"2017-01-10T10:30:31.000Z","comments":true,"path":"2016/10/22/ansible_04/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_04/","excerpt":"","text":"Ansible默认安装好后有一个配置文件/etc/ansible/ansible.cfg，该配置文件中定义了ansible的主机的默认配置部分，如默认是否需要输入密码、是否开启sudo认证、action_plugins插件的位置、hosts主机组的位置、是否开启log功能、默认端口、key文件位置等等。 具体如下： 123456789101112131415161718192021222324252627282930313233[defaults]# some basic default values...hostfile = /etc/ansible/hosts \\\\指定默认hosts配置的位置# library_path = /usr/share/my_modules/remote_tmp = $HOME/.ansible/tmppattern = *forks = 5poll_interval = 15sudo_user = root \\\\远程sudo用户#ask_sudo_pass = True \\\\每次执行ansible命令是否询问ssh密码#ask_pass = True \\\\每次执行ansible命令时是否询问sudo密码transport = smartremote_port = 22module_lang = Cgathering = implicithost_key_checking = False \\\\关闭第一次使用ansible连接客户端是输入命令提示log_path = /var/log/ansible.log \\\\需要时可以自行添加。chown -R root:root ansible.logsystem_warnings = False \\\\关闭运行ansible时系统的提示信息，一般为提示升级# set plugin path directories here, separate with colonsaction_plugins = /usr/share/ansible_plugins/action_pluginscallback_plugins = /usr/share/ansible_plugins/callback_pluginsconnection_plugins = /usr/share/ansible_plugins/connection_pluginslookup_plugins = /usr/share/ansible_plugins/lookup_pluginsvars_plugins = /usr/share/ansible_plugins/vars_pluginsfilter_plugins = /usr/share/ansible_plugins/filter_pluginsfact_caching = memory[accelerate]accelerate_port = 5099accelerate_timeout = 30accelerate_connect_timeout = 5.0# The daemon timeout is measured in minutes. This time is measured# from the last activity to the accelerate daemon.accelerate_daemon_timeout = 30 本篇就结合一个示例对其进行下了解。我在对之前未连接的主机进行连结时报错如下： 123[root@361way.com ~]# ansible test -a &apos;uptime&apos;10.212.52.14 | FAILED =&gt; Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this. Please add this host&apos;s fingerprint to your known_hosts file to manage this host.10.212.52.16 | FAILED =&gt; Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this. Please add this host&apos;s fingerprint to your known_hosts file to manage this host. 从上面的输出提示上基本可以了解到由于在本机的~/.ssh/known_hosts文件中并有fingerprint key串，ssh第一次连接的时候一般会提示输入yes 进行确认为将key字符串加入到 ~/.ssh/known_hosts 文件中。 方法1：了解到问题原因为，我们了解到进行ssh连接时，可以使用-o参数将StrictHostKeyChecking设置为no，使用ssh连接时避免首次连接时让输入yes/no部分的提示。通过查看ansible.cfg配置文件，发现如下行： 12345[ssh_connection]# ssh arguments to use# Leaving off ControlPersist will result in poor performance, so use# paramiko on older platforms rather than removing it#ssh_args = -o ControlMaster=auto -o ControlPersist=60s 所以这里我们可以启用ssh_args 部分，使用下面的配置，避免上面出现的错误： 1ssh_args = -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking＝no 方法2：在ansible.cfg配置文件中，也会找到如下部分： 12# uncomment this to disable SSH key host checkinghost_key_checking = False 默认host_key_checking部分是注释的，通过找开该行的注释，同样也可以实现跳过 ssh 首次连接提示验证部分。由于配置文件中直接有该选项，所以推荐用方法2 。 其他部分由于官方给的说明比较详细，同时ansible.cfg 文件本身默认也有注释提示部分，所以不做过多说明，这里再举个例子，默认ansible 执行的时候，并不会输出日志到文件，不过在ansible.cfg 配置文件中有如下行： 123# logging is off by default unless this path is defined# if so defined, consider logrotatelog_path = /var/log/ansible.log 同样，默认log_path这行是注释的，打开该行的注释，所有的命令执行后，都会将日志输出到/var/log/ansible.log 文件，便于了解在何时执行了何操作及其结果，如下： 12345678910[root@361way.com ansible]# cat /var/log/ansible.log2015-05-04 01:57:19,758 p=4667 u=root |2015-05-04 01:57:19,759 p=4667 u=root | /usr/bin/ansible test -a uptime2015-05-04 01:57:19,759 p=4667 u=root |2015-05-04 01:57:20,563 p=4667 u=root | 10.212.52.252 | success | rc=0 &gt;&gt; 01:57am up 23 days 11:20, 2 users, load average: 0.38, 0.38, 0.402015-05-04 01:57:20,831 p=4667 u=root | 10.212.52.14 | success | rc=0 &gt;&gt; 02:03am up 331 days 8:19, 2 users, load average: 0.08, 0.05, 0.052015-05-04 01:57:20,909 p=4667 u=root | 10.212.52.16 | success | rc=0 &gt;&gt; 02:05am up 331 days 8:56, 2 users, load average: 0.00, 0.01, 0.05 更多部分可以参看官方文档。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（三）Inventory与Patterns","slug":"ansible_03","date":"2016-10-22T02:20:16.000Z","updated":"2017-01-11T01:39:12.000Z","comments":true,"path":"2016/10/22/ansible_03/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_03/","excerpt":"","text":"一、Hosts and Groups（主机与组）对于/etc/ansible/hosts最简单的定义格式像下面： 1、简单的主机和组1234567mail.361way.com[webservers]web1.361way.comweb2.361way.com [dbservers]db1.361way.comdb2.361way.com a、中括号中的名字代表组名，你可以根据你自己的需求将庞大的主机分成具有标识的组，如上面我分了两个组webservers和dbservers组； b、主机(hosts)部分可以使用域名、主机名、IP地址表示；当然使用前两者时，也需要主机能反解析到相应的IP地址，一般此类配置中多使用IP地址； 2、端口与别名如果某些主机的SSH运行在自定义的端口上，ansible使用Paramiko进行ssh连接时，不会使用你SSH配置文件中列出的端口，但是如果修改ansible使用openssh进行ssh连接时将会使用： 1192.168.0.10:5309 假如你想要为某些静态IP设置一些别名，类似于SaltStack中minion配置文件中id的参数配置。你可以这样做： 1jumper ansible_ssh_port = 5555 ansible_ssh_host = 192.168.1.50 上面的 jumper 别名就指代了IP为192.168.1.50，ssh连接端口为5555的主机。 3、指定主机范围1234[webservers]www[01:50].361way.com[databases]db-[a:f].91it.org 上面指定了从web1到web50，webservers组共计50台主机；databases组有db-a到db-f共6台主机。 4、使用主机变量以下是Hosts部分中经常用到的变量部分 123456789ansible_ssh_host # 要连接的主机名ansible_ssh_port # 端口号默认是22ansible_ssh_user # ssh连接时默认使用的用户名ansible_ssh_pass # ssh连接时的密码ansible_sudo_pass # 使用sudo连接用户是的密码ansible_ssh_private_key_file # 秘钥文件如果不想使用ssh-agent管理时可以使用此选项ansible_shell_type # shell的类型默认shansible_connection # SSH 连接的类型： local , ssh , paramiko在 ansible 1.2 之前默认是 paramiko ，后来智能选择，优先使用基于 ControlPersist 的 ssh （支持的前提）ansible_python _ interpreter #用来指定 python 解释器的路径，同样可以指定ruby 、perl 的路径 示例如下： 1234[test]10.212.52.252 ansible_ssh_user=root ansible_ssh_pass=&apos;361way.com&apos;10.212.52.14 ansible_ssh_user=test1 ansible_ssh_pass=&apos;91it.org&apos;10.212.52.16 ansible_ssh_user=test2 ansible_ssh_port=7788 ansible_ssh_pass=&apos;123456&apos; 上面的示例中指定了三台主机，三台主机的用密码分别是361way.com、91it.org、123456，指定的ssh连接的用户名分别为root、test1、test2，ssh 端口分别为22、22、7788 ，这样在ansible命令执行的时候就不用再指令用户和密码等了，执行结果如下： 1234567[root@361way.com ~]# ansible test -a &apos;uptime&apos;10.212.52.252 | success | rc=0 &gt;&gt;01:34am up 23 days 10:57, 2 users, load average: 0.42, 0.39, 0.4110.212.52.16 | success | rc=0 &gt;&gt;01:41am up 331 days 8:33, 2 users, load average: 0.00, 0.01, 0.0510.212.52.14 | success | rc=0 &gt;&gt;01:40am up 331 days 7:55, 2 users, load average: 0.09, 0.03, 0.05 5、组内变量变量也可以通过组名，应用到组内的所有成员： 123456[test]host1host2[test:vars]ntp_server=ntp.361way.comproxy=proxy.361way.com 上面test组中包含两台主机，通过对test组指定vars变更，相应的host1和host2相当于相应的指定了ntp_server和proxy变量参数值 。 6、组的包含与组内变量12345678910111213141516171819[hangzhou]host1host2[jiaxing]host2host3[zhejiang:children]hangzhoujiaxing[zhejiang:vars]some_server=foo.southeast.example.comhalon_system_timeout=30self_destruct_countdown=60escape_pods=2[china:children]zhejianghenanshandonghebei 如上面的示例中，我指定了杭州组我有host1、hosts2；嘉兴组我有host3、host4主机；我又指定了一个组浙江组，同时包含杭州和嘉兴；同时为该组内的所有主机指定了四个vars变量。后面我又设定了一个组中国组，包含浙江、河南、山东、河北。 注：由于vars变量在ansible ad-hoc部分中基本用不到，主要用在ansible-playbook中，后面的章节部分也会提到。 以上部分基本上是完全按照官方Inventory 文档部分进行了翻译和微小的变化。英文感觉还可以的可以直接查看官方页面。 二、Patterns（主机与组正则匹配部分）把Patterns 直接理解为正则实际是不完全准确的，正常的理解为patterns意味着在ansible中管理哪些主机，也可以理解为，要与哪台主机进行通信。在探讨这个问题之前我们先看下ansible的用法： 1ansible &lt;pattern_goes_here&gt; -m &lt;module_name&gt; -a &lt;arguments&gt; 直接上一个示例： 1ansible webservers -m service -a &quot;name=httpd state=restarted&quot; 这里是对webservers 组或主机重启httpd服务 ，其中webservers 就是Pattern部分。而之所以上面我说Pattern（模式）可以理解为正则，主要针对下面经常用到的用法而言的。 1、表示所有的主机可以使用all 或 *2、通配符与逻辑或利用通配符还可以指定一组具有规则特征的主机或主机名，冒号表示or－－－逻辑或 1234one.361way.comone.361way:two.361way.com192.168.1.50192.168.1.* 当然，这里的*通配符也可以用在前面，如： 12*.361way.com*.com 上面的用法，在多个组之间同样适用 ，如： 12webserverswebservers:dbservers //表示两个组中所有的主机 3、逻辑非与逻辑and当然你可以做出非的表达式，例如，目标主机必须在组webservers但不在phoenix组中 1webserver:!phoenix 你还可以做出交集的表达式，例如，目标主机必须即在组webservers中又在组staging中 1webservers:&amp;staging 一个更复杂的示例： 1webserver:dbservers:&amp;staging:!phoenix 上面这个复杂的表达式最后表示的目标主机必须满足：在webservers或者dbservers组中，必须还存在于staging组中，但是不在phoenix组中。这些可以看作是SaltStack中Compound matchers 。 4、混合高级用法1*.361way.com:*.org 还可以在开头的地方使用”~”，用来表示这是一个正则表达式: 1~(web|db).*\\.91it\\.org 到这里估计你应该用能明白为什么前面我会提到Patterns 可以理解为正则的原因了。最后部分给两个ansible-playbook中具体可能用的用法： a、在ansible-palybook命令中，你也可以使用变量来组成这样的表达式，但是你必须使用“-e”的选项来指定这个表达式（通常我们不这样用）： 1ansible-palybook -e webservers:!&#123;&#123;excluded&#125;&#125;:&amp;&#123;&#123;required&#125;&#125; b、在ansible和ansible-playbook中，还可以通过一个参数”–limit”来明确指定排除某些主机或组： 1ansible-playbook site.yml --limit datacenter2 以上部分主要按照官方Pattern部分进行翻译和尝试。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（二）ansible架构","slug":"ansible_02","date":"2016-10-22T02:10:16.000Z","updated":"2017-01-11T01:38:59.000Z","comments":true,"path":"2016/10/22/ansible_02/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_02/","excerpt":"","text":"一、Ansible基本架构 上图为ansible的基本架构，从上图可以了解到其由以下部分组成： 核心：ansible 核心模块（Core Modules）：这些都是ansible自带的模块 扩展模块（Custom Modules）：如果核心模块不足以完成某种功能，可以添加扩展模块 插件（Plugins）：完成模块功能的补充 剧本（Playbooks）：ansible的任务配置文件，将多个任务定义在剧本中，由ansible自动执行 连接插件（Connectior Plugins）：ansible基于连接插件连接到各个主机上，虽然ansible是使用ssh连接到各个主机的，但是它还支持其他的连接方法，所以需要有连接插件 主机群（Host Inventory）：定义ansible管理的主机 二、ansible工作原理 以上是从网上找到的两张ansible工作原理图，两张图基本都是在架构图的基本上进行的拓展。从上面的图上可以了解到： 1、管理端支持local 、ssh、zeromq 三种方式连接被管理端，默认使用基于ssh的连接－－－这部分对应基本架构图中的连接模块； 2、可以按应用类型等方式进行Host Inventory（主机群）分类，管理节点通过各类模块实现相应的操作－－－单个模块，单条命令的批量执行，我们可以称之为ad-hoc； 3、管理节点可以通过playbooks 实现多个task的集合实现一类功能，如web服务的安装部署、数据库服务器的批量备份等。playbooks我们可以简单的理解为，系统通过组合多条ad-hoc操作的配置文件 。 三、ansible的七个命令安装完ansible后，发现ansible一共为我们提供了七个指令：ansible、ansible-doc、ansible-galaxy、ansible-lint、ansible-playbook、ansible-pull、ansible-vault 。这里我们只查看usage部分，详细部分可以通过 “指令 -h” 的方式获取。 1、ansible12[root@localhost ~]# ansible -hUsage: ansible &lt;host-pattern&gt; [options] ansible是指令核心部分，其主要用于执行ad-hoc命令，即单条命令。默认后面需要跟主机和选项部分，默认不指定模块时，使用的是command模块。如： 123[root@361way.com ~]# ansible 192.168.0.102 -a &apos;date&apos;192.168.0.102 | success | rc=0 &gt;&gt;Tue May 12 22:57:24 CST 2015 不过默认使用的模块是可以在ansible.cfg 中进行修改的。ansible命令下的参数部分解释如下： 12345678910111213141516171819202122232425262728293031323334353637383940参数： -a &apos;Arguments&apos;, --args=&apos;Arguments&apos; 命令行参数 -m NAME, --module-name=NAME 执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数 -i PATH, --inventory=PATH 指定库存主机文件的路径,默认为/etc/ansible/hosts. -u Username， --user=Username 执行用户，使用这个远程用户名而不是当前用户 -U --sud-user=SUDO_User sudo到哪个用户，默认为 root -k --ask-pass 登录密码，提示输入SSH密码而不是假设基于密钥的验证 -K --ask-sudo-pass 提示密码使用sudo -s --sudo sudo运行 -S --su 用 su 命令 -l --list 显示所支持的所有模块 -s --snippet 指定模块显示剧本片段 -f --forks=NUM 并行任务数。NUM被指定为一个整数,默认是5。 #ansible testhosts -a &quot;/sbin/reboot&quot; -f 10 重启testhosts组的所有机器，每次重启10台 --private-key=PRIVATE_KEY_FILE 私钥路径，使用这个文件来验证连接 -v --verbose 详细信息 all 针对hosts 定义的所有主机执行 -M MODULE_PATH, --module-path=MODULE_PATH 要执行的模块的路径，默认为/usr/share/ansible/ --list-hosts 只打印有哪些主机会执行这个 playbook 文件，不是实际执行该 playbook 文件 -o --one-line 压缩输出，摘要输出.尝试一切都在一行上输出。 -t Directory, --tree=Directory 将内容保存在该输出目录,结果保存在一个文件中在每台主机上。 -B 后台运行超时时间 -P 调查后台程序时间 -T Seconds, --timeout=Seconds 时间，单位秒s -P NUM, --poll=NUM 调查背景工作每隔数秒。需要- b -c Connection, --connection=Connection 连接类型使用。可能的选项是paramiko(SSH),SSH和地方。当地主要是用于crontab或启动。 --tags=TAGS 只执行指定标签的任务 例子:ansible-playbook test.yml --tags=copy 只执行标签为copy的那个任务 --list-hosts 只打印有哪些主机会执行这个 playbook 文件，不是实际执行该 playbook 文件 --list-tasks 列出所有将被执行的任务 -C, --check 只是测试一下会改变什么内容，不会真正去执行;相反,试图预测一些可能发生的变化 --syntax-check 执行语法检查的剧本,但不执行它 -l SUBSET, --limit=SUBSET 进一步限制所选主机/组模式 --limit=192.168.0.15 只对这个ip执行 --skip-tags=SKIP_TAGS 只运行戏剧和任务不匹配这些值的标签 --skip-tags=copy_start -e EXTRA_VARS, --extra-vars=EXTRA_VARS 额外的变量设置为键=值或YAML / JSON #cat update.yml --- - hosts: &#123;&#123; hosts &#125;&#125; remote_user: &#123;&#123; user &#125;&#125; .............. #ansible-playbook update.yml --extra-vars &quot;hosts=vipers user=admin&quot; 传递&#123;&#123;hosts&#125;&#125;、&#123;&#123;user&#125;&#125;变量,hosts可以是 ip或组名 -l,--limit 对指定的 主机/组 执行任务 --limit=192.168.0.10，192.168.0.11 或 -l 192.168.0.10，192.168.0.11 只对这个2个ip执行任务 2、ansible-doc12# ansible-doc -hUsage: ansible-doc [options] [module...] 该指令用于查看模块信息，常用参数有两个-l 和 -s ，具体如下： 1234//列出所有已安装的模块# ansible-doc -l//查看具体某模块的用法，这里如查看command模块# ansible-doc -s command 3、ansible-galaxy12# ansible-galaxy -hUsage: ansible-galaxy [init|info|install|list|remove] [--help] [options] ... ansible-galaxy 指令用于方便的从https://galaxy.ansible.com/ 站点下载第三方扩展模块，我们可以形象的理解其类似于centos下的yum、python下的pip或easy_install 。如下示例： 12345[root@localhost ~]# ansible-galaxy install aeriscloud.docker- downloading role &apos;docker&apos;, owned by aeriscloud- downloading role from https://github.com/AerisCloud/ansible-docker/archive/v1.0.0.tar.gz- extracting aeriscloud.docker to /etc/ansible/roles/aeriscloud.docker- aeriscloud.docker was installed successfully 这个安装了一个aeriscloud.docker组件，前面aeriscloud是galaxy上创建该模块的用户名，后面对应的是其模块。在实际应用中也可以指定txt或yml 文件进行多个组件的下载安装。这部分可以参看官方文档。 4、ansible-lintansible-lint是对playbook的语法进行检查的一个工具。用法是ansible-lint playbook.yml 。 5、ansible-playbook该指令是使用最多的指令，其通过读取playbook 文件后，执行相应的动作，这个后面会做为一个重点来讲。 6、ansible-pull该指令使用需要谈到ansible的另一种模式－－－pull 模式，这和我们平常经常用的push模式刚好相反，其适用于以下场景：你有数量巨大的机器需要配置，即使使用非常高的线程还是要花费很多时间；你要在一个没有网络连接的机器上运行Anisble，比如在启动之后安装。这部分也会单独做一节来讲。 7、ansible-vaultansible-vault主要应用于配置文件中含有敏感信息，又不希望他能被人看到，vault可以帮你加密/解密这个配置文件，属高级用法。主要对于playbooks里比如涉及到配置密码或其他变量时，可以通过该指令加密，这样我们通过cat看到的会是一个密码串类的文件，编辑的时候需要输入事先设定的密码才能打开。这种playbook文件在执行时，需要加上 –ask-vault-pass参数，同样需要输入密码后才能正常执行。具体该部分可以参查官方博客。 注：上面七个指令，用的最多的只有两个ansible 和ansible-playbook ，这两个一定要掌握，其他五个属于拓展或高级部分。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible小结（一）ansible的安装","slug":"ansible_01","date":"2016-10-22T01:10:16.000Z","updated":"2017-01-11T01:38:47.000Z","comments":true,"path":"2016/10/22/ansible_01/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/22/ansible_01/","excerpt":"","text":"一、简介Ansible 是一个配置管理和应用部署工具，功能类似于目前业界的配置管理工具 Chef,Puppet,Saltstack。Ansible 是通过 Python 语言开发。Ansible 平台由 Michael DeHaan 创建，他同时也是知名软件 Cobbler 与 Func 的作者。Ansible 的第一个版本发布于 2012 年 2 月。Ansible 默认通过 SSH 协议管理机器，所以 Ansible 不需要安装客户端程序在服务器上。您只需要将 Ansible 安装在一台服务器，在 Ansible 安装完后，您就可以去管理控制其它服务器。不需要为它配置数据库，Ansible 不会以 daemons 方式来启动或保持运行状态。Ansible 可以实现以下目标： 自动化部署应用 自动化管理配置 自动化的持续交付 自动化的（AWS）云服务管理。 根据 Ansible 官方提供的信息，当前使用 Ansible 的用户有：evernote、rackspace、NASA、Atlassian、twitter 等。 注：以上简介来自于ibm developerworks 中国的介绍。 二、Ansible的安装1、yum源安装以centos为例，默认在源里没有ansible，不过在fedora epel源里有ansible，配置完epel 源后，可以直接通过yum 进行安装。这里以centos6.8为例： 12# yum install http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm# yum install ansible 2、apt-get安装在ubuntu及其衍生版中，可以通过增加ppa源进行apt-get安装，具体如下： 1234$ sudo apt-get install software-properties-common$ sudo apt-add-repository ppa:ansible/ansible$ sudo apt-get update$ sudo apt-get install ansible 3、源码安装源码安装需要python2.6以上版本，其依赖模块paramiko、PyYAML、Jinja2、httplib2、simplejson、pycrypto模块，以上模块可以通过pip或easy_install 进行安装，不过本部分既然提到的是源码安装，主要针对的无法上外网的情况下，可以通过pypi 站点搜索以上包，下载后通过python setup.py install 进行安装。 最后通过github或pypi上下载ansible源码包，通过python setup.py install 安装即可。由于安装过程相对简单，这里略过，主要介绍安装后，可能遇到的问题。 a、安装PyYAML时，报错如下： 123456# python setup.py installlibyaml is not found or a compiler error: forcing --without-libyaml(if libyaml is installed correctly, you may need to specify the option --include-dirs or uncomment and modify the parameter include_dirs in setup.cfg)running install_librunning install_egg_infoRemoving /usr/lib64/python2.6/site-packages/PyYAML-3.11-py2.6.egg-infoWriting /usr/lib64/python2.6/site-packages/PyYAML-3.11-py2.6.egg-info 在centos6.8系统中，可以通过yum -y install libyaml 包解决，或者从ISO文件中提供该包，通过rpm -ivh进行安装。 b、安装完ansible是，报错如下： 1234567891011121314151617[root@361way.com ansible-1.9.1]# ansible -hTraceback (most recent call last):File &quot;/usr/local/src/ansible-devel/bin/ansible&quot;, line 36, in &lt;module&gt; from ansible.runner import RunnerFile &quot;/usr/local/src/ansible-devel/lib/ansible/runner/__init__.py&quot;, line 62, in &lt;module&gt;from Crypto.Random import atforkFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Random/__init__.py&quot;, line 29, in &lt;module&gt;from Crypto.Random import _UserFriendlyRNGFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Random/_UserFriendlyRNG.py&quot;, line 38, in &lt;module&gt;from Crypto.Random.Fortuna import FortunaAccumulatorFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Random/Fortuna/FortunaAccumulator.py&quot;, line 39, in &lt;module&gt;import FortunaGeneratorFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Random/Fortuna/FortunaGenerator.py&quot;, line 34, in &lt;module&gt; from Crypto.Util.number import ceil_shift, exact_log2, exact_divFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Util/number.py&quot;, line 56, in &lt;module&gt;if _fastmath is not None and not _fastmath.HAVE_DECL_MPZ_POWM_SEC:AttributeError: &apos;module&apos; object has no attribute &apos;HAVE_DECL_MPZ_POWM_SEC&apos; import paramiko包时，报错如下： 12345678910111213141516171819202122232425&gt;&gt;&gt; import paramikoTraceback (most recent call last):File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;/usr/lib/python2.6/site-packages/paramiko/__init__.py&quot;, line 69, in &lt;module&gt;from transport import randpool, SecurityOptions, TransportFile &quot;/usr/lib/python2.6/site-packages/paramiko/transport.py&quot;, line 32, in &lt;module&gt;from paramiko import utilFile &quot;/usr/lib/python2.6/site-packages/paramiko/util.py&quot;, line 32, in &lt;module&gt;from paramiko.common import *File &quot;/usr/lib/python2.6/site-packages/paramiko/common.py&quot;, line 98, in &lt;module&gt;from rng import StrongLockingRandomPoolFile &quot;/usr/lib/python2.6/site-packages/paramiko/rng.py&quot;, line 22, in &lt;module&gt;from Crypto.Util.randpool import RandomPool as _RandomPoolFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Util/randpool.py&quot;, line 30, in &lt;module&gt;import Crypto.RandomFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Random/__init__.py&quot;, line 29, in &lt;module&gt;from Crypto.Random import _UserFriendlyRNGFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Random/_UserFriendlyRNG.py&quot;, line 38, in &lt;module&gt;from Crypto.Random.Fortuna import FortunaAccumulatorFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Random/Fortuna/FortunaAccumulator.py&quot;, line 39, in &lt;module&gt;import FortunaGeneratorFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Random/Fortuna/FortunaGenerator.py&quot;, line 34, in &lt;module&gt; from Crypto.Util.number import ceil_shift, exact_log2, exact_divFile &quot;/usr/lib64/python2.6/site-packages/Crypto/Util/number.py&quot;, line 56, in &lt;module&gt;if _fastmath is not None and not _fastmath.HAVE_DECL_MPZ_POWM_SEC:AttributeError: &apos;module&apos; object has no attribute &apos;HAVE_DECL_MPZ_POWM_SEC&apos; 经网上查找，确认为pycrypto包安装时依赖的GMP版本不对的问题，具体可以通过以下步骤验证： 123456[root@361way.com pycrypto-2.6.1]# python setup.py buildrunning buildrunning build_pyrunning build_extrunning build_configurewarning: GMP or MPIR library not found; Not building Crypto.PublicKey._fastmath. 解决方法： 打开 /usr/lib64/python2.6/site-packages/Crypto/Util/number.py 文件，可以 看到 56 行上的注释说明，要求 libgmp 为 v5 以上版本。而系统现有版本为 4.1.4，把以下两行暂时注释掉，Ansible 执行正常。 12if _fastmath is not None and not _fastmath.HAVE_DECL_MPZ_POWM_SEC: _warn(&quot;Not using mpz_powm_sec. You should rebuild using libgmp &gt;= 5 to avoid timing attack vulnerability.&quot;, PowmInsecureWarning) 不过，此方法只是临时加以解决，更好的方式是去将 libgmp 升级到符合要求的版本。 c、执行时报错 123[root@361way.com src]# ansible test -m raw -a &apos;uptime&apos;10.212.52.14 | FAILED =&gt; to use the &apos;ssh&apos; connection type with passwords, you must install the sshpass program10.212.52.16 | FAILED =&gt; to use the &apos;ssh&apos; connection type with passwords, you must install the sshpass program 安装sshpass程序。默认源里没有，我这里选择直接从sohu源里下载安装。 三、Ansible的配置与验证这里以pypi上下载的源码内有一个examles包，可以将使用该示例文件做为默认配置，具体如下： 123[root@361way.com ansible-1.9.1]# mkdir -p /etc/ansible[root@361way.com ansible-1.9.1]# cp -rp examples/* /etc/ansible/[root@361way.com ansible-1.9.1]# cd /etc/ansible/ 使用默认示例配置文件后，编辑/etc/ansible/hosts文件，通过以下方式验证ansible是否可用： 12345[root@361way.com ~]# cat /etc/ansible/hosts[test]10.212.52.252 ansible_ssh_user=root ansible_ssh_pass=361way.com10.212.52.14 ansible_ssh_user=root ansible_ssh_pass=abc12310.212.52.16 ansible_ssh_user=root ansible_ssh_pass=91it.org 以上的配置中，我配置了一个test组，该组下有三台主机，三台都使用root验证，三台的密码分别是361way.com、abc123、91it.org 。 注：后面的用户和密码项是非必须的，在配置key认证的情况下，不使用密码也可以直接操作 。未使用key的，也可以在ansible通过 -k参数在操作前询问手动输入密码。 1234567[root@361way.com ~]# ansible test -a &apos;uptime&apos;10.212.52.252 | success | rc=0 &gt;&gt; 18:01pm up 21 days 3:24, 3 users, load average: 0.39, 0.38, 0.3510.212.52.16 | success | rc=0 &gt;&gt; 18:09pm up 329 days 1:01, 2 users, load average: 0.08, 0.03, 0.0510.212.52.14 | success | rc=0 &gt;&gt; 18:08pm up 329 days 0:23, 2 users, load average: 0.06, 0.06, 0.05 执行以上指令后，有结果输出，证明安装成功。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"ansible 使用主机IP批量修改机器名","slug":"ansible_rename_hostname","date":"2016-10-12T02:30:16.000Z","updated":"2017-01-10T10:14:02.000Z","comments":true,"path":"2016/10/12/ansible_rename_hostname/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/12/ansible_rename_hostname/","excerpt":"","text":"首先看看我的hosts配置 12345678910root@jastme:/etc/ansible/playbooks# more ../hosts [test]192.168.32.131 ansible_connection=local [test1]192.168.32.133 ansible_ssh_pass=123[test2]192.168.32.132 ansible_ssh_pass=123[testall]192.168.32.132 ansible_ssh_pass=123192.168.32.133 ansible_ssh_pass=123 看看2台主机的原始机器名 1234567891011121314151617181920212223主机1[root@ZooKeeper-01 ~]# hostname ZooKeeper-01[root@ZooKeeper-01 ~]# ifconfig eth2eth2 Link encap:Ethernet HWaddr 00:0C:29:58:95:55 inet addr:192.168.32.132 Bcast:192.168.32.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:39614 errors:0 dropped:0 overruns:0 frame:0 TX packets:18265 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:5279094 (5.0 MiB) TX bytes:1110521 (1.0 MiB) 主机2[root@ZooKeeper-02 ~]# hostname ZooKeeper-02[root@ZooKeeper-02 ~]# ifconfig eth2eth2 Link encap:Ethernet HWaddr 00:0C:29:C8:7F:48 inet addr:192.168.32.133 Bcast:192.168.32.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:41538 errors:0 dropped:0 overruns:0 frame:0 TX packets:20085 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:6164131 (5.8 MiB) TX bytes:1729825 (1.6 MiB) 目标 我们需要需要改这两台机器的主机名，按照他们自己的IP修改 类似 web132 web133 playbook 123456789root@jastme:/etc/ansible/playbooks# more changehostname.yml - hosts : testall remote_user : root tasks : - name : show hostname shell : hostname - name : show ip command : ip a - hostname : name=web&#123;&#123; ansible_default_ipv4.address.split(&apos;.&apos;)[-1] &#125;&#125; #直接调用res字典，引用成变量 执行一下，看看结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475root@jastme:/etc/ansible/playbooks# ansible-playbook changehostname.yml PLAY [testall] **************************************************************** GATHERING FACTS *************************************************************** ok: [192.168.32.133] #IP&#123;&apos;module_name&apos;: &apos;setup&apos;, &apos;module_complex_args&apos;: &#123;&#125;, &apos;module_args&apos;: &apos;&apos;&#125;ok: [192.168.32.132]&#123;&apos;module_name&apos;: &apos;setup&apos;, &apos;module_complex_args&apos;: &#123;&#125;, &apos;module_args&apos;: &apos;&apos;&#125;TASK: [show hostname] ********************************************************* changed: [192.168.32.133]ZooKeeper-02 #主机名&#123;&apos;module_name&apos;: u&apos;shell&apos;, &apos;module_complex_args&apos;: &#123;&#125;, &apos;module_args&apos;: u&apos;hostname&apos;&#125;changed: [192.168.32.132]ZooKeeper-01&#123;&apos;module_name&apos;: u&apos;shell&apos;, &apos;module_complex_args&apos;: &#123;&#125;, &apos;module_args&apos;: u&apos;hostname&apos;&#125;TASK: [show ip] *************************************************************** changed: [192.168.32.133]1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo2: eth0: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master bond0 qlen 1000 link/ether 00:0c:29:c8:7f:34 brd ff:ff:ff:ff:ff:ff3: eth1: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master bond1 qlen 1000 link/ether 00:0c:29:c8:7f:3e brd ff:ff:ff:ff:ff:ff4: eth2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000 link/ether 00:0c:29:c8:7f:48 brd ff:ff:ff:ff:ff:ff inet 192.168.32.133/24 brd 192.168.32.255 scope global eth25: eth3: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master bond0 qlen 1000 link/ether 00:0c:29:c8:7f:34 brd ff:ff:ff:ff:ff:ff6: eth4: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master bond1 qlen 1000 link/ether 00:0c:29:c8:7f:3e brd ff:ff:ff:ff:ff:ff7: bond0: &lt;BROADCAST,MULTICAST,MASTER,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue link/ether 00:0c:29:c8:7f:34 brd ff:ff:ff:ff:ff:ff inet 144.148.64.230/24 brd 144.148.64.255 scope global bond0 inet 144.148.64.231/32 brd 144.148.64.231 scope global bond0:08: bond1: &lt;BROADCAST,MULTICAST,MASTER,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue link/ether 00:0c:29:c8:7f:3e brd ff:ff:ff:ff:ff:ff inet 10.25.17.82/24 brd 10.25.17.255 scope global bond1 inet 10.25.17.83/32 brd 10.25.17.83 scope global bond1:0&#123;&apos;module_name&apos;: u&apos;command&apos;, &apos;module_complex_args&apos;: &#123;&#125;, &apos;module_args&apos;: u&apos;ip a&apos;&#125;changed: [192.168.32.132]1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo2: eth0: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master bond0 qlen 1000 link/ether 00:0c:29:58:95:41 brd ff:ff:ff:ff:ff:ff3: eth1: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master bond1 qlen 1000 link/ether 00:0c:29:58:95:4b brd ff:ff:ff:ff:ff:ff4: eth2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000 link/ether 00:0c:29:58:95:55 brd ff:ff:ff:ff:ff:ff inet 192.168.32.132/24 brd 192.168.32.255 scope global eth25: eth3: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master bond0 qlen 1000 link/ether 00:0c:29:58:95:41 brd ff:ff:ff:ff:ff:ff6: eth4: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master bond1 qlen 1000 link/ether 00:0c:29:58:95:4b brd ff:ff:ff:ff:ff:ff7: bond0: &lt;BROADCAST,MULTICAST,MASTER,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue link/ether 00:0c:29:58:95:41 brd ff:ff:ff:ff:ff:ff inet 144.148.64.229/24 brd 144.148.64.255 scope global bond08: bond1: &lt;BROADCAST,MULTICAST,MASTER,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue link/ether 00:0c:29:58:95:4b brd ff:ff:ff:ff:ff:ff inet 10.25.17.81/24 brd 10.25.17.255 scope global bond1&#123;&apos;module_name&apos;: u&apos;command&apos;, &apos;module_complex_args&apos;: &#123;&#125;, &apos;module_args&apos;: u&apos;ip a&apos;&#125;TASK: [hostname name=web&#123;&#123; ansible_default_ipv4.address.split(&apos;.&apos;)[-1] &#125;&#125;] **** changed: [192.168.32.133]&#123;&apos;module_name&apos;: u&apos;hostname&apos;, &apos;module_complex_args&apos;: &#123;&#125;, &apos;module_args&apos;: u&apos;name=web133&apos;&#125; #这里就是我们需要的操作 可以看见主机名已经被修改成功changed: [192.168.32.132]&#123;&apos;module_name&apos;: u&apos;hostname&apos;, &apos;module_complex_args&apos;: &#123;&#125;, &apos;module_args&apos;: u&apos;name=web132&apos;&#125;PLAY RECAP ******************************************************************** 192.168.32.132 : ok=4 changed=3 unreachable=0 failed=0 192.168.32.133 : ok=4 changed=3 unreachable=0 failed=0 验证 12345[root@ZooKeeper-01 ~]# hostname web132[root@ZooKeeper-02 ~]# hostname web133 验证修改成功。。。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"集群运维ansible的playbook配置及template模板的使用","slug":"ansible_playbook","date":"2016-10-08T01:30:16.000Z","updated":"2017-01-10T03:42:56.000Z","comments":true,"path":"2016/10/08/ansible_playbook/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/08/ansible_playbook/","excerpt":"","text":"原文 http://rfyiamcool.blog.51cto.com/1030776/1413031 前言： 学习下ansible的playbook的状态配置管理，说来puppet saltstack都有类似的叫法，只是ansible的叫法更犀利，我当时一看playbook还以为是花花公子的playboy。要使用ansible就要深入学习playbook配置及模板。 先把官网的简单几个语法给说明下。 1234567891011121314151617181920212223#这个是你选择的主机- hosts: webservers#这个是变量 vars: http_port: 80 max_clients: 200#远端的执行权限 remote_user: root tasks:#利用yum模块来操作 - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf#触发重启服务器 notify: - restart apache - name: ensure apache is running service: name=httpd state=started#这里的restart apache 和上面的触发是配对的。这就是handlers的作用。相当于tag handlers: - name: restart apache service: name=httpd state=restarted 如果有些系统做了相关的sudo限制，需要在playbook里面开启sodu，或者直接偷懒，权限直接为root ！ 12345- hosts: web remote_user: xiaorui tasks: - service: name=nginx state=started sudo: yes 原文：http://rfyiamcool.blog.51cto.com/1030776/1413031 官网的基本完事了，这里就直接实战吧。先说一个简单的ansible playbook的例子。 123456789- name: create user hosts: web user: root gather_facts: false vars: - user: &quot;xiaorui&quot; tasks: - name: create &#123;&#123; user &#125;&#125; user: name=&quot;&#123;&#123; user &#125;&#125;&quot; 然后我们执行一下，Playbook 采用 YAML 语法结构，因此它们一般比较易于阅读并加以配置。 上面的意思已经很简单明了了，就是创建一个xiaorui的用户，里面引用了一个user的变量，用jinja2模板给赋值进去了。 下面的还用我说么？ 多了一个service的调用，nginx的状态保持为启动。 1234567891011- name: create user hosts: web user: root gather_facts: false vars: - user: &quot;xiaorui&quot; tasks: - name: create &#123;&#123; user &#125;&#125; user: name=&quot;&#123;&#123; user &#125;&#125;&quot; tasks: - service: name=nginx state=started 使用copy传送文件的时候，经常出些问题，是ansible需要python-selinux包而已. 123456789[root@67 ~]# ansible-playbook user.yamlPLAY [create user] ************************************************************TASK: [Copy file to client] ***************************************************failed: [10.10.10.66] =&gt; &#123;&quot;failed&quot;: true, &quot;md5sum&quot;: &quot;1f18348f32c9a4694f16426798937ae2&quot;&#125;msg: Aborting, target uses selinux but python bindings (libselinux-python) aren&apos;t installed!FATAL: all hosts have already failed -- abortingPLAY RECAP ******************************************************************** to retry, use: --limit @/root/user.yaml.retry10.10.10.66 : ok=0 changed=0 unreachable=0 failed=1 yum install -y libselinux-python 就可以行了 copy是传送文件用的。 123456789101112131415- name: create user hosts: web user: root gather_facts: false remote_user: root vars: - user: &quot;xiaorui&quot; tasks: - name: create &#123;&#123; user &#125;&#125; user: name=&quot;&#123;&#123; user &#125;&#125;&quot; tasks: - service: name=nginx state=started tasks: - name: Copy file to client copy: src=/root/rs.sh dest=/root/ccc 根据一些特殊的情况，可以做更多的模板，比如这样 123456789101112vars: - user: &quot;xiaorui&quot; - say: &quot;xiaorui&quot; tasks: - name: create &#123;&#123; user &#125;&#125; user: name=&quot;&#123;&#123; user &#125;&#125;&quot; tasks: - service: name=nginx state=started tasks: - name: Copy file to client# copy: src=/root/rs.sh dest=/root/ccc template: src=/root/testfile dest=/root/&#123;&#123; say &#125;&#125; 不只是这样，我可以把刚才那个say变量传到文件里面。 爽吧? 其实和saltstack一样。。。。 再来一个和puppet exec一样执行外部命令的模块 123tasks:- name: &quot;cmd&quot; action: command touch /root/1111 还有一种shell模块的使用方法 。 123tasks:- name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true ansible在多任务下，推荐使用多进程模式的。其实就是用multiprocess做的多进程池 ！ -f 10 就是limit 10个任务并发。 1ansible-playbook user.yml -f 10 顺便讲解下，在ansible下，类似puppet的facter，saltstack grains的自定义变量。 -m setup 模块 咱们可以在模板文件中，引用这些setup系统变量的 1234#xiaorui.cc&#123;&#123; ansible_devices.sda.model &#125;&#125;&#123;&#123; ansible_hostname &#125;&#125;&#123;&#123; ansible_machine &#125;&#125; 看看我测试机的setup是啥样子的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231[root@67 ~]# ansible web -m setup10.10.10.66 | success &gt;&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_all_ipv4_addresses&quot;: [ &quot;10.10.10.66&quot; ], &quot;ansible_all_ipv6_addresses&quot;: [ &quot;fe80::20c:29ff:fe06:f2dc&quot; ], &quot;ansible_architecture&quot;: &quot;i386&quot;, &quot;ansible_bios_date&quot;: &quot;06/02/2011&quot;, &quot;ansible_bios_version&quot;: &quot;6.00&quot;, &quot;ansible_cmdline&quot;: &#123; &quot;KEYBOARDTYPE&quot;: &quot;pc&quot;, &quot;KEYTABLE&quot;: &quot;us&quot;, &quot;LANG&quot;: &quot;zh_CN.UTF-8&quot;, &quot;quiet&quot;: true, &quot;rd_LVM_LV&quot;: &quot;vg_65/lv_swap&quot;, &quot;rd_NO_DM&quot;: true, &quot;rd_NO_LUKS&quot;: true, &quot;rd_NO_MD&quot;: true, &quot;rhgb&quot;: true, &quot;ro&quot;: true, &quot;root&quot;: &quot;/dev/mapper/vg_65-lv_root&quot; &#125;, &quot;ansible_date_time&quot;: &#123; &quot;date&quot;: &quot;2014-05-18&quot;, &quot;day&quot;: &quot;18&quot;, &quot;epoch&quot;: &quot;1400373954&quot;, &quot;hour&quot;: &quot;08&quot;, &quot;iso8601&quot;: &quot;2014-05-18T00:45:54Z&quot;, &quot;iso8601_micro&quot;: &quot;2014-05-18T00:45:54.840220Z&quot;, &quot;minute&quot;: &quot;45&quot;, &quot;month&quot;: &quot;05&quot;, &quot;second&quot;: &quot;54&quot;, &quot;time&quot;: &quot;08:45:54&quot;, &quot;tz&quot;: &quot;CST&quot;, &quot;tz_offset&quot;: &quot;+0800&quot;, &quot;year&quot;: &quot;2014&quot; &#125;, &quot;ansible_default_ipv4&quot;: &#123; &quot;address&quot;: &quot;10.10.10.66&quot;, &quot;alias&quot;: &quot;eth0&quot;, &quot;gateway&quot;: &quot;10.10.10.1&quot;, &quot;interface&quot;: &quot;eth0&quot;, &quot;macaddress&quot;: &quot;00:0c:29:06:f2:dc&quot;, &quot;mtu&quot;: 1500, &quot;netmask&quot;: &quot;255.255.255.0&quot;, &quot;network&quot;: &quot;10.10.10.0&quot;, &quot;type&quot;: &quot;ether&quot; &#125;, &quot;ansible_default_ipv6&quot;: &#123;&#125;, &quot;ansible_devices&quot;: &#123; &quot;sda&quot;: &#123; &quot;holders&quot;: [], &quot;host&quot;: &quot;SCSI storage controller: LSI Logic / Symbios Logic 53c1030 PCI-X Fusion-MPT Dual Ultra320 SCSI (rev 01)&quot;, &quot;model&quot;: &quot;VMware Virtual S&quot;, &quot;partitions&quot;: &#123; &quot;sda1&quot;: &#123; &quot;sectors&quot;: &quot;1024000&quot;, &quot;sectorsize&quot;: 512, &quot;size&quot;: &quot;500.00 MB&quot;, &quot;start&quot;: &quot;2048&quot; &#125;, &quot;sda2&quot;: &#123; &quot;sectors&quot;: &quot;418404352&quot;, &quot;sectorsize&quot;: 512, &quot;size&quot;: &quot;199.51 GB&quot;, &quot;start&quot;: &quot;1026048&quot; &#125; &#125;, &quot;removable&quot;: &quot;0&quot;, &quot;rotational&quot;: &quot;1&quot;, &quot;scheduler_mode&quot;: &quot;cfq&quot;, &quot;sectors&quot;: &quot;419430400&quot;, &quot;sectorsize&quot;: &quot;512&quot;, &quot;size&quot;: &quot;200.00 GB&quot;, &quot;support_discard&quot;: &quot;0&quot;, &quot;vendor&quot;: &quot;VMware,&quot; &#125;, &quot;sr0&quot;: &#123; &quot;holders&quot;: [], &quot;host&quot;: &quot;IDE interface: Intel Corporation 82371AB/EB/MB PIIX4 IDE (rev 01)&quot;, &quot;model&quot;: &quot;VMware IDE CDR10&quot;, &quot;partitions&quot;: &#123;&#125;, &quot;removable&quot;: &quot;1&quot;, &quot;rotational&quot;: &quot;1&quot;, &quot;scheduler_mode&quot;: &quot;cfq&quot;, &quot;sectors&quot;: &quot;2097151&quot;, &quot;sectorsize&quot;: &quot;512&quot;, &quot;size&quot;: &quot;1024.00 MB&quot;, &quot;support_discard&quot;: &quot;0&quot;, &quot;vendor&quot;: &quot;NECVMWar&quot; &#125; &#125;, &quot;ansible_distribution&quot;: &quot;CentOS&quot;, &quot;ansible_distribution_release&quot;: &quot;Final&quot;, &quot;ansible_distribution_version&quot;: &quot;6.4&quot;, &quot;ansible_domain&quot;: &quot;ruifengyun.com&quot;, &quot;ansible_env&quot;: &#123; &quot;CVS_RSH&quot;: &quot;ssh&quot;, &quot;G_BROKEN_FILENAMES&quot;: &quot;1&quot;, &quot;HOME&quot;: &quot;/root&quot;, &quot;LANG&quot;: &quot;C&quot;, &quot;LESSOPEN&quot;: &quot;|/usr/bin/lesspipe.sh %s&quot;, &quot;LOGNAME&quot;: &quot;root&quot;, &quot;MAIL&quot;: &quot;/var/mail/root&quot;, &quot;PATH&quot;: &quot;/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin&quot;, &quot;PWD&quot;: &quot;/root&quot;, &quot;SELINUX_LEVEL_REQUESTED&quot;: &quot;&quot;, &quot;SELINUX_ROLE_REQUESTED&quot;: &quot;&quot;, &quot;SELINUX_USE_CURRENT_RANGE&quot;: &quot;&quot;, &quot;SHELL&quot;: &quot;/bin/bash&quot;, &quot;SHLVL&quot;: &quot;2&quot;, &quot;SSH_CLIENT&quot;: &quot;10.10.10.67 50278 22&quot;, &quot;SSH_CONNECTION&quot;: &quot;10.10.10.67 50278 10.10.10.66 22&quot;, &quot;USER&quot;: &quot;root&quot;, &quot;_&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;ansible_eth0&quot;: &#123; &quot;active&quot;: true, &quot;device&quot;: &quot;eth0&quot;, &quot;ipv4&quot;: &#123; &quot;address&quot;: &quot;10.10.10.66&quot;, &quot;netmask&quot;: &quot;255.255.255.0&quot;, &quot;network&quot;: &quot;10.10.10.0&quot; &#125;, &quot;ipv6&quot;: [ &#123; &quot;address&quot;: &quot;fe80::20c:29ff:fe06:f2dc&quot;, &quot;prefix&quot;: &quot;64&quot;, &quot;scope&quot;: &quot;link&quot; &#125; ], &quot;macaddress&quot;: &quot;00:0c:29:06:f2:dc&quot;, &quot;module&quot;: &quot;pcnet32&quot;, &quot;mtu&quot;: 1500, &quot;promisc&quot;: false, &quot;type&quot;: &quot;ether&quot; &#125;, &quot;ansible_form_factor&quot;: &quot;Other&quot;, &quot;ansible_fqdn&quot;: &quot;66.ruifengyun.com&quot;, &quot;ansible_hostname&quot;: &quot;66&quot;, &quot;ansible_interfaces&quot;: [ &quot;lo&quot;, &quot;eth0&quot; ], &quot;ansible_kernel&quot;: &quot;2.6.32-358.el6.i686&quot;, &quot;ansible_lo&quot;: &#123; &quot;active&quot;: true, &quot;device&quot;: &quot;lo&quot;, &quot;ipv4&quot;: &#123; &quot;address&quot;: &quot;127.0.0.1&quot;, &quot;netmask&quot;: &quot;255.0.0.0&quot;, &quot;network&quot;: &quot;127.0.0.0&quot; &#125;, &quot;ipv6&quot;: [ &#123; &quot;address&quot;: &quot;::1&quot;, &quot;prefix&quot;: &quot;128&quot;, &quot;scope&quot;: &quot;host&quot; &#125; ], &quot;mtu&quot;: 16436, &quot;promisc&quot;: false, &quot;type&quot;: &quot;loopback&quot; &#125;, &quot;ansible_machine&quot;: &quot;i686&quot;, &quot;ansible_memfree_mb&quot;: 694, &quot;ansible_memtotal_mb&quot;: 1006, &quot;ansible_mounts&quot;: [ &#123; &quot;device&quot;: &quot;/dev/mapper/vg_65-lv_root&quot;, &quot;fstype&quot;: &quot;ext4&quot;, &quot;mount&quot;: &quot;/&quot;, &quot;options&quot;: &quot;rw&quot;, &quot;size_available&quot;: 47512358912, &quot;size_total&quot;: 52844687360 &#125;, &#123; &quot;device&quot;: &quot;/dev/sda1&quot;, &quot;fstype&quot;: &quot;ext4&quot;, &quot;mount&quot;: &quot;/boot&quot;, &quot;options&quot;: &quot;rw&quot;, &quot;size_available&quot;: 449800192, &quot;size_total&quot;: 507744256 &#125;, &#123; &quot;device&quot;: &quot;/dev/mapper/vg_65-lv_home&quot;, &quot;fstype&quot;: &quot;ext4&quot;, &quot;mount&quot;: &quot;/home&quot;, &quot;options&quot;: &quot;rw&quot;, &quot;size_available&quot;: 145807802368, &quot;size_total&quot;: 153817976832 &#125; ], &quot;ansible_os_family&quot;: &quot;RedHat&quot;, &quot;ansible_pkg_mgr&quot;: &quot;yum&quot;, &quot;ansible_processor&quot;: [ &quot;Intel(R) Core(TM) i5-2430M CPU @ 2.40GHz&quot; ], &quot;ansible_processor_cores&quot;: 1, &quot;ansible_processor_count&quot;: 1, &quot;ansible_processor_threads_per_core&quot;: 1, &quot;ansible_processor_vcpus&quot;: 1, &quot;ansible_product_name&quot;: &quot;VMware Virtual Platform&quot;, &quot;ansible_product_serial&quot;: &quot;VMware-56 4d bf 2f b7 6c f2 9d-bb f1 a6 0b 1a 06 f2 dc&quot;, &quot;ansible_product_uuid&quot;: &quot;564DBF2F-B76C-F29D-BBF1-A60B1A06F2DC&quot;, &quot;ansible_product_version&quot;: &quot;None&quot;, &quot;ansible_python_version&quot;: &quot;2.6.6&quot;, &quot;ansible_selinux&quot;: &#123; &quot;config_mode&quot;: &quot;enforcing&quot;, &quot;mode&quot;: &quot;permissive&quot;, &quot;policyvers&quot;: 24, &quot;status&quot;: &quot;enabled&quot;, &quot;type&quot;: &quot;targeted&quot; &#125;, &quot;ansible_ssh_host_key_dsa_public&quot;: &quot;AAAAB3NzaC1kc3MAAACBAOjq8+laDLF6/ly/BezPQONwHrIhRmAwYIDysQEIWvvZ4eq/2MJO6GNleSqHd/e6VH1T3SWO4wbPcgTXVRqoQLlT46RQ3hxCCIQ1Q3vThB+QPstMslYFVrtupzSqrRDbtwakEsdp1VlW5RSyBJ7JgzlQn8yQgQwmuS7IXSl2yX5LAAAAFQD+tvRyt+h7lJngeQc0AXWnN/Ij4QAAAIEAtD9SU4ZGmRSX5Ms8W8oqaTED5b/0VqLgT7ear6NkH0zHi0pRGs2kgf0KLqRjuBKqwlYdBj309Oc+Rip23cqb725BWHlrI4mEvVl2FLSOnTi8zd4esYeRga5od26g9VDjIbE0MGB/hUukH5od4dXjnK1zowADyz7jJkrkT+dFpkcAAACAH/0s0vagsSWR4EsXyR0lQsc/lBT1xSCiRFZbPtqMXxmq/3cqM1bbmyK7puQiJDy3ay/vrV/fmLk5RlgbFJB7n/ZVJnEoGfwXSoHJLRC+7tBJIKUm2jskZ1rl3o3ZxWQsSHPGy3sBDE9R1czKf8p1T8gM/EQrHDtTOqmDgrc287M=&quot;, &quot;ansible_ssh_host_key_rsa_public&quot;: &quot;AAAAB3NzaC1yc2EAAAABIwAAAQEAltE2aPOjHIF9Jh79LAm5Dc31VylZk15CqXwnwlQTOqAmFRoPwqnMn+F1oKOTVZ52BAQvitMF4XvNyE0sveSb5hFQkKBsJpEfBPNkQjty1Hgk03HpwHgspu9sk7HmwoPht+qTTm2764YYXiIbDJXva458eWBZsMTPX8frIeNzz1XbwveGbQt+jTYPdqzywp1UEJ4+EwGx9l3zR1WFDqA4Kz3clJJgtoGWasMmNXybr3tHn/csYllWdG0+03fxBM6d4QuR0WmgR7kIxxXnQcvWk0ZNUC3x9dVMeuGPsIvUh2bQOIv1rGWfB24mzIZIjV17RgNXrM8qy2FBZ96Mrvkd3w==&quot;, &quot;ansible_swapfree_mb&quot;: 4063, &quot;ansible_swaptotal_mb&quot;: 4063, &quot;ansible_system&quot;: &quot;Linux&quot;, &quot;ansible_system_vendor&quot;: &quot;VMware, Inc.&quot;, &quot;ansible_user_id&quot;: &quot;root&quot;, &quot;ansible_userspace_architecture&quot;: &quot;i386&quot;, &quot;ansible_userspace_bits&quot;: &quot;32&quot;, &quot;ansible_virtualization_role&quot;: &quot;guest&quot;, &quot;ansible_virtualization_type&quot;: &quot;VMware&quot; &#125;, &quot;changed&quot;: false&#125; 如果觉得信息太多，有些乱，可以用filter过滤下 123456789101112131415161718192021222324252627282930313233[root@67 ~]# ansible web -m setup -a &quot;filter=ansible_mounts&quot;10.10.10.66 | success &gt;&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_mounts&quot;: [ &#123; &quot;device&quot;: &quot;/dev/mapper/vg_65-lv_root&quot;, &quot;fstype&quot;: &quot;ext4&quot;, &quot;mount&quot;: &quot;/&quot;, &quot;options&quot;: &quot;rw&quot;, &quot;size_available&quot;: 47511494656, &quot;size_total&quot;: 52844687360 &#125;, &#123; &quot;device&quot;: &quot;/dev/sda1&quot;, &quot;fstype&quot;: &quot;ext4&quot;, &quot;mount&quot;: &quot;/boot&quot;, &quot;options&quot;: &quot;rw&quot;, &quot;size_available&quot;: 449800192, &quot;size_total&quot;: 507744256 &#125;, &#123; &quot;device&quot;: &quot;/dev/mapper/vg_65-lv_home&quot;, &quot;fstype&quot;: &quot;ext4&quot;, &quot;mount&quot;: &quot;/home&quot;, &quot;options&quot;: &quot;rw&quot;, &quot;size_available&quot;: 145807802368, &quot;size_total&quot;: 153817976832 &#125; ] &#125;, &quot;changed&quot;: false&#125;[root@67 ~]# 如果想把这些 facts加入到template模板中，中途可能会遇到几处让人困扰的地方。 这边需要开启facts变量功能， gather_facts: no 或者是false是关闭，gather_facts:yes 或者是true都是开启。 当时没注意，找到了官方的实例，直接就干，结果sx了。咋都不行，总是提示define为定义。。。 原来facts没有开。。 123&#123;% for v in hostvars.iteritems() %&#125; &#123;&#123; v[&apos;ansible_hostname&apos;] &#125;&#125;&#123;% endfor %&#125; 咱们在看看对端服务器的文件渲染情况。 用过puppet saltstack的朋友，知道Variables最后可以扩展什么东西，可以高度的定义每个配置文件。 可以根据ip地址，推送配置文件所需要的绑定的ip地址，根据内存大小，定义nginx缓存的内容大小，根据你的cpu核数，做nginx cpu的绑定，根据你的系统，我需要文件路径的判断等等。。。。。 虽然这些fact够多了，貌似很全，但是如果还不够你用，还不足以让你标识定位一台服务器，咋办？ 赞一个 ansible不愧是比saltstack在国外更受欢迎的集群配置工具（据说。。。。 看了youtube的视频，几个老外说，他们热衷于去各种系统框架大会，ansible要比saltstack用的多点，其实我在有一篇文章说过，ansible为啥多？ 有兴趣翻翻看看）。 说回来，saltstack的框架确实相当的优秀，但由于更新太频繁，自己不幸又是那是yum epel的人，结果中枪了。。。。 nima，扯远了，继续聊刚才自定义fact变量，官方说的很明白， 在控制机创建一个文件就行了。。。 看懂了吧。 我刚才测试的时候，方法有些土，直接创建的，你可以参照一个例子，copy文件。 12345678- hosts: web tasks: - name: create directory for ansible custom facts file: state=directory recurse=yes path=/etc/ansible/facts.d - name: install custom impi fact copy: src=ipmi.fact dest=/etc/ansible/facts.d - name: re-read facts after adding custom fact setup: filter=ansible_local ansbile还有一个有意思的功能，可以判断上个tasks的值，根据这个值在做判断。 里面的when ， foot_result。。。。 懂了吧 1234567tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True - name: &quot;cmd&quot; action: command touch /root/kkkkk when: foo_result.rc == 127 这个是测试的过程 123456789101112131415161718192021222324252627282930313233343536373839#http://xiaorui.cc[root@67 facts.d]# ansible web -m shell -a &quot;ls /root/&quot;10.10.10.66 | success | rc=0 &gt;&gt;anaconda-ks.cfgdateinstall.loginstall.log.syslogl.pynnnqpid-python-0.20qpid-python-0.20.tar.gztestfileurllib-post.py[root@67 facts.d]# ansible-playbook cmd.yamlPLAY [web] ********************************************************************GATHERING FACTS ***************************************************************ok: [10.10.10.66]TASK: [shell /usr/bin/foo] ****************************************************failed: [10.10.10.66] =&gt; &#123;&quot;changed&quot;: true, &quot;cmd&quot;: &quot;/usr/bin/foo &quot;, &quot;delta&quot;: &quot;0:00:00.002429&quot;, &quot;end&quot;: &quot;2014-05-18 10:25:12.544151&quot;, &quot;rc&quot;: 127, &quot;start&quot;: &quot;2014-05-18 10:25:12.541722&quot;&#125;stderr: /bin/sh: /usr/bin/foo: No such file or directory...ignoringTASK: [cmd] *******************************************************************changed: [10.10.10.66]PLAY RECAP ********************************************************************10.10.10.66 : ok=3 changed=2 unreachable=0 failed=0[root@67 facts.d]# ansible web -m shell -a &quot;ls /root/&quot;10.10.10.66 | success | rc=0 &gt;&gt;anaconda-ks.cfgdateinstall.loginstall.log.syslogkkkkkl.pynnnqpid-python-0.20qpid-python-0.20.tar.gztestfileurllib-post.py[root@67 facts.d]# 好了，先这么着吧。。。。 这两天再讲解下 用ansible如何多元配置nginx、lvs keepalived的环境。 本文出自 “峰云，就她了。” 博客","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"自动化工具 ansible中文指南","slug":"ansible_abc","date":"2016-10-01T02:35:16.000Z","updated":"2017-01-09T07:58:37.000Z","comments":true,"path":"2016/10/01/ansible_abc/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/10/01/ansible_abc/","excerpt":"","text":"1. 什么是ansibleansible是个什么东西呢？官方的title是“Ansible is Simple IT Automation”——简单的自动化IT工具。这个工具的目标有这么几项：让我们自动化部署APP；自动化管理配置项；自动化的持续交付；自动化的（AWS）云服务管理。 所有的这几个目标本质上来说都是在一个台或者几台服务器上，执行一系列的命令而已。就像我之前有介绍过的Fabric，以及我们基于Fabric开发的自动化应用部署的工具： Essay 。都是做了这么个事——批量的在远程服务器上执行命令 。 那么fabric和ansible有什么差别呢？简单来说fabric像是一个工具箱，提供了很多好用的工具，用来在Remote执行命令，而Ansible则是提供了一套简单的流程，你要按照它的流程来做，就能轻松完成任务。这就像是库和框架的关系一样。 当然，它们之间也是有共同点的——都是基于 paramiko 开发的。这个paramiko是什么呢？它是一个纯Python实现的ssh协议库。因此fabric和ansible还有一个共同点就是不需要在远程主机上安装client/agents，因为它们是基于ssh来和远程主机通讯的。 2. 快速安装上面简单介绍了下这是个什么东西，怎么安装呢？也很简单，因为ansible是python开发的，因此可以这么安装: 123sudo esay_install ansible# 或者sudo pip install ansible 你也可以从github上clone最新版本，然后安装。 另外需要注意的是，控制服务器（Master）需要安装Python2.6/7，windows上无法使用ansible。被管理的服务器（Managed Node）需要安装Python2.4以上的版本，如果低于2.5，需要安装python-simplejson。 3. 配置安装完成之后，先来配置下配置项——.ansible.cfg。ansible执行的时候会按照以下顺序查找配置项: 1234* ANSIBLE_CONFIG (环境变量)* ansible.cfg (当前目录下)* .ansible.cfg (用户家目录下)* /etc/ansible/ansible.cfg 还有一个重要的配置是hosts的配置，所有的远程主机需要在hosts中配置，可以分组。当然hosts也可以执行是指定。先来一个简单的例子，在家目录下新建一个hosts文件: 123# hosts[local]127.0.0.1 然后在终端执行: 1234567$ ansible -i ~/hosts all -a &apos;who&apos;# 结果如下:127.0.0.1 | success | rc=0 &gt;&gt;Guest console Feb 1 16:29the5fire console Jan 20 19:50the5fire ttys018 Feb 22 15:35 (localhost) 这是一条ad-hoc命令——临时执行命令，ad-hoc是ansible里的一个概念, 在上面命令中就是 -a ，具体稍后再说。命令中的all是值hoss中的所有服务器，当然也可以通过 ansible -i ~/hosts local -a’who’ 这样根据组名指定服务器。 再说到ansible.cfg的配置，默认ansible执行时会从该配置中加载hosts配置，因此可以通过修改.ansible.cfg来指定默认的hosts文件地址: 123# .ansible.cfg[defaults]hostfile=/Users/the5fire/hosts 这样下次执行，就不需要 -i 参数了。 4. Ad-Hocad hoc——临时的，在ansible中是指需要快速执行，并且不需要保存的命令。说白了就是执行简单的命令——一条命令。对于复杂的命令后面会说playbook。 那么这个Ad-Hoc命令怎么用呢？上面已经简单的示范了下。在ansible中还有一个Module（模块）的概念，这个模块可以理解为一个库，所有的命令都需要通过模块来执行，比如上面的那个命令: ansible-i ~/hosts all -a ‘who’ ，其实是调用了默认的command模块: ansible -i ~/hosts all -mcommand -a ‘who’ ,除了command模块还有其他很多模块，比如你就想ping下这个服务器是不是还存在可以通过ping模块: ansible -i ~/hosts all -m ping 。 还有几个参数需要记录下: 123-u username # 指定ssh连接的用户名-f 10 # 指定并发数--sudo [-K] # 如果需要root权限执行的话，-K参数是用来输入root密码的 你可以通过各种模块来批量完成某个包的安装，或者其他什么需要的操作。 更多模块可以看官网文档: modules 关于Ad-Hoc的更多内容参考这里: intro_adhoc 5. 简单Playbook上面的ad hoc是指执行一条临时的不需要保存的命令，那么复杂的命令怎么执行呢？因此也就有了playbook这个命令: ansible-playbook 。 playbook（剧本），顾名思义，就是需要定义一个脚本或者说配置文件，然后定义好做什么。一个简单的playbook是这样的，把当前用户名输出到whoami.rst文件中: 1234567# playbook.yml---- hosts: local # hosts中指定 remote_user: the5fire # 如果和当前用户一样，则无需指定 tasks: - name: whoami shell: &apos;whoami &gt; whoami.rst&apos; 执行完这个命令后，你可以在local所代表的服务器的用户目录下发现这么个文件。说道这里，要停一下。这个配置文件是yaml格式的，因此你可能需要去了解下YAML： wiki YAML 。 简单解释下上面的playbook，hosts后面根据local是从hosts中读取的，tasks是是关键词，指明了要执行哪些任务；下面的name是任务的名称，shell是前面提到的module(模块)，单引号中是命令。 除了tasks之外，还有一个handlers的命令，handlers是在执行tasks之后服务器发生变化之后可供调用的handler，使用起来如下: 123456789101112# playbook.yml---- hosts: local # hosts中指定 remote_user: the5fire # 如果和当前用户一样，则无需指定 tasks: - name: whoami copy: src=~/hosts dest=~/hosts.dest # 本地拷贝到远端 notify: # 如果copy执行完之后~/hosts.dest文件发送了变化，则执行 - clear copy # 调用handler handlers: - name: clear copy shell: &apos;mv ~/hosts.dest hosts.del&apos; # 假装删除 上面只是一个演示，再来一个真实的功能——在local服务器上，从git上clone下来我的blog源码，然后创建虚拟环境，创建数据库，最后运行: 1234567891011121314151617# deploy-blog-simple.yml---- hosts: local # hosts中指定remote_user: the5fire # 如果和当前用户一样，则无需指定tasks: - name: check out django_blog git: dest=~/demos/django_selfblog repo=https://github.com/the5fire/django_selfblog update=yes - name: make virtualenv shell: &apos;virtualenv ~/demos&apos; - name: install requirements pip: requirements=~/demos/django_selfblog/requirements.txt virtualenv=~/demos - name: init database shell: . ./bin/activate &amp;&amp; cd django_selfblog/selfblog &amp;&amp; ./init_database.sh chdir=~/demos - name: run manage.py shell: . ./bin/activate &amp;&amp; cd django_selfblog/selfblog &amp;&amp; ./run.sh chdir=~/demos 如果你已经配置好ssh账户免密码登录之后，直接执行: ansible-playbookdeploy-blog-simple.yml 就可以在你指定的服务器上部署，并启动blog了。 好了，关于ansible的使用，到这里应该先告一段落了，后面还有一些稍微复杂点的概念：role和include。以后有时间再补充一个续。 在写最后一个playbook的时候，为了最后能正常启动blog程序，花了小半天时间把ansible的代码看了下，下一篇来分享下ansbile里面的一些原理性的东西。","categories":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://plpcm.github.io/blog/tags/devops/"},{"name":"ansible","slug":"ansible","permalink":"https://plpcm.github.io/blog/tags/ansible/"}]},{"title":"网站统计中的数据收集原理及实现","slug":"web-analysis","date":"2016-04-04T02:30:16.000Z","updated":"2016-12-06T10:54:55.000Z","comments":true,"path":"2016/04/04/web-analysis/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/04/04/web-analysis/","excerpt":"","text":"网站数据统计分析工具是网站站长和运营人员经常使用的一种工具，比较常用的有谷歌分析、百度统计和腾讯分析等等。所有这些统计分析工具的第一步都是网站访问数据的收集。目前主流的数据收集方式基本都是基于javascript的。本文将简要分析这种数据收集的原理，并一步一步实际搭建一个实际的数据收集系统。 数据收集原理分析简单来说，网站统计分析工具需要收集到用户浏览目标网站的行为（如打开某网页、点击某按钮、将商品加入购物车等）及行为附加数据（如某下单行为产生的订单金额等）。早期的网站统计往往只收集一种用户行为：页面的打开。而后用户在页面中的行为均无法收集。这种收集策略能满足基本的流量分析、来源分析、内容分析及访客属性等常用分析视角，但是，随着ajax技术的广泛使用及电子商务网站对于电子商务目标的统计分析的需求越来越强烈，这种传统的收集策略已经显得力不能及。 后来，Google在其产品谷歌分析中创新性的引入了可定制的数据收集脚本，用户通过谷歌分析定义好的可扩展接口，只需编写少量的javascript代码就可以实现自定义事件和自定义指标的跟踪和分析。目前百度统计、搜狗分析等产品均照搬了谷歌分析的模式。 其实说起来两种数据收集模式的基本原理和流程是一致的，只是后一种通过javascript收集到了更多的信息。下面看一下现在各种网站统计工具的数据收集基本原理。 流程概览首先通过一幅图总体看一下数据收集的基本流程。 图1. 网站统计数据收集基本流程 首先，用户的行为会触发浏览器对被统计页面的一个http请求，这里姑且先认为行为就是打开网页。当网页被打开，页面中的埋点javascript片段会被执行，用过相关工具的朋友应该知道，一般网站统计工具都会要求用户在网页中加入一小段javascript代码，这个代码片段一般会动态创建一个script标签，并将src指向一个单独的js文件，此时这个单独的js文件（图1中绿色节点）会被浏览器请求到并执行，这个js往往就是真正的数据收集脚本。数据收集完成后，js会请求一个后端的数据收集脚本（图1中的backend），这个脚本一般是一个伪装成图片的动态脚本程序，可能由php、python或其它服务端语言编写，js会将收集到的数据通过http参数的方式传递给后端脚本，后端脚本解析参数并按固定格式记录到访问日志，同时可能会在http响应中给客户端种植一些用于追踪的cookie。 上面是一个数据收集的大概流程，下面以谷歌分析为例，对每一个阶段进行一个相对详细的分析。 埋点脚本执行阶段若要使用谷歌分析（以下简称GA），需要在页面中插入一段它提供的javascript片段，这个片段往往被称为埋点代码。下面是我的博客中所放置的谷歌分析埋点代码截图： 图2. 谷歌分析埋点代码 其中_gaq是GA的的全局数组，用于放置各种配置，其中每一条配置的格式为： 1_gaq.push([&apos;Action&apos;,&apos;param1&apos;,&apos;param2&apos;,...]); Action指定配置动作，后面是相关的参数列表。GA给的默认埋点代码会给出两条预置配置，_setAccount用于设置网站标识ID，这个标识ID是在注册GA时分配的。_trackPageview告诉GA跟踪一次页面访问。更多配置请参考：https://developers.google.com/analytics/devguides/collection/gajs/。实际上，这个_gaq是被当做一个FIFO队列来用的，配置代码不必出现在埋点代码之前，具体请参考上述链接的说明。 就本文来说，_gaq的机制不是重点，重点是后面匿名函数的代码，这才是埋点代码真正要做的。这段代码的主要目的就是引入一个外部的js文件（ga.js），方式是通过document.createElement方法创建一个script并根据协议（http或https）将src指向对应的ga.js，最后将这个element插入页面的dom树上。 注意ga.async = true的意思是异步调用外部js文件，即不阻塞浏览器的解析，待外部js下载完成后异步执行。这个属性是HTML5新引入的。 数据收集脚本执行阶段数据收集脚本（ga.js）被请求后会被执行，这个脚本一般要做如下几件事： 1、通过浏览器内置javascript对象收集信息，如页面title（通过document.title）、referrer（上一跳url，通过document.referrer）、用户显示器分辨率（通过windows.screen）、cookie信息（通过document.cookie）等等一些信息。 2、解析_gaq收集配置信息。这里面可能会包括用户自定义的事件跟踪、业务数据（如电子商务网站的商品编号等）等。 3、将上面两步收集的数据按预定义格式解析并拼接。 4、请求一个后端脚本，将信息放在http request参数中携带给后端脚本。 这里唯一的问题是步骤4，javascript请求后端脚本常用的方法是ajax，但是ajax是不能跨域请求的。这里ga.js在被统计网站的域内执行，而后端脚本在另外的域（GA的后端统计脚本是http://www.google-analytics.com/__utm.gif），ajax行不通。一种通用的方法是js脚本创建一个Image对象，将Image对象的src属性指向后端脚本并携带参数，此时即实现了跨域请求后端。这也是后端脚本为什么通常伪装成gif文件的原因。通过http抓包可以看到ga.js对__utm.gif的请求： 图3. 后端脚本请求的http包 可以看到ga.js在请求__utm.gif时带了很多信息，例如utmsr=1280×1024是屏幕分辨率，utmac=UA-35712773-1是_gaq中解析出的我的GA标识ID等等。 值得注意的是，__utm.gif未必只会在埋点代码执行时被请求，如果用_trackEvent配置了事件跟踪，则在事件发生时也会请求这个脚本。 由于ga.js经过了压缩和混淆，可读性很差，我们就不分析了，具体后面实现阶段我会实现一个功能类似的脚本。 后端脚本执行阶段GA的__utm.gif是一个伪装成gif的脚本。这种后端脚本一般要完成以下几件事情： 1、解析http请求参数的到信息。 2、从服务器（WebServer）中获取一些客户端无法获取的信息，如访客ip等。 3、将信息按格式写入log。 5、生成一副1×1的空gif图片作为响应内容并将响应头的Content-type设为image/gif。 5、在响应头中通过Set-cookie设置一些需要的cookie信息。 之所以要设置cookie是因为如果要跟踪唯一访客，通常做法是如果在请求时发现客户端没有指定的跟踪cookie，则根据规则生成一个全局唯一的cookie并种植给用户，否则Set-cookie中放置获取到的跟踪cookie以保持同一用户cookie不变（见图4）。 图4. 通过cookie跟踪唯一用户的原理 这种做法虽然不是完美的（例如用户清掉cookie或更换浏览器会被认为是两个用户），但是是目前被广泛使用的手段。注意，如果没有跨站跟踪同一用户的需求，可以通过js将cookie种植在被统计站点的域下（GA是这么做的），如果要全网统一定位，则通过后端脚本种植在服务端域下（我们待会的实现会这么做）。 系统的设计实现根据上述原理，我自己搭建了一个访问日志收集系统。总体来说，搭建这个系统要做如下的事： 图5. 访问数据收集系统工作分解 下面详述每一步的实现。我将这个系统叫做MyAnalytics。 确定收集的信息为了简单起见，我不打算实现GA的完整数据收集模型，而是收集以下信息。 名称 途径 备注 访问时间 web server Nginx $msec IP web server Nginx $remote_addr 域名 javascript document.domain URL javascript document.URL 页面标题 javascript document.title 分辨率 javascript window.screen.height &amp; width 颜色深度 javascript window.screen.colorDepth Referrer javascript document.referrer 浏览客户端 web server Nginx $http_user_agent 客户端语言 javascript navigator.language 访客标识 cookie 网站标识 javascript 自定义对象 埋点代码埋点代码我将借鉴GA的模式，但是目前不会将配置对象作为一个FIFO队列用。一个埋点代码的模板如下： 12345678910&lt;script type=&quot;text/javascript&quot;&gt;var _maq = _maq || [];_maq.push([&apos;_setAccount&apos;, &apos;网站标识&apos;]); (function() &#123; var ma = document.createElement(&apos;script&apos;); ma.type =&apos;text/javascript&apos;; ma.async = true; ma.src = (&apos;https:&apos; == document.location.protocol ?&apos;https://analytics&apos; : &apos;http://analytics&apos;) + &apos;.codinglabs.org/ma.js&apos;; var s = document.getElementsByTagName(&apos;script&apos;)[0]; s.parentNode.insertBefore(ma, s);&#125;)();&lt;/script&gt; 这里我启用了二级域名analytics.codinglabs.org，统计脚本的名称为ma.js。当然这里有一点小问题，因为我并没有https的服务器，所以如果一个https站点部署了代码会有问题，不过这里我们先忽略吧。 前端统计脚本我写了一个不是很完善但能完成基本工作的统计脚本ma.js： 1234567891011121314151617181920212223242526272829303132333435363738394041424344(function () &#123; var params = &#123;&#125;; //Document对象数据 if(document) &#123; params.domain = document.domain || &apos;&apos;; params.url = document.URL || &apos;&apos;; params.title = document.title || &apos;&apos;; params.referrer = document.referrer || &apos;&apos;; &#125; //Window对象数据 if(window &amp;&amp; window.screen) &#123; params.sh = window.screen.height || 0; params.sw = window.screen.width || 0; params.cd = window.screen.colorDepth || 0; &#125; //navigator对象数据 if(navigator) &#123; params.lang = navigator.language || &apos;&apos;; &#125; //解析_maq配置 if(_maq) &#123; for(var i in _maq) &#123; switch(_maq[i][0]) &#123; case &apos;_setAccount&apos;: params.account = _maq[i][1]; break; default: break; &#125; &#125; &#125; //拼接参数串 var args = &apos;&apos;; for(var i in params) &#123; if(args != &apos;&apos;) &#123; args += &apos;&amp;&apos;; &#125; args += i + &apos;=&apos; + encodeURIComponent(params[i]); &#125; //通过Image对象请求后端脚本 var img = new Image(1, 1); img.src = &apos;http://analytics.codinglabs.org/1.gif?&apos; + args;&#125;)(); 整个脚本放在匿名函数里，确保不会污染全局环境。功能在原理一节已经说明，不再赘述。其中1.gif是后端脚本。 日志格式日志采用每行一条记录的方式，采用不可见字符^A（ascii码0×01，Linux下可通过ctrl + v ctrl + a输入，下文均用“^A”表示不可见字符0×01），具体格式如下： 时间^AIP^A域名^AURL^A页面标题^AReferrer^A分辨率高^A分辨率宽^A颜色深度^A语言^A客户端信息^A用户标识^A网站标识 后端脚本为了简单和效率考虑，我打算直接使用nginx的access_log做日志收集，不过有个问题就是nginx配置本身的逻辑表达能力有限，所以我选用了OpenResty做这个事情。OpenResty是一个基于Nginx扩展出的高性能应用开发平台，内部集成了诸多有用的模块，其中的核心是通过ngx_lua模块集成了Lua，从而在nginx配置文件中可以通过Lua来表述业务。关于这个平台我这里不做过多介绍，感兴趣的同学可以参考其官方网站http://openresty.org/，或者这里有其作者章亦春（agentzh）做的一个非常有爱的介绍OpenResty的slide：http://agentzh.org/misc/slides/ngx-openresty-ecosystem/，关于ngx_lua可以参考：https://github.com/chaoslawful/lua-nginx-module。 首先，需要在nginx的配置文件中定义日志格式： 123log_format tick&quot;$msec^A$remote_addr^A$u_domain^A$u_url^A$u_title^A$u_referrer^A$u_sh^A$u_sw^A$u_cd^A$u_lang^A$http_user_agent^A$u_utrace^A$u_account&quot;; 注意这里以u_开头的是我们待会会自己定义的变量，其它的是nginx内置变量。 然后是核心的两个location： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253location /1.gif &#123;#伪装成gif文件 default_type image/gif;#本身关闭access_log，通过subrequest记录log access_log off; access_by_lua \" -- 用户跟踪cookie名为__utrace local uid = ngx.var.cookie___utrace if not uid then -- 如果没有则生成一个跟踪cookie，算法为md5(时间戳+IP+客户端信息) uid = ngx.md5(ngx.now() .. ngx.var.remote_addr .. ngx.var.http_user_agent) end ngx.header['Set-Cookie'] = &#123;'__utrace=' .. uid .. '; path=/'&#125; if ngx.var.arg_domain then -- 通过subrequest到/i-log记录日志，将参数和用户跟踪cookie带过去 ngx.location.capture('/i-log?' .. ngx.var.args .. '&amp;utrace=' .. uid) end \"; #此请求不缓存 add_header Expires \"Fri, 01 Jan 1980 00:00:00 GMT\"; add_header Pragma \"no-cache\"; add_header Cache-Control \"no-cache, max-age=0, must-revalidate\"; #返回一个1×1的空gif图片 empty_gif;&#125;location /i-log &#123; #内部location，不允许外部直接访问 internal; #设置变量，注意需要unescape set_unescape_uri $u_domain $arg_domain; set_unescape_uri $u_url $arg_url; set_unescape_uri $u_title $arg_title; set_unescape_uri $u_referrer $arg_referrer; set_unescape_uri $u_sh $arg_sh; set_unescape_uri $u_sw $arg_sw; set_unescape_uri $u_cd $arg_cd; set_unescape_uri $u_lang $arg_lang; set_unescape_uri $u_utrace $arg_utrace; set_unescape_uri $u_account $arg_account; #打开日志 log_subrequest on; #记录日志到ma.log，实际应用中最好加buffer，格式为tick access_log /path/to/logs/directory/ma.log tick; #输出空字符串 echo '';&#125; 要完全解释这段脚本的每一个细节有点超出本文的范围，而且用到了诸多第三方ngxin模块（全都包含在OpenResty中了），重点的地方我都用注释标出来了，可以不用完全理解每一行的意义，只要大约知道这个配置完成了我们在原理一节提到的后端逻辑就可以了。 日志轮转真正的日志收集系统访问日志会非常多，时间一长文件变得很大，而且日志放在一个文件不便于管理。所以通常要按时间段将日志切分，例如每天或每小时切分一个日志。我这里为了效果明显，每一小时切分一个日志。我是通过crontab定时调用一个shell脚本实现的，shell脚本如下： 1234567891011_prefix=\"/path/to/nginx\"time=`date +%Y%m%d%H` mv $&#123;_prefix&#125;/logs/ma.log $&#123;_prefix&#125;/logs/ma/ma-$&#123;time&#125;.logkill -USR1 `cat $&#123;_prefix&#125;/logs/nginx.pid`&lt;/div&gt;这个脚本将ma.log移动到指定文件夹并重命名为ma-&#123;yyyymmddhh&#125;.log，然后向nginx发送USR1信号令其重新打开日志文件。然后再/etc/crontab里加入一行：59**** root /path/to/directory/rotatelog.sh 在每个小时的59分启动这个脚本进行日志轮转操作。 测试下面可以测试这个系统是否能正常运行了。我昨天就在我的博客中埋了相关的点，通过http抓包可以看到ma.js和1.gif已经被正确请求： 图6. http包分析ma.js和1.gif的请求 同时可以看一下1.gif的请求参数： 图7. 1.gif的请求参数 相关信息确实也放在了请求参数中。 然后我tail打开日志文件，然后刷新一下页面，因为没有设access log buffer， 我立即得到了一条新日志： 11351060731.360^A0.0.0.0^Awww.codinglabs.org^Ahttp://www.codinglabs.org/^ACodingLabs^A^A1024^A1280^A24^Azh-CN^AMozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.4 (KHTML, like Gecko) Chrome/22.0.1229.94 Safari/537.4^A4d612be64366768d32e623d594e82678^AU-1-1 注意实际上原日志中的^A是不可见的，这里我用可见的^A替换为方便阅读，另外IP由于涉及隐私我替换为了0.0.0.0。 看一眼日志轮转目录，由于我之前已经埋了点，所以已经生成了很多轮转文件： 关于分析通过上面的分析和开发可以大致理解一个网站统计的日志收集系统是如何工作的。有了这些日志，就可以进行后续的分析了。本文只注重日志收集，所以不会写太多关于分析的东西。 注意，原始日志最好尽量多的保留信息而不要做过多过滤和处理。例如上面的MyAnalytics保留了毫秒级时间戳而不是格式化后的时间，时间的格式化是后面的系统做的事而不是日志收集系统的责任。后面的系统根据原始日志可以分析出很多东西，例如通过IP库可以定位访问者的地域、user agent中可以得到访问者的操作系统、浏览器等信息，再结合复杂的分析模型，就可以做流量、来源、访客、地域、路径等分析了。当然，一般不会直接对原始日志分析，而是会将其清洗格式化后转存到其它地方，如MySQL或HBase中再做分析。 分析部分的工作有很多开源的基础设施可以使用，例如实时分析可以使用Storm，而离线分析可以使用Hadoop。当然，在日志比较小的情况下，也可以通过shell命令做一些简单的分析，例如，下面三条命令可以分别得出我的博客在今天上午8点到9点的访问量（PV），访客数（UV）和独立IP数（IP）：123awk -F^A '&#123;print $1&#125;' ma-2012102409.log | wc -lawk -F^A '&#123;print $12&#125;' ma-2012102409.log | uniq | wc -lawk -F^A '&#123;print $2&#125;' ma-2012102409.log | uniq | wc -l 其它好玩的东西朋友们可以慢慢挖掘。 参考GA的开发者文档：https://developers.google.com/analytics/devguides/collection/gajs/一篇关于实现nginx收日志的文章:http://blog.linezing.com/2011/11/%E4%BD%BF%E7%94%A8nginx%E8%AE%B0%E6%97%A5%E5%BF%97关于Nginx可以参考：http://wiki.nginx.org/MainOpenResty的官方网站为：http://openresty.orgngx_lua模块可参考：https://github.com/chaoslawful/lua-nginx-module本文http抓包使用Chrome浏览器开发者工具，绘制思维导图使用Xmind，流程和结构图使用Tikz PGF","categories":[{"name":"analysis","slug":"analysis","permalink":"https://plpcm.github.io/blog/categories/analysis/"}],"tags":[{"name":"openresty","slug":"openresty","permalink":"https://plpcm.github.io/blog/tags/openresty/"},{"name":"analysis","slug":"analysis","permalink":"https://plpcm.github.io/blog/tags/analysis/"},{"name":"web","slug":"web","permalink":"https://plpcm.github.io/blog/tags/web/"},{"name":"nginxlog","slug":"nginxlog","permalink":"https://plpcm.github.io/blog/tags/nginxlog/"},{"name":"ga","slug":"ga","permalink":"https://plpcm.github.io/blog/tags/ga/"}]},{"title":"Nginx虚拟主机根据不同的域名使用不同的root路径","slug":"nginx-var-root","date":"2016-03-12T07:33:16.000Z","updated":"2016-12-02T10:07:55.000Z","comments":true,"path":"2016/03/12/nginx-var-root/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/03/12/nginx-var-root/","excerpt":"","text":"一 应用场景描述应开发同事需求，需要在开发环境的Nginx能够根据不同的域名使用不同的root路径。例如如果域名是 aa.abc.com,就使用root路径为/data/public/aa bb.abc.com,就使用root路径为/data/public/bb cc.abc.com,就是用root路径为/data/public/cc 二 解决方法123456789101112131415161718192021222324252627server&#123; listen 80; server_name *.abc.com; set $path_name aa; if ($host ~ \"bb\") &#123; set $path_name bb; &#125; if ($host ~ \"cc\") &#123; set $path_name cc; &#125; root /data/public/$path_name/; location / &#123; if (!-e $request_filename)&#123; rewrite /(.*) /index.php last; &#125; index index.php; &#125; location ~ .php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125; 这里设置变量$path_name,然后在root路径中使用这个变量 三 相关Nginx指令介绍 set指令用于定义一个变量，并为变量赋值作用范围为if,location,server如以上的set $path_name aa; if指令if(condition) {…}作用范围为如： 1234if ($host ~ &quot;bb&quot;)&#123;set $path_name bb;&#125; if指令用于检查一个条件是否符合，如果条件符合，则执行大括号内的内容。if指令不支持嵌套，不支持多个&amp;&amp;或||可以指定的条件为： 123456781）变量名2）变量比较可以使用 =（等于）和!=（不等于）3）正则表达式匹配可以使用 ~（区分大小写匹配）和 ~* （不区分大小写匹配） !~ 和 !~* 则表示不匹配4）-f和!-f 用来判断文件是否存在5) -d和!-d 用来判断目录是否存在6) -e和!-e 用来判断文件或目录是否存在7）-x和!-x 用来判断文件是否可以执行 Nginx内置变量 12$host 请求的主机名$request_filename 请求的文件名 rewrite指令 1rewrite regex replacement flag; 用来重定向URL 123if (!-e $request_filename)&#123;rewrite /(.*) /index.php last;&#125; rewrite最后一项为标记位，Nginx支持的标记为有： 1234last 表示完成rewritepermanent 返回301永久重定向，浏览器地址栏会显示跳转后的URLbreak 本条规则匹配完成后，终止其他规则的匹配redirect 返回302临时重定向 last和break完成URL的重定向，浏览器上的地址不会变，但在服务器端上的位置发生了变化。permanent和redirect用来实现URL跳转，浏览器地址栏会显示跳转后的URL。使用alias指令时必须使用last指令，使用proxy_pass指令时必须使用break指令","categories":[{"name":"nginx","slug":"nginx","permalink":"https://plpcm.github.io/blog/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://plpcm.github.io/blog/tags/nginx/"}]},{"title":"使用OpenResty搭建验证码服务器","slug":"openresty-luagd-checkcode","date":"2016-03-05T02:30:16.000Z","updated":"2016-12-07T09:50:16.000Z","comments":true,"path":"2016/03/05/openresty-luagd-checkcode/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/03/05/openresty-luagd-checkcode/","excerpt":"","text":"使用openresty可以很容易的实现生成验证码功能。Lua下有个Lua-GD图形库，通过简单的Lua语句就能控制、生成图片。 环境说明： 操作系统：RHEL6.4 RHEL系统默认已安装RPM包的Lua-5.1.4，但其只具有Lua基本功能，不提供 lua.h 等，但 Lua-GD 编译需要用到 lua.h，故 Lua 需要编译安装。 Lua-GD 版本号格式为X.Y.XrW，其中X.Y.Z代表gd版本，W代表效力版本，所以 lua-gd 版本：lua-gd-2.0.33r2 相对应 gd 版本为：gd-2.0.33，须注意保持一致。 因生成gif的lua脚本中用到md5加密，故需编译安装md5。 因为生成图片需要唯一命名，故依赖 UUID 另外： 以下操作均以root用户运行，并且以下脚本的当前目录为/opt，即所有的下载的文件都会保存在/opt目录下。 需要安装的软件如下： OpenResty：WEB应用服务器，部署lua代码，提供URL供用户调用和访问 LuaJIT：LUA代码解释器，使用OpenResty中集成的版本 GD库：C图形库 Lua-GD库：Lua绑定的C图形库，使得lua可调用gd Lua-Resty-UUID库：用于生成UUID，保证图片命名唯一性 LuaSocket：lua 的 socket 库 安装lua安装编译所需软件包: 1$ yum install -y make gcc 下载并编译安装 lua-5.1： 123456$ yum install -y readline-devel$ wget http://www.lua.org/ftp/lua-5.1.4.tar.gz$ tar lua-5.1.4.tar.gz$ cd lua-5.1.4$ make linux$ make linux install 安装 gdGD版本：gd-2.0.33 下载地址: http://www.boutell.com/gd/http/gd-2.0.33.tar.gz 1234567$ yum install -y libjpeg-devel libpng-devel freetype-devel fontconfig-devel libXpm-devel$ wget http://www.boutell.com/gd/http/gd-2.0.33.tar.gz$ tar zvxf gd-2.0.33.tar.gz$ cd gd-2.0.33$ ./configure$ make &amp;&amp; make install 安装 Lua-gd 库Lua-GD版本：lua-gd-2.0.33r2 下载地址: http://jaist.dl.sourceforge.net/project/lua-gd/lua-gd/lua-gd-2.0.33r2%20%28for%20Lua%205.1%29/lua-gd-2.0.33r2.tar.gz 开发手册可参考: http://ittner.github.io/lua-gd/manual.html 说明： 须先完成gd的安装，且版本号必须为gd-2.0.33 调用Lua-GD库的lua代码须由OpenResty中集成的LuaJIT解释执行 123$ wget http://jaist.dl.sourceforge.net/project/lua-gd/lua-gd/lua-gd-2.0.33r2%20%28for%20Lua%205.1%29/lua-gd-2.0.33r2.tar.gz$ tar zvxf lua-gd-2.0.33r2.tar.gz$ cd lua-gd-2.0.33r2 接写来修改Makefile文件： 注释第36～42行 打开第48～52行注释，并做如下修改 1234567OUTFILE=gd.soCFLAGS=-Wall `gdlib-config --cflags` -I/usr/local/include/lua -O3 //第49行，修改 lua 的 C 库头文件所在路径GDFEATURES=`gdlib-config --features |sed -e \"s/GD_/-DGD_/g\"`LFLAGS=-shared `gdlib-config --ldflags` `gdlib-config --libs` -llua -lgd //第51行，取消lua库版本号51INSTALL_PATH=/usr/local/lib/lua/5.1 //第52行，设置 gd.so 的安装路径$(CC) -fPIC -o ... //第70行，gcc 编译，添加 -fPIC 参数 然后编译： 1$ make &amp;&amp; make install 安装 md5123456$ yum install unzip$ wget https://github.com/keplerproject/md5/archive/master.zip -O md5-master.zip$ unzip md5-master.zip$ cd md5-master$ make &amp;&amp; make install 安装 Lua-resty-UUID 库调用系统的UUID模块生成的由32位16进制（0-f）数组成的的串，本模块进一步压缩为62进制。正如你所想，生成的UUID越长，理论冲突率就越小，请根据业务需要自行斟酌。 基本思想为把系统生成的16字节（128bit）的UUID转换为62进制（a-zA-Z0-9），同时根据业务需要进行截断。 下载地址: https://github.com/dcshi/lua-resty-UUID/archive/master.zip 12345$ yum -y install libuuid-devel$ wget https://github.com/dcshi/lua-resty-UUID/archive/master.zip -O lua-resty-UUID-master.zip$ unzip lua-resty-UUID-master.zip$ cd lua-resty-UUID-master/clib$ make 下载nginx sysguard模块 如果nginx被攻击或者访问量突然变大，nginx会因为负载变高或者内存不够用导致服务器宕机，最终导致站点无法访问。 今天要谈到的解决方法来自淘宝开发的模块nginx-http-sysguard，主要用于当负载和内存达到一定的阀值之时，会执行相应的动作，比如直接返回503,504或者其他的。一直等到内存或者负载回到阀值的范围内，站点恢复可用。简单的说，这几个模块是让nginx有个缓冲时间，缓缓。 12$ wget https://github.com/alibaba/nginx-http-sysguard/archive/master.zip -O nginx-http-sysguard-master.zip$ unzip nginx-http-sysguard-master.zip 安装 OpenResty OpenResty（也称为 ngx_openresty）是一个全功能的 Web 应用服务器。它打包了标准的 Nginx 核心，很多的常用的第三方模块，以及它们的大多数依赖项。 OpenResty 中的 LuaJIT 组件默认未激活，需使用 --with-luajit 选项在编译 OpenResty 时激活,使用--add-module，添加上sysguard模块 安装的版本：1.2.7.6 下载地址： http://openresty.org/#Download http://openresty.org/download/ngx_openresty-1.2.7.6.tar.gz 先安装依赖软件，然后在编译代码，编译时使用--perfix选项指定 OpenResty 的安装目录，--with-luajit 选项激活 LuaJIT 组件。 1234567$ yum -y install gcc make gmake openssl-devel pcre-devel readline-devel zlib-devel$ wget http://openresty.org/download/ngx_openresty-1.2.7.6.tar.gz$ tar zvxf ngx_openresty-1.2.7.6.tar.gz$ cd ngx_openresty-1.2.7.6$ ./configure --with-luajit --with-http_stub_status_module --add-module=/opt/nginx-http-sysguard-master/$ gmake &amp;&amp; gmake install 创建软连接： 1$ ln -s /usr/local/openresty/nginx/sbin/nginx /usr/sbin/nginx 安装 Redis Server Lua 脚本功能是 Reids 2.6 版本的最大亮点， 通过内嵌对 Lua 环境的支持， Redis 解决了长久以来不能高效地处理 CAS （check-and-set）命令的缺点， 并且可以通过组合使用多个命令， 轻松实现以前很难实现或者不能高效实现的模式。 1234567$ wget http://redis.googlecode.com/files/redis-2.6.14.tar.gz$ tar zvxf redis-2.6.14.tar.gz$ cd redis-2.6.14$ make &amp;&amp; make install$ mkdir -p /usr/local/redis/conf$ cp redis.conf /usr/local/redis/conf/ 安装 LuaSocket 库 LuaSocket是一个Lua扩展库，它能很方便地提供SMTP、HTTP、FTP等网络议访问操作。 LuaSocket版本：luasocket-2.0-beta2 下载地址: http://files.luaforge.net/releases/luasocket/luasocket/luasocket-2.0-beta2/luasocket-2.0-beta2.tar.gz 1234$ wget http://files.luaforge.net/releases/luasocket/luasocket/luasocket-2.0.2/luasocket-2.0.2.tar.gz$ tar zvxf luasocket-2.0.2.tar.gz$ cd luasocket-2.0.2$ make -f makefile.Linux 安装 redis-lua 库Redis-Lua版本：2.0 下载地址: https://github.com/nrk/redis-lua/archive/version-2.0.zip 123$ wget https://github.com/nrk/redis-lua/archive/version-2.0.zip$ unzip redis-lua-version-2.0.zip$ cd redis-lua-version-2.0 然后，拷贝redis.lua至所需目录。 lua调用方式如下： 1local redis = require(“redis”) 安装 zklua zklua 仅依赖 zookeeper c API 实现，一般存在于 zookeeper-X.Y.Z/src/c， 因此你需要首先安装 zookeeper c API。 zookeeper c API 安装: 12345$ wget http://apache.fayea.com/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz$ tar zvxf zookeeper-3.4.9$ cd zookeeper-3.4.9/src/c$ ./configure$ make &amp;&amp; make install 然后安装zklua： 1234$ wget https://github.com/forhappy/zklua/archive/master.zip -O zklua-master.zip$ unzip zklua-master.zip$ cd zklua-master$ make &amp;&amp; make install 修改配置文件配置openrestyopenresty安装在/usr/local/openresty目录，在其目录下创建lualib，用于存放上面安装的一些动态连接库 1234567891011mkdir -p /usr/local/openresty/lualib/captchacp lua-resty-UUID-master/clib/libuuidx.so /usr/local/openresty/lualib/captcha/ #拷贝uuid的库文件cp -r lua-resty-UUID-master/lib/* /usr/local/openresty/lualib/captcha/cp luasocket-2.0.2/luasocket.so.2.0 /usr/local/openresty/lualib/captcha/ #拷贝luasocket的库文件到/usr/local/openresty/lualib/captcha/ln -s /usr/local/openresty/lualib/captcha/luasocket.so.2.0 /usr/local/openresty/lualib/captcha/socket.socp redis-lua-version-2.0/src/redis.lua /usr/local/openresty/lualib/captcha/ #拷贝reis.lua到/usr/local/openresty/lualib/captcha/mkdir -p /usr/local/openresty/lualib/zklua #拷贝zklua文件到/usr/local/openresty/lualib/captcha/cp cd zklua-master/zklua.so /usr/local/openresty/lualib/zklua/ 配置nginx创建www用户： 1useradd -M -s /sbin/nologin www 编辑ngnix.conf，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113 user www; worker_processes 31; error_log logs/error.log; pid logs/nginx.pid; worker_rlimit_nofile 65535; events &#123; worker_connections 1024; use epoll; &#125; http &#123; include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; gzip on; gzip_min_length 1K; gzip_buffers 4 8k; gzip_comp_level 2; gzip_types text/plain image/gif image/png image/jpg application/x-javascript text/css application/xml text/javascript; gzip_vary on; upstream redis-pool&#123; server 127.0.0.1:10005; keepalive 1024; &#125; server &#123; sysguard on; sysguard_load load=90 action=/50x.html; server_tokens off; listen 10002; server_name localhost; charset utf-8; location / &#123; root html; index index.html index.htm; &#125; #----------------------------------------------------------------------------------------- # 验证码生成 location /captcha &#123; set $percent 0; set $modecount 1; content_by_lua_file /usr/local/openresty/nginx/luascripts/luajit/captcha.lua; &#125; #----------------------------------------------------------------------------------------- # 验证码校验 location /captcha-check &#123; content_by_lua_file /usr/local/openresty/nginx/luascripts/luajit/captcha-check.lua; &#125; # 验证码删除 location /captcha-delete &#123; content_by_lua_file /usr/local/openresty/nginx/luascripts/luajit/captcha-delete.lua; &#125; #----------------------------------------------------------------------------------------- # 样式1-静态图片 location /mode1 &#123; content_by_lua_file /usr/local/openresty/nginx/luascripts/luajit/mode/mode1.lua; &#125; #----------------------------------------------------------------------------------------- # redis中添加key-value location /redisSetQueue &#123; internal; set_unescape_uri $key $arg_key; set_unescape_uri $val $arg_val; redis2_query rpush $key $val; redis2_pass redis-pool; &#125; # redis中获取captcha-string location /redisGetStr &#123; internal; set_unescape_uri $key $arg_key; redis2_query lindex $key 0; redis2_pass redis-pool; &#125; # redis中获取captcha-image location /redisGetImg &#123; internal; set_unescape_uri $key $arg_key; redis2_query lindex $key 1; redis2_pass redis-pool; &#125; #----------------------------------------------------------------------------------------- location ~.*.(gif|jpg|png)$ &#123; expires 10s; &#125; error_page 404 /404.html; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 上面将 ngnix 的端口修改为10002。 /usr/local/openresty/nginx/luascripts/luajit/captcha.lua 是用于生成验证码，内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061--中控脚本----部分应用预先生成--部分应用实时生成，并且随机选择生成样式------------------------------------------------------------------------------------------------package.path = \"/usr/local/openresty/lualib/?.lua;/usr/local/openresty/lualib/captcha/?.lua;\"package.cpath = \"/usr/local/openresty/lualib/?.so;/usr/local/openresty/lualib/captcha/?.so;\"------------------------------------------------------------------------------------------------设置随机种子local resty_uuid=require(\"resty.uuid\")math.randomseed(tonumber(resty_uuid.gennum20()))---------------------------------------------------------------------------------------------[[ 预先生成 ]]--if math.random(1,99)&lt;tonumber(ngx.var.percent) then --在redis的预先生成key中随机选择keyid local kid=math.random(1,ngx.var.pregencount) local res = ngx.location.capture('/redisGetImg',&#123; args = &#123; key = kid &#125; &#125;) if res.status==200 then local parser=require(\"redis.parser\") local pic=parser.parse_reply(res.body) ngx.header.content_type=\"application/octet-stream\" --在header中返回用于去redis中查找记录的key ngx.header.picgid=kid --在body中返回captcha ngx.say(pic) ngx.exit(200) endend---------------------------------------------------------------------------------------------[[ 实时生成 ]]----随机选择captcha模式Xlocal mode=math.random(1,ngx.var.modecount)--调用modeX.lua，生成captchalocal res = ngx.location.capture(\"/mode\"..mode)if res.status==200 then ngx.header.content_type=\"application/octet-stream\" --在header中返回用于去redis中查找记录的key ngx.header.picgid=res.header.picgid --在body中返回captcha ngx.say(res.body) ngx.exit(200)end /usr/local/openresty/nginx/luascripts/luajit/captcha-check.lua 用于校验验证码： 1234567891011121314151617181920212223242526272829303132--[[captcha check]]----------------------------------------------------------------------------------------------package.path = \"/usr/local/openresty/lualib/?.lua;/usr/local/openresty/lualib/captcha/?.lua;\"package.cpath = \"/usr/local/openresty/lualib/?.so;/usr/local/openresty/lualib/captcha/?.so;\"------------------------------------------------------------------------------------------------获取请求中参数local uriargs = ngx.req.get_uri_args()local picgid = uriargs[\"image\"]local ustr=string.lower(uriargs[\"str\"])--查找redis中key为picgid的记录local res = ngx.location.capture('/redisGetStr',&#123; args = &#123; key = picgid &#125; &#125;)if res.status==200 then local parser=require(\"redis.parser\") local reply=parser.parse_reply(res.body) local rstr=string.lower(reply) --匹配用户输入字符串与redis中记录的字符串，一致返回True，否则返回False ngx.header.content_type=\"text/plain\" if ustr == rstr then ngx.say(\"True\") else ngx.say(\"False\") end --匹配操作后删除redis中该key记录 local redis = require('redis') local client = redis.connect('127.0.0.1', 10005) client:del(picgid)end /usr/local/openresty/nginx/luascripts/luajit/mode/mode1.lua 是生成静态验证码图片： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384--静态图片------------------------------------------------------------------------------------------------package.path = \"/usr/local/openresty/lualib/?.lua;/usr/local/openresty/lualib/captcha/?.lua;\"package.cpath = \"/usr/local/openresty/lualib/?.so;/usr/local/openresty/lualib/captcha/?.so;\"--------------------------------------------------------------------------------------------------Redis中插入记录方法function setRedis(skey, sval) local res = ngx.location.capture('/redisSetQueue', &#123;args= &#123;key=skey,val=sval&#125;&#125;) if res.status == 200 then return true else return false endend--设置随机种子local resty_uuid=require(\"resty.uuid\")math.randomseed(tonumber(resty_uuid.gennum20()))--在32个备选字符中随机筛选4个作为captcha字符串local dict=&#123;'A','B','C','D','E','F','G','H','J','K','L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z','2','3','4','5','6','7','8','9'&#125;local stringmark=\"\"for i=1,4 do stringmark=stringmark..dict[math.random(1,32)]end--图片基本info--picgidlocal filename= \"1\"..resty_uuid.gen20()..\".png\"--图片78x26local xsize = 78local ysize = 26--字体大小local wsize = 17.5--干扰线(yes/no)local line = \"yes\"--加载模块local gd=require('gd')--创建面板local im = gd.createTrueColor(xsize, ysize)--定义颜色local black = im:colorAllocate(0, 0, 0)local grey = im:colorAllocate(202,202,202)local color=&#123;&#125;for c=1,100 do color[c] = im:colorAllocate(math.random(100),math.random(100),math.random(100))end--画背景x, y = im:sizeXY()im:filledRectangle(0, 0, x, y, grey)--画字符gd.useFontConfig(true)for i=1,4 do k=(i-1)*16+3 im:stringFT(color[math.random(100)],\"Arial:bold\",wsize,math.rad(math.random(-10,10)),k,22,string.sub(stringmark,i,i))end--干扰线点if line==\"yes\" then for j=1,math.random(3) do im:line(math.random(xsize),math.random(ysize),math.random(xsize),math.random(ysize),color[math.random(100)]) end for p=1,20 do im:setPixel(math.random(xsize),math.random(ysize),color[math.random(100)]) endend--流输出local fp=im:pngStr(75)--redis中添加picgid为key,string为value的记录setRedis(filename,stringmark)--response header中传参picgidngx.header.content_type=\"text/plain\"ngx.header.picgid=filename--页面返回picngx.say(fp)--nginx退出ngx.exit(200) 配置redis在/usr/local/openresty/redis/conf/创建redis-10005.conf文件，内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940daemonize yespidfile /usr/local/openresty/redis/redis-10005.pidport 10005timeout 300tcp-keepalive 10loglevel noticelogfile /usr/local/openresty/redis/redis-10005.logdatabases 16save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump-10005.rdbdir /usr/local/openresty/redisslave-serve-stale-data yesslave-read-only yesrepl-disable-tcp-nodelay noslave-priority 100appendonly noappendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mblua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10 配置验证码服务器在/etc/ld.so.conf.d/目录创建captcha.conf，内容如下： 123456$ vim /etc/ld.so.conf.d/captcha.conf/usr/local/lib/usr/local/openresty/lualib/usr/local/openresty/lualib/captcha/usr/local/openresty/lualib/zklua/usr/local/openresty/luajit/lib 测试生成验证码URL：http://IP:10002/captcha 然后从响应Header中获取图片的picgid=XXXXX 验证码校验URL：http://IP:10002/captcha-check?image=XXXXX&amp;str=ABCD http://IP:10002/captcha-check?image=XXXXX&amp;str=ABCD&amp;delete=true 或 http://IP:10002/captcha-check?image=XXXXX&amp;str=ABCD&amp;delete=false 参数说明如下： 参数image：要校验的验证码图片的picgid。 参数str：用户输入的验证码字符串。 参数delete：当且仅当传该参数且参数值为false时，校验完成之后该验证码记录不被删除，验证码未过期之前可多次校验，用于异步校验应用中；否则，若不传该参数或者其值为true，校验完成之后该验证码记录删除。 验证码删除URL：http://IP:10002/captcha-delete?image=XXXXX 其中image为要删除的验证码图片的picgid。","categories":[{"name":"openresty","slug":"openresty","permalink":"https://plpcm.github.io/blog/categories/openresty/"}],"tags":[{"name":"openresty","slug":"openresty","permalink":"https://plpcm.github.io/blog/tags/openresty/"},{"name":"checkcode","slug":"checkcode","permalink":"https://plpcm.github.io/blog/tags/checkcode/"},{"name":"lua","slug":"lua","permalink":"https://plpcm.github.io/blog/tags/lua/"},{"name":"lua-gd","slug":"lua-gd","permalink":"https://plpcm.github.io/blog/tags/lua-gd/"}]},{"title":"OpenResty实现防cc攻击","slug":"openresty-cc","date":"2016-03-02T10:30:16.000Z","updated":"2016-12-02T10:28:47.000Z","comments":true,"path":"2016/03/02/openresty-cc/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/03/02/openresty-cc/","excerpt":"","text":"导读OpenResty 通过汇聚各种设计精良的 Nginx 模块（由章亦春自主研发并汇聚各种精良模块），从而将 Nginx 有效地变成一个强大的通用 Web 应用平台。这样，Web 开发人员和系统工程师可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块，快速构造出足以胜任 10K 乃至 1000K 以上单机并发连接的高性能 Web 应用系统 本文介绍使用openresty来实现防cc攻击的功能。openresty官网http://openresty.org/cn/index.html。下面是防cc攻击的流程图。 根据流程图，我们知道防cc攻击主要包括两部分，一是限制请求速度，二是给用户发送js跳转代码进行验证请求是否合法。 安装依赖 RHEL/Centos: 1yum install readline-devel pcre-devel openssl-devel ubuntu: 1apt-get install libreadline-dev libncurses5-dev libpcre3-dev libssl-dev perl luajit安装 123456cd /tmp/git clone http://luajit.org/git/luajit-2.0.gitcd luajit-2.0/make &amp;&amp; make installln -sf luajit-2.0.0-beta10 /usr/local/bin/luajitln -sf /usr/local/lib/libluajit-5.1.so.2 /usr/lib/ openresty安装 123456cd /tmpwget http://agentzh.org/misc/nginx/ngx_openresty-1.2.4.13.tar.gztar xzf ngx_openresty-1.2.4.13.tar.gzcd ngx_openresty-1.2.4.13/./configure --prefix=/usr/local/openresty --with-luajitmake &amp;&amp; make install nginx配置 nginx.conf: 123456789101112131415161718192021http&#123;[......]lua_shared_dict limit 10m;lua_shared_dict jsjump 10m; server &#123;#lua_code_cache off; listen 80; server_name www.centos.bz; location / &#123;default_type text/html;content_by_lua_file \"/usr/local/openresty/nginx/conf/lua\"; &#125; location @cc &#123; internal; root html; index index.html index.htm; &#125; &#125;&#125; /usr/local/openresty/nginx/conf/lua文件: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556-- 限速功能local ip = ngx.var.binary_remote_addrlocal limit = ngx.shared.limitlocal req,_=limit:get(ip)if req then -- 10秒钟内容最多只能请求20次 if req &gt; 20 then ngx.exit(503) else limit:incr(ip,1) endelse limit:set(ip,1,10)end--验证部分local jsjump = ngx.shared.jsjumplocal uri = ngx.var.request_urilocal jspara,flags=jsjump:get(ip)local args = ngx.req.get_uri_args()if jspara then if flags then ngx.exec(\"@cc\") else local p_jskey='' if args[\"jskey\"] and type(args[\"jskey\"])=='table' then p_jskey=args[\"jskey\"][table.getn(args[\"jskey\"])] else p_jskey=args[\"jskey\"] end if p_jskey and p_jskey==tostring(jspara) then jsjump:set(ip,jspara,3600,1) --通过后，白名单时间为3600秒，即1小时 ngx.exec(\"@cc\") else local url='' if ngx.var.args then url=ngx.var.scheme..\"://\"..ngx.var.host..uri..\"&amp;jskey=\"..jspara else url=ngx.var.scheme..\"://\"..ngx.var.host..uri..\"?jskey=\"..jspara end local jscode=\"window.location.href='\"..url..\"';\" ngx.say(jscode) end endelsemath.randomseed( os.time() ); local random=math.random(100000,999999) jsjump:set(ip,random,60) local url='' if ngx.var.args then url=ngx.var.scheme..\"://\"..ngx.var.host..uri..\"&amp;jskey=\"..random else url=ngx.var.scheme..\"://\"..ngx.var.host..uri..\"?jskey=\"..random end local jscode=\"window.location.href='\"..url..\"';\" ngx.say(jscode)end","categories":[{"name":"openresty","slug":"openresty","permalink":"https://plpcm.github.io/blog/categories/openresty/"}],"tags":[{"name":"cc","slug":"cc","permalink":"https://plpcm.github.io/blog/tags/cc/"},{"name":"防攻击","slug":"防攻击","permalink":"https://plpcm.github.io/blog/tags/防攻击/"},{"name":"openresty","slug":"openresty","permalink":"https://plpcm.github.io/blog/tags/openresty/"}]},{"title":"nginx限制某个IP同一时间段的访问次数","slug":"nginx-limit-mod","date":"2016-03-02T09:35:16.000Z","updated":"2016-12-02T10:28:33.000Z","comments":true,"path":"2016/03/02/nginx-limit-mod/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/03/02/nginx-limit-mod/","excerpt":"","text":"转载自: http://www.nginx.cn/446.html 如何设置能限制某个IP某一时间段的访问次数是一个让人头疼的问题，特别面对恶意的ddos攻击的时候。其中CC攻击（Challenge Collapsar）是DDOS（分布式拒绝服务）的一种，也是一种常见的网站攻击方法，攻击者通过代理服务器或者肉鸡向向受害主机不停地发大量数据包，造成对方服务器资源耗尽，一直到宕机崩溃。 cc攻击一般就是使用有限的ip数对服务器频繁发送数据来达到攻击的目的，nginx可以通过HttpLimitReqModul和HttpLimitZoneModule配置来限制ip在同一时间段的访问次数来防cc攻击。 HttpLimitReqModul用来限制连单位时间内连接数的模块，使用limit_req_zone和limit_req指令配合使用来达到限制。一旦并发连接超过指定数量，就会返回503错误。 HttpLimitConnModul用来限制单个ip的并发连接数，使用limit_zone和limit_conn指令 这两个模块的区别前一个是对一段时间内的连接数限制，后者是对同一时刻的连接数限制 HttpLimitReqModul 限制某一段时间内同一ip访问数实例1234567891011121314151617181920212223242526272829303132http&#123; ... #定义一个名为allips的limit_req_zone用来存储session，大小是10M内存， #以$binary_remote_addr 为key,限制平均每秒的请求为20个， #1M能存储16000个状态，rete的值必须为整数， #如果限制两秒钟一个请求，可以设置成30r/m limit_req_zone $binary_remote_addr zone=allips:10m rate=20r/s; ... server&#123; ... location &#123; ... #限制每ip每秒不超过20个请求，漏桶数burst为5 #brust的意思就是，如果第1秒、2,3,4秒请求为19个， #第5秒的请求为25个是被允许的。 #但是如果你第1秒就25个请求，第2秒超过20的请求返回503错误。 #nodelay，如果不设置该选项，严格使用平均速率限制请求数， #第1秒25个请求时，5个请求放到第2秒执行， #设置nodelay，25个请求将在第1秒执行。 limit_req zone=allips burst=5 nodelay; ... &#125; ... &#125; ...&#125; HttpLimitZoneModule 限制并发连接数实例limit_zone只能定义在http作用域，limit_conn可以定义在http server location作用域 123456789101112131415161718192021222324http&#123; ... #定义一个名为one的limit_zone,大小10M内存来存储session， #以$binary_remote_addr 为key #nginx 1.18以后用limit_conn_zone替换了limit_conn #且只能放在http作用域 limit_conn_zone one $binary_remote_addr 10m; ... server&#123; ... location &#123; ... limit_conn one 20; #连接数限制 #带宽限制,对单个连接限数，如果一个ip两个连接，就是500x2k limit_rate 500k; ... &#125; ... &#125; ...&#125; nginx白名单设置以上配置会对所有的ip都进行限制，有些时候我们不希望对搜索引擎的蜘蛛或者自己测试ip进行限制，对于特定的白名单ip我们可以借助geo指令实现。1. 123456789101112131415161718192021222324252627282930313233http&#123; geo $limited&#123; default 1; #google 64.233.160.0/19 0; 65.52.0.0/14 0; 66.102.0.0/20 0; 66.249.64.0/19 0; 72.14.192.0/18 0; 74.125.0.0/16 0; 209.85.128.0/17 0; 216.239.32.0/19 0; #M$ 64.4.0.0/18 0; 157.60.0.0/16 0; 157.54.0.0/15 0; 157.56.0.0/14 0; 207.46.0.0/16 0; 207.68.192.0/20 0; 207.68.128.0/18 0; #yahoo 8.12.144.0/24 0; 66.196.64.0/18 0; 66.228.160.0/19 0; 67.195.0.0/16 0; 74.6.0.0/16 0; 68.142.192.0/18 0; 72.30.0.0/16 0; 209.191.64.0/18 0; #My IPs 127.0.0.1/32 0; 123.456.0.0/28 0; #example for your server CIDR &#125; geo指令定义了一个白名单$limited变量，默认值为1，如果客户端ip在上面的范围内，$limited的值为0 2.使用map指令映射搜索引擎客户端的ip为空串，如果不是搜索引擎就显示本身真是的ip，这样搜索引擎ip就不能存到limit_req_zone内存session中，所以不会限制搜索引擎的ip访问 map $limited $limit {1 $binary_remote_addr;0 “”;} 3.设置limit_req_zone和limit_reqlimit_req_zone $limit zone=foo:1m rate=10r/m; limit_req zone=foo burst=5; 最后我们使用ab压php-fpm的方式，对上面的方法效果实际测试下 例1：限制只允许一分钟内只允许一个ip访问60次配置，也就是平均每秒1次首先我们准备一个php脚本放在根目录下$document_roottest.php &gt; nginx配置增加limit_req_zone 和 limit_req 123456789101112131415http&#123; ... limit_req_zone $binary_remote_addr zone=allips:10m rate=60r/m; ... server&#123; ... location &#123; ... limit_req zone=allips; ... &#125; ... &#125; ...&#125; ab -n 5 -c 1 http://www.weizhang.org/test.php 118.144.94.193 - - [22/Dec/2012:06:27:06 +0000] “GET /test.php HTTP/1.0” 200 11000 “-“ “ApacheBench/2.3”118.144.94.193 - - [22/Dec/2012:06:27:06 +0000] “GET /test.php HTTP/1.0” 503 537 “-“ “ApacheBench/2.3”118.144.94.193 - - [22/Dec/2012:06:27:07 +0000] “GET /test.php HTTP/1.0” 503 537 “-“ “ApacheBench/2.3”118.144.94.193 - - [22/Dec/2012:06:27:07 +0000] “GET /test.php HTTP/1.0” 503 537 “-“ “ApacheBench/2.3”118.144.94.193 - - [22/Dec/2012:06:27:07 +0000] “GET /test.php HTTP/1.0” 503 537 “-“ “ApacheBench/2.3” 未设置brust和nodelay可以看到该配置只允许每秒访问1次，超出的请求返回503错误 123456789101112131415http&#123; ... limit_req_zone $binary_remote_addr zone=allips:10m rate=60r/m; ... server&#123; ... location &#123; ... limit_req zone=allips burst=1 nodelay; ... &#125; ... &#125; ...&#125; ab -n 5 -c 1 http://www.weizhang.org/test.php 118.144.94.193 - - [22/Dec/2012:07:01:00 +0000] “GET /test.php HTTP/1.0” 200 11000 “-“ “ApacheBench/2.3”118.144.94.193 - - [22/Dec/2012:07:01:00 +0000] “GET /test.php HTTP/1.0” 200 11000 “-“ “ApacheBench/2.3”118.144.94.193 - - [22/Dec/2012:07:01:01 +0000] “GET /test.php HTTP/1.0” 503 537 “-“ “ApacheBench/2.3”118.144.94.193 - - [22/Dec/2012:07:01:01 +0000] “GET /test.php HTTP/1.0” 503 537 “-“ “ApacheBench/2.3”118.144.94.193 - - [22/Dec/2012:07:01:01 +0000] “GET /test.php HTTP/1.0” 503 537 “-“ “ApacheBench/2.3” 设置brust=1和nodelay后允许第1秒处理两个请求。","categories":[{"name":"nginx","slug":"nginx","permalink":"https://plpcm.github.io/blog/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://plpcm.github.io/blog/tags/nginx/"},{"name":"cc","slug":"cc","permalink":"https://plpcm.github.io/blog/tags/cc/"},{"name":"防攻击","slug":"防攻击","permalink":"https://plpcm.github.io/blog/tags/防攻击/"}]},{"title":"Git 的 .gitignore 配置","slug":"git-ignore","date":"2016-02-22T07:00:16.000Z","updated":"2016-11-30T09:56:11.000Z","comments":true,"path":"2016/02/22/git-ignore/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/02/22/git-ignore/","excerpt":"","text":".gitignore配置文件用于配置不需要加入版本管理的文件，配置好该文件可以为我们的版本管理带来很大的便利，以下是个人对于配 置.gitignore 的一些心得。 1.配置语法： 以斜杠“ /”“开头表示目录； 以星号“ *”“通配多个字符； 以问号“ ?”“通配单个字符 以方括号“ []” 包含单个字符的匹配列表； 以叹号“ !”“表示不忽略(跟踪)匹配到的文件或目录； 此外，git 对于 .ignore配置文件是按行从上到下进行规则匹配的，意味着如果前面的规则匹配的范围更大，则后面的规则将不会生效； 2.示例： (1)规则：fd1/* 说明：忽略目录 fd1 下的全部内容；注意，不管是根目录下的 /fd1/ 目录，还是某个子目录 /child/fd1/ 目录，都会被忽略； (2)规则：/fd1/* 说明：忽略根目录下的 /fd1/ 目录的全部内容； (3)规则： /* !.gitignore !/fw/bin/ !/fw/sf/ 说明：忽略全部内容，但是不忽略 .gitignore 文件、根目录下的 /fw/bin/ 和 /fw/sf/ 目录；","categories":[{"name":"git","slug":"git","permalink":"https://plpcm.github.io/blog/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://plpcm.github.io/blog/tags/git/"}]},{"title":"Git远程操作详解","slug":"git-remote-server","date":"2016-02-21T02:45:33.000Z","updated":"2016-12-02T10:11:48.000Z","comments":true,"path":"2016/02/21/git-remote-server/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/02/21/git-remote-server/","excerpt":"","text":"Git是目前最流行的版本管理系统，学会Git几乎成了开发者的必备技能。Git有很多优势，其中之一就是远程操作非常简便。本文详细介绍5个Git命令，它们的概念和用法，理解了这些内容，你就会完全掌握Git远程操作。 git clone git remote git fetch git pull git push 本文针对初级用户，从最简单的讲起，但是需要读者对Git的基本用法有所了解。同时，本文覆盖了上面5个命令的几乎所有的常用用法，所以对于熟练用户也有参考价值。 ##一、git clone远程操作的第一步，通常是从远程主机克隆一个版本库，这时就要用到git clone命令。 1$ git clone &lt;版本库的网址&gt; 比如，克隆jQuery的版本库。 1$ git clone https://github.com/jquery/jquery.git 该命令会在本地主机生成一个目录，与远程主机的版本库同名。如果要指定不同的目录名，可以将目录名作为git clone命令的第二个参数。 1$ git clone &lt;版本库的网址&gt; &lt;本地目录名&gt; git clone支持多种协议，除了HTTP(s)以外，还支持SSH、Git、本地文件协议等，下面是一些例子。 1234567$ git clone http[s]://example.com/path/to/repo.git/$ git clone ssh://example.com/path/to/repo.git/$ git clone git://example.com/path/to/repo.git/$ git clone /opt/git/project.git $ git clone file:///opt/git/project.git$ git clone ftp[s]://example.com/path/to/repo.git/$ git clone rsync://example.com/path/to/repo.git/ SSH协议还有另一种写法。 1$ git clone [user@]example.com:path/to/repo.git/ 通常来说，Git协议下载速度最快，SSH协议用于需要用户认证的场合。各种协议优劣的详细讨论请参考官方文档。 ##二、git remote为了便于管理，Git要求每个远程主机都必须指定一个主机名。git remote命令就用于管理主机名。不带选项的时候，git remote命令列出所有远程主机。 12$ git remoteorigin 使用-v选项，可以参看远程主机的网址。 123$ git remote -vorigin git@github.com:jquery/jquery.git (fetch)origin git@github.com:jquery/jquery.git (push) 上面命令表示，当前只有一台远程主机，叫做origin，以及它的网址。克隆版本库的时候，所使用的远程主机自动被Git命名为origin。如果想用其他的主机名，需要用git clone命令的-o选项指定。 123$ git clone -o jQuery https://github.com/jquery/jquery.git$ git remotejQuery 上面命令表示，克隆的时候，指定远程主机叫做jQuery。git remote show命令加上主机名，可以查看该主机的详细信息。 1$ git remote show &lt;主机名&gt; git remote add命令用于添加远程主机。 1$ git remote add &lt;主机名&gt; &lt;网址&gt; git remote rm命令用于删除远程主机。 1$ git remote rm &lt;主机名&gt; git remote rename命令用于远程主机的改名。 1$ git remote rename &lt;原主机名&gt; &lt;新主机名&gt; ##三、git fetch一旦远程主机的版本库有了更新（Git术语叫做commit），需要将这些更新取回本地，这时就要用到git fetch命令。 1$ git fetch &lt;远程主机名&gt; 上面命令将某个远程主机的更新，全部取回本地。git fetch命令通常用来查看其他人的进程，因为它取回的代码对你本地的开发代码没有影响。默认情况下，git fetch取回所有分支（branch）的更新。如果只想取回特定分支的更新，可以指定分支名。 1$ git fetch &lt;远程主机名&gt; &lt;分支名&gt; 比如，取回origin主机的master分支。 1$ git fetch origin master 所取回的更新，在本地主机上要用”远程主机名/分支名”的形式读取。比如origin主机的master，就要用origin/master读取。git branch命令的-r选项，可以用来查看远程分支，-a选项查看所有分支。 123456$ git branch -rorigin/master$ git branch -a* master remotes/origin/master 上面命令表示，本地主机的当前分支是master，远程分支是origin/master。 取回远程主机的更新以后，可以在它的基础上，使用git checkout命令创建一个新的分支。 1$ git checkout -b newBrach origin/master 上面命令表示，在origin/master的基础上，创建一个新分支。 此外，也可以使用git merge命令或者git rebase命令，在本地分支上合并远程分支。 123 $ git merge origin/master# 或者 $ git rebase origin/master 上面命令表示在当前分支上，合并origin/master。 ##四、git pull git pull命令的作用是，取回远程主机某个分支的更新，再与本地的指定分支合并。它的完整格式稍稍有点复杂。 1$ git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。 1$ git pull origin next:master 如果远程分支是与当前分支合并，则冒号后面的部分可以省略。 1$ git pull origin next 上面命令表示，取回origin/next分支，再与当前分支合并。实质上，这等同于先做git fetch，再做git merge。 12$ git fetch origin$ git merge origin/next 在某些场合，Git会自动在本地分支与远程分支之间，建立一种追踪关系（tracking）。比如，在git clone的时候，所有本地分支默认与远程主机的同名分支，建立追踪关系，也就是说，本地的master分支自动”追踪”origin/master分支。 Git也允许手动建立追踪关系。 1git branch --set-upstream master origin/next 上面命令指定master分支追踪origin/next分支。 如果当前分支与远程分支存在追踪关系，git pull就可以省略远程分支名。 1$ git pull origin 上面命令表示，本地的当前分支自动与对应的origin主机”追踪分支”（remote-tracking branch）进行合并。 如果当前分支只有一个追踪分支，连远程主机名都可以省略。 1$ git pull 上面命令表示，当前分支自动与唯一一个追踪分支进行合并。 如果合并需要采用rebase模式，可以使用--rebase选项。 1$ git pull --rebase &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 如果远程主机删除了某个分支，默认情况下，git pull 不会在拉取远程分支的时候，删除对应的本地分支。这是为了防止，由于其他人操作了远程主机，导致git pull不知不觉删除了本地分支。 但是，你可以改变这个行为，加上参数-p 就会在本地删除远程已经删除的分支。 1234 $ git pull -p# 等同于下面的命令 $ git fetch --prune origin $ git fetch -p ##五、git push git push命令用于将本地分支的更新，推送到远程主机。它的格式与git pull命令相仿。 1$ git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 注意，分支推送顺序的写法是&lt;来源地&gt;:&lt;目的地&gt;，所以git pull是&lt;远程分支&gt;:&lt;本地分支&gt;，而git push是&lt;本地分支&gt;:&lt;远程分支&gt;。 如果省略远程分支名，则表示将本地分支推送与之存在”追踪关系”的远程分支（通常两者同名），如果该远程分支不存在，则会被新建。 1$ git push origin master 上面命令表示，将本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建。 如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。 123 $ git push origin :master# 等同于 $ git push origin --delete master 上面命令表示删除origin主机的master分支。 如果当前分支与远程分支之间存在追踪关系，则本地分支和远程分支都可以省略。 1$ git push origin 上面命令表示，将当前分支推送到origin主机的对应分支。 如果当前分支只有一个追踪分支，那么主机名都可以省略。 1$ git push 如果当前分支与多个主机存在追踪关系，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用git push。 1$ git push -u origin master 上面命令将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不加任何参数使用git push了。 不带任何参数的git push，默认只推送当前分支，这叫做simple方式。此外，还有一种matching方式，会推送所有有对应的远程分支的本地分支。Git 2.0版本之前，默认采用matching方法，现在改为默认采用simple方式。如果要修改这个设置，可以采用git config命令。 123 $ git config --global push.default matching# 或者 $ git config --global push.default simple 还有一种情况，就是不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用--all选项。 1$ git push --all origin 上面命令表示，将所有本地分支都推送到origin主机。 如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用--force选项。 1$ git push --force origin 上面命令使用--force选项，结果导致远程主机上更新的版本被覆盖。除非你很确定要这样做，否则应该尽量避免使用--force选项。 最后，git push不会推送标签（tag），除非使用--tags选项。 1$ git push origin --tags","categories":[{"name":"git","slug":"git","permalink":"https://plpcm.github.io/blog/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://plpcm.github.io/blog/tags/git/"}]},{"title":"Git工作原理","slug":"git-works-how","date":"2016-02-20T02:30:16.000Z","updated":"2016-12-06T05:57:20.000Z","comments":true,"path":"2016/02/20/git-works-how/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/02/20/git-works-how/","excerpt":"","text":"原文地址：https://codewords.recurse.com/issues/two/git-from-the-inside-out) 这篇文章解释了git的工作原理，它会使你更深入的理解git，更好的使用它来控制项目的版本。 本文重点介绍了支持Git的图形结构，以及该图形的属性指示Git行为的方式。从基础开始，同时有实例讲解，根据实例建立一个更真实的模型，让你更好地理解git做了什么。 创建项目12~ $ mkdir alpha~ $ cd alpha 项目目录是alpha 12~/alpha $ mkdir data~/alpha $ printf &apos;a&apos; &gt; data/letter.txt 到目录alpha下创建了一个名为data的目录，在里面创建了一个名为letter.txt的文件，其中的内容是一个字符a，alpha目录结构如下： 123alpha└── data └── letter.txt 初始化仓库12~/alpha $ git init Initialized empty Git repository git init使当前目录变成了Git仓库，为此，它创建了一个.git目录并向其中写入了一些文件。这些文件定义了关于Git配置和项目历史的一切，它们只是普通文件。 用户可以使用文本编辑器或shell来读取和编辑它们。 这就是说，用户可以像他们的项目文件一样轻松地阅读和编辑他们项目的历史。 现在alpha目录的结构就像下面这样 123456alpha├── data| └── letter.txt└── .git ├── objects etc... .git目录及其内容归Git系统所有，所有其他的文件统称为工作副本，归用户所有。 添加文件1~/alpha $ git add data/letter.txt 运行上面的命令，有两个效果。 首先，它在.git/objects/目录中创建了一个新的blob文件。 这个blob文件包含data/letter.txt的压缩内容。 它的名称通过文件内容的Hash(应该是用的sha1)得到。取一段文本的Hash值意味着运行一个程序，将其内容变成一块较小的文本，这块文本是原始内容的唯一标识。例如，Git将aes转换为2e65efe2a145dda7ee51d1741299f848e5bf752e，前两个字符用作对象数据库中的目录的名称：.git/objects/2e/。 散列的其余部分用作保存所添加文件的内容的blob文件的名称： .git/objects/2e/65efe2a145dda7ee51d1741299f848e5bf752e。 git add将文件添加到Git并将其内容保存到objects目录中。 如果用户从工作副本中删除data/letter.text，它的内容在Git中仍然是安全的。 其次，git add将文件添加到索引。 索引是一个列表，其中包含Git已被告知要跟踪的每个文件。 它作为一个文件存储在.git/index。 文件的每一行将被跟踪的文件映射到其内容的哈希。 这是运行git add命令后的索引： data/letter.txt 2e65efe2a145dda7ee51d1741299f848e5bf752e 创建一个包含内容1234的文件data/number.txt 1~/alpha $ printf &apos;1234&apos; &gt; data/number.txt 目录结构变成了下面这样： 1234alpha└── data └── letter.txt └── number.txt 添加文件到Git 1~/alpha $ git add data git add命令创建一个包含data/number.txt内容的blob对象。 它为指向blob的data/number.txt添加一个索引条目。 这是git add命令第二次运行后的索引： 12data/letter.txt 2e65efe2a145dda7ee51d1741299f848e5bf752edata/number.txt 274c0052dd5408f8ae2bc8440029ff67d79bc5c3 只有数据目录中的文件被列在索引中，虽然用户运行了git add data。 数据目录data不单独列出。 12~/alpha $ printf &apos;1&apos; &gt; data/number.txt~/alpha $ git add data 当最初创建data/number.txt时，想要输入内容1，而不是1234.他们进行更正并将文件再次添加到索引。 此命令将使用新内容创建一个新的blob。 并且它更新data/number.txt的索引条目以指向新的blob。 git commit12~/alpha $ git commit -m &apos;a1&apos; [master (root-commit) 774b54a] a 进行a1提交，Git打印了这次提交的相关信息。 commit命令有三个步骤。 创建一个树形图来表示正在提交的项目版本的内容。 创建一个提交对象。 将当前分支指向新的提交对象。 创建树形图Git通过从索引创建树图来记录项目的当前状态。 此树图记录项目中每个文件的位置和内容。 该图由两种类型的对象组成：blob和树。 Blob是通过git add存储的。 它们表示文件的内容。 在commit时存储树。 树表示工作副本中的目录。 下面是记录新提交的data目录的内容的树对象： 12100664 blob 2e65efe2a145dda7ee51d1741299f848e5bf752e letter.txt100664 blob 56a6051ca2b02b04ef92d5150c9ef600403cb1de number.txt 第一行记录展示了data/letter.txt文件的信息。 第一部分是文件的权限。 第二部表示此条目的内容由blob而不是树表示。 第三部分描述了blob的Hash。 第四部分描述文件的名称。第二行当然就是文件data/number.txt文件的信息。 下面是alpha的树对象： 1040000 tree 0eed1217a2947f4930583229987d90fe5e8e0b74 data alpha树对象只包含了一个指向data树指针。(译著：如果alpha目录下还有一个文件， alpha树对象就还会多一行，就是指向多出文件的blob对象) 在上面的图中，root树指向data树。 data树指向data/letter.txt和data/number.txt的blob。 创建一个提交对象git commit在创建树图后创建一个提交对象。 提交对象只是.git/objects/中的另一个文本文件： 12345tree ffe298c3ce8bb07326f888907996eaa48d266db4author Mary Rose Cook &lt;mary@maryrosecook.com&gt; 1424798436 -0500committer Mary Rose Cook &lt;mary@maryrosecook.com&gt; 1424798436 -0500a1 第一行指向树图。 Hash是表示工作副本的根的树对象。 也就是alpha目录。 最后一行是提交消息。 将当前分支指向新的提交最后，commit命令将当前分支指向新的提交对象。哪个是当前分支？ .git/HEAD文件记录了当前分支： 1ref: refs/heads/master 这说明HEAD指向master, master是主分支。HEAD和master都是refs。 ref是Git用来标识特定提交的标签。 表示master引用的文件不存在，因为这是对仓库的第一次提交。 Git在.git/refs/heads/master下创建文件，并将其内容设置为提交对象的哈希值： 174ac3ad9cde0b265d2b4f1c778b283a6e2ffbafd (如果你在阅读时输入这些Git命令，你的a1提交的哈希值将不同于我的哈希值。 内容对象（如blob和树）总是散列为相同的值。 提交不会，因为它们包括创建者的日期和名称。) 添加HEAD和master到树图： HEAD指向master，就像提交之前一样。 但master现在存在并指向新的提交对象a1。 再一次commit下面是a1提交后的Git结构图。 包含工作副本和索引。 工作副本，索引和a1提交都具有与data/letter.txt和data/number.txt相同的内容。 索引和HEAD提交都使用Hash来引用blob对象，但是工作副本内容作为文本存储在不同的地方。 1~/alpha $ printf &apos;2&apos; &gt; data/number.txt 将data/number.txt的内容设置为2.这会更新工作副本，但索引和HEAD不变。 1~/alpha $ git add data/number.txt 将文件添加到Git。 这会向objects目录添加一个包含2的blob。 它指向新blob的data/number.txt的索引条目。 12~/alpha $ git commit -m &apos;a2&apos; [master f0af7e6] a2 提交的步骤与之前相同。 首先，创建一个新的树形图来表示索引的内容。 data/number.txt的索引条目已更改。 旧的数据树不再反映data目录的索引状态。 必须创建一个新的data树对象： 12100664 blob 2e65efe2a145dda7ee51d1741299f848e5bf752e letter.txt100664 blob d8263ee9860594d2806b0dfd1bfd17528b0ba2a4 number.txt 新数据树与旧数据树的哈希值不同。 必须创建一个新的根树以记录此Hash值： 1040000 tree 40b0318811470aaacc577485777d7a6780e51f0b data 其次，创建一个新的提交对象。 123456tree ce72afb5ff229a39f6cce47b00d1b0ed60fe3556parent 774b54a193d6cfdd081e581a007d2e11f784b9feauthor Mary Rose Cook &lt;mary@maryrosecook.com&gt; 1424813101 -0500committer Mary Rose Cook &lt;mary@maryrosecook.com&gt; 1424813101 -0500a2 提交对象的第一行指向新的根树对象。 第二行指向a1：新提交的父级。要找到父提交，要跟着HEAD和master来掌握并发现a1的提交哈希。 最后，master分支文件的内容被设置为新提交的hash值。 内容存储为对象树。 这意味着只有diffs存储在对象数据库中。 看看上面的图表。 a2 commit重用了在a1提交之前创建的blob。 类似地，如果提交中整个没有变，则其树以及其下的所有blob和树可以被重用。 一般来说，提交的内容更改很少。 这意味着Git可以在小的空间中存储大的提交历史。 每个提交都有一个父级。 这意味着存储库可以存储项目的历史记录。 refs是提交历史的一部分或另一部分的入口点。 这意味着提交可以被赋予有意义的名称。 用户将他们的工作组织到对他们的项目有意义的谱系中，具体的参考如fix-for-bug-376。 Git使用符号引用，如HEAD，MERGE_HEAD和FETCH_HEAD来支持操作提交历史记录的命令。 objects目录中的节点是不可变的。 这意味着内容被编辑，而不是被删除。 每一次添加的内容和每次提交的对象都是在目录中. refs是可变的。 因此，ref的含义可以改变。 master指向的提交可能是当前项目的最佳版本，但是，很快，它将被更新的更好的提交取代。 Check out a commit12~/alpha $ git checkout 37888c2 You are in &apos;detached HEAD&apos; state... 使用Hash值checkout``a2的提交(如果你在运行这些git命令，这里的hash值要换成你自己的，使用git log查看) checkout 有四个步骤： 获取a2提交，并获取指向它的树图 它将树形图中的文件条目写入工作副本。 这将导致没有更改。 工作副本已经具有被写入其中的树图的内容，因为HEAD已经通过master指向a2提交。 将树图中的文件条目写入索引。 这也导致没有变化。 索引已经具有a2提交的内容。 HEAD的内容设置为a2提交的哈希： 1f0af7e62679e144bb28c627ee3e8f7bdb235eee9 将HEAD的内容设置为Hash值会使存储库处于分离的HEAD状态。 注意在下面的图表中，HEAD直接指向a2提交，而不是指向master。 1234~/alpha $ printf &apos;3&apos; &gt; data/number.txt~/alpha $ git add data/number.txt~/alpha $ git commit -m &apos;a3&apos; [detached HEAD 3645a0e] a3 将data/number.txt的内容设置为3，并提交更改。 Git去HEAD得到a3提交的父级。 而不是找到一个分支ref，它找到并返回a2提交的哈希。 Git更新HEAD直接指向新的a3提交的哈希。 存储库仍处于分离的HEAD状态。 它不在一个分支上，因为没有提交指向a3或其一个后代。 这意味着它很容易丢失。 创建分支1~/alpha $ git branch deputy 创建一个新分支deputy。 这只是在.git/refs/heads/deputy创建一个新文件，其中包含HEAD指向的哈希, 也就是a3提交的哈希。 分支只是refs, refs只是文件。 这意味着Git分支是轻量级的。 deputy分支的创建将新的a3提交安全地放置在分支上。 HEAD仍然分离，因为它仍然直接指向一个提交。 切换分支12~/alpha $ git checkout master Switched to branch &apos;master&apos; 切换到了master分支 获取a2提交，并将master指向获取提交点的树图。 树形图中的文件条目替换工作副本的文件。 这将使data/number.txt的内容设置为2。 将树图中的文件条目写入索引。 这会将data/number.txt的条目更新为2个blob的散列。 改变HEAD的值 1ref: refs/heads/master 切换到与工作副本不兼容(有改变)的分支1234567~/alpha $ printf &apos;789&apos; &gt; data/number.txt~/alpha $ git checkout deputy Your changes to these files would be overwritten by checkout: data/number.txt Commit your changes or stash them before you switch branches. 将data/number.txt的内容设置为789， 当checkout到deputy时，Git报了一个错误。 HEAD指向master，master指向a2，其中data/number.txt的内容是2。deputy指向a3，其中data/number.txt的内容是3。data/number.txt在工作副本的内容为789，所有这些版本都不同，差异必须解决。 Git可以使用要切换分支中提交的版本替换掉工作副本中的版本，这样可以避免数据丢失。 Git可以合并工作副本的版本和要切换分支中的版本，但这很复杂。 所以Git报了一个错误，不能切换分支。 123~/alpha $ printf &apos;2&apos; &gt; data/number.txt~/alpha $ git checkout deputy Switched to branch &apos;deputy&apos; 把data/number.txt的内容变回2时，便切换成功了。 合并祖先12~/alpha $ git merge master Already up-to-date. 将主分支master和并到deputy分支。和并两个分支实际上是合并两个提交。第一个提交指向deputy，它是接收者。第二个提交指向master，它是提交者。可以理解为把master提交到deputy。对于这个合并，git什么也没有做，因为两个分支的内容是一样的。 图中的一系列的提交可以看成是对存储库的一系列更改。这也就意味着，在合并中，如果提交者(master)是接收者(deputy)的祖先，git将什么也不做，因为这些变化已经存在。 合并后代12~/alpha $ git checkout master Switched to branch &apos;master&apos; 切换到分支master 12~/alpha $ git merge deputy Fast-forward 合并deputy到master。Git发现接受者的a2提是提交者a3的祖先，它可以做快进合并。 获得提交者的提交a3并提供指向它的树图，将树图中的文件条目写入工作副本和索引。快进是指master指向a3。 在合并中，如果提交者(deputy分支上的a3提价)是接收者(master上的a2提价)的后代，则历史记录不改变。 已经有一系列提交描述了要做出的改变(接收者和提交者之间的提交序列)。 虽然Git历史没有改变，Git图确实改变。 HEAD指向的具体引用被更新为指向提交者(master指向a3)。 合并来自两个不同谱系的分支1234~/alpha $ printf &apos;4&apos; &gt; data/number.txt~/alpha $ git add data/number.txt~/alpha $ git commit -m &apos;a4&apos; [master 7b7bd9a] a4 把number.txt的内容设置为4，并提交到master 123456~/alpha $ git checkout deputy Switched to branch &apos;deputy&apos;~/alpha $ printf &apos;b&apos; &gt; data/letter.txt~/alpha $ git add data/letter.txt~/alpha $ git commit -m &apos;b3&apos; [deputy 982dffb] b3 切换到deputy分支，把data/letter.txt的内容设置为b，并提交到deputy。 提交可以共享父级，这意味着可以在提价的历史中创建新的谱系。 提交可以有多个父级。 这意味着单独的谱系可以通过具有两个父的提交来合并：合并提交。 12~/alpha $ git merge master -m &apos;b4&apos; Merge made by the &apos;recursive&apos; strategy. 合并master到deputy Git发现接收者b3和提供者a4在不同的谱系中。 它做一个合并提交。 这个过程有八个步骤。 Git将提交者的提交的哈希写入到alpha/.git/MERGE_HEAD文件。 这个文件的存在告诉Git在合并中。 Git查找基本提交：接收者和提交者提交的最近的祖先的共同点。 提交有父级别。 这意味着可以找到两个谱系起始点。 Git从b3向后跟踪，找到所有的祖先，从a4向后寻找所有的祖先。 它找到两个谱系共享的最近的祖先a3。 这是基本提交。 Git从接收者和提交者提交的树图生成基本的索引。 Git生成一个diff，它将接收者提交和提交者提交对基础提交所做的更改合并。 此diff是指向更改的文件路径列表：添加，删除，修改或冲突。 Git获取出现在base，receiver或giver索引中的所有文件的列表。 比较较索引条目以决定对文件做出的更改。 它将一个相应的条目写入diff。 在这种情况下，diff有两个条目。 第一个条目是是data/letter.txt。 文件内容在base和receiver中不同。 但是在base和giver中是一样的。 Git看到内容被reviceer修改，但是没有被giver修改。 data/letter.txt的diff条目是一个修改，而不是冲突。 diff中的第二个条目是data/number.txt。 在这种情况下，文件内容在base和receiver中是相同的，并且在giver中是不同的。 data/letter.txt的diff条目也是一个修改。 可以找到合并的base提交。 这意味着，如果一个文件只是从receiver或提giver的base改变，Git可以自动解决该文件的合并。 这减少了用户必须做的工作。 由diff中的条目指示的更改将应用于工作副本。 data/letter.txt的内容设置为b，data/number.txt的内容设置为4。 由diff中的条目指示的更改将应用于索引。 data/letter.txt的条目指向b blob，data/number.txt的条目指向4 blob。 更新索引： 1234567tree 20294508aea3fb6f05fcc49adaecc2e6d60f7e7dparent 982dffb20f8d6a25a8554cc8d765fb9f3ff1333bparent 7b7bd9a5253f47360d5787095afc5ba56591bfe7author Mary Rose Cook &lt;mary@maryrosecook.com&gt; 1425596551 -0500committer Mary Rose Cook &lt;mary@maryrosecook.com&gt; 1425596551 -0500b4 注意：这次提交有两个父级 将当前分支deputy 分支指向新的提交。 合并来自不同谱系的两个提交，这两个提交都修改同一个文件切换到master分支，并把deputy合并到master，快进到b4，现在master和deputy都指向同一个提交 123456~/alpha $ git checkout deputy Switched to branch &apos;deputy&apos;~/alpha $ printf &apos;5&apos; &gt; data/number.txt~/alpha $ git add data/number.txt~/alpha $ git commit -m &apos;b5&apos; [deputy bd797c2] b5 切换到deputy分支，把data/number.txt的内容设置为5，并提交。 123456~/alpha $ git checkout master Switched to branch &apos;master&apos;~/alpha $ printf &apos;6&apos; &gt; data/number.txt~/alpha $ git add data/number.txt~/alpha $ git commit -m &apos;b6&apos; [master 4c3ce18] b6 切换到master分支，把data/number.txt的内容设置为6，并提交。 1234~/alpha $ git merge deputy CONFLICT in data/number.txt Automatic merge failed; fix conflicts and commit the result. 将deputy合并到master。存在冲突，并且合并已暂停。冲突合并的过程遵循与未冲突合并的过程相同的前六个步骤：设置.git/MERGE_HEAD，查找base，生成base，receiver，giver的索引，创建diff，更新工作副本和更新索引。由于冲突，不采取第七提交步骤和第八更新ref步骤。让我们再次看看这些步骤，发生了什么。 Git将giver提交的哈希写入.git/MERGE_HEAD文件。 Git找到base提交b4 Git从接收者和提交者提交的树图生成基本的索引。 Git生成一个diff，它将接收者提交和提交者提交对基础提交所做的更改合并。 此diff是指向更改的文件路径列表：添加，删除，修改或冲突。 在这种情况下，diff只包含一个条目：data/number.txt。 该条目被标记为冲突，因为data/number.txt的内容在接收者，提供者和base中是不同的。 由diff中的条目指示的更改将应用于工作副本。 对于冲突区域，Git将两个版本写入工作副本中的文件。 data/number.txt的内容设置为： 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD6=======5&gt;&gt;&gt;&gt;&gt;&gt;&gt; deputy 由diff中的条目指示的更改应用于索引。 索引中的条目通过其文件路径和阶段的组合成唯一标识。 未冲突文件的条目具有阶段0.在此合并之前，索引如下所示，其中0是阶段值： 120 data/letter.txt 63d8dbd40c23542e740659a7168a0ce3138ea7480 data/number.txt 62f9457511f879886bb7728c986fe10b0ece6bcb 在合并diff被写入索引之后，索引如下所示： 12340 data/letter.txt 63d8dbd40c23542e740659a7168a0ce3138ea7481 data/number.txt bf0d87ab1b2b0ec1a11a3973d2845b42413d97672 data/number.txt 62f9457511f879886bb7728c986fe10b0ece6bcb3 data/number.txt 7813681f5b41c028345ca62a2be376bae70b7f61 在阶段0的data/letter.txt的条目与在合并之前相同。 在阶段0的data/number.txt的条目被去掉了。 它有三个新的条目。 阶段1的条目具有base data/number.txt内容的散列。 阶段2的条目具有receiver data/number.txt内容的散列。 阶段3的条目具有giver data/number.txt内容的散列。 这三个条目的存在告诉Git data/number.txt是冲突的。合并就暂停了。 12~/alpha $ printf &apos;11&apos; &gt; data/number.txt~/alpha $ git add data/number.txt 通过将data/number.txt的内容设置为11来合成两个冲突版本的内容。他们将文件添加到索引。 Git添加一个包含11的Blob。添加一个冲突的文件告诉Git冲突已解决。 Git从索引中删除阶段1,2和3的data/number.txt条目。 在阶段0的data/number.txt的条目中添加新blob的散列。 该索引现在为： 120 data/letter.txt 63d8dbd40c23542e740659a7168a0ce3138ea7480 data/number.txt 9d607966b721abde8931ddd052181fae905db503 12~/alpha $ git commit -m &apos;b11&apos; [master 251a513] b11 提交。 Git在存储库中看到.git/MERGE_HEAD，告诉它合并正在进行。 然后检查索引并发现没有冲突。 就创建一个新的提交b11，以记录解析的合并的内容。 z最后会删除.git/MERGE_HEAD文件。 这将完成合并。 将当前分支master指向新的提交。 移除一个文件下面的图包括提交历史、最近提交的树和blob以及工作副本和索引： 12~/alpha $ git rm data/letter.txt rm &apos;data/letter.txt&apos; 告诉Git删除data/letter.txt。 该文件从工作副本中删除。 该条目从索引中删除。 12~/alpha $ git commit -m &apos;11&apos; [master d14c7d2] 11 提交。 作为提交的一部分，一如既往，Git构建一个表示索引内容的树形图。 data/letter.txt不包括在树图中，因为它不在索引中。 复制存储库12~/alpha $ cd .. ~ $ cp -R alpha bravo 将alpha/存储库的内容复制到bravo/目录。 这将产生以下目录结构： 1234567~├── alpha| └── data| └── number.txt└── bravo └── data └── number.txt 现在bravo目录中有另一个Git图： 将存储库链接到另一个存储库12 ~ $ cd alpha~/alpha $ git remote add bravo ../bravo 移回到alpha存储库。 他们将bravo设置为alpha上的远程存储库。 这会在alpha/.git/config文件中添加： 12[remote &quot;bravo&quot;] url = ../bravo/ 从远程获取分支12345~/alpha $ cd ../bravo~/bravo $ printf &apos;12&apos; &gt; data/number.txt~/bravo $ git add data/number.txt~/bravo $ git commit -m &apos;12&apos; [master 94cd04d] 12 进入bravo存储库。 将data/number.txt的内容设置为12，并将更改提交到bravo上的master。 12345~/bravo $ cd ../alpha~/alpha $ git fetch bravo master Unpacking objects: 100% From ../bravo * branch master -&gt; FETCH_HEAD 进入alpha存储库。 从bravo获取master到alpha。 这个过程有四个步骤。 Git获取master在bravo上指向的提交的哈希。 这是12提交的哈希。 Git提供了12提交所依赖的所有对象的列表：提交对象本身，其树图中的对象，12提交的祖先提交和它们的树图中的对象。 它从此列表中删除alpha对象数据库已有的对象。 它将其余部分复制到alpha/.git/objects/。 将alpha/.git/refs/remotes/bravo/master下的具体ref文件的内容设置为12提交的哈希值。 将alpha/.git/FETCH_HEAD的内容设置为： 194cd04d93ae88a1f53a4646532b1e8cdfbc0977f branch &apos;master&apos; of ../bravo 下图表示了fetch命令从bravo获取了master的12提交 对象是可以复制的，这意味着可以在存储库之间共享历史记录。 存储库可以存储远程分支引用，如alpha/.git/refs/remotes/bravo/master， 这意味着存储库可以在本地记录在远程存储库上分支的状态。 在获取时是正确的，但如果远程分支改变，它将过期。 合并FETCH_HEAD123~/alpha $ git merge FETCH_HEAD Updating d14c7d2..94cd04d Fast-forward 合并FETCH_HEAD, FETCH_HEAD只是另一个ref。 解析了12提交，giver。 master开始指向11提交。 Git做一个快进合并，并将master指向在12提交。 从远程分支Pull12~/alpha $ git pull bravo master Already up-to-date. 将bravo的master拉到alpha。 Pull是fetch and merge FETCH_HEAD的缩写。 Clone一个存储库123~/alpha $ cd .. ~ $ git clone alpha charlie Cloning into &apos;charlie&apos; 移动到上面的目录。 clone alpha到charlie。 clone到charlie具有与生成bravo存储库的cp类似的结果。 Git创建一个名为charlie的新目录。 它将charlie作为一个Git仓库，将alpha添加为远程仓库被称为origin，获取源并合并FETCH_HEAD。 Push分支到远程分支12345 ~ $ cd alpha~/alpha $ printf &apos;13&apos; &gt; data/number.txt~/alpha $ git add data/number.txt~/alpha $ git commit -m &apos;13&apos; [master 3238468] 13 返回到alpha仓库，把data/number.txt的内容设置为13，并提交。 1~/alpha $ git remote add charlie ../charlie 设置alpha的远程仓库为charlie 12345~/alpha $ git push charlie master Writing objects: 100% remote error: refusing to update checked out branch: refs/heads/master because it will make the index and work tree inconsistent push master到charlie. 13提交所需的所有对象都复制到charlie。 此时，推送过程停止。 Git告诉我们出了什么问题。 它拒绝推送到远程分支。 这是有道理的, 因为推送将更新远程索引和HEAD。 这将导致混乱，如果有人正在编辑远程的工作副本。(这也有其他的解决办法，可以google一下) 此时，可以创建一个新的分支，将13提交合并到其中，并将该分支推送到charlie。但是我们想要一个类似GitHub那样的中央仓库，无论什么时候都可以push pull。(中央仓库为什么可以？因为在初始化仓库的时候使用的是git init --bare, 初始化成一个裸存储库，远程仓库应该都要这么初始化。) Clone 一个裸仓库123~/alpha $ cd .. ~ $ git clone alpha delta --bare Cloning into bare repository &apos;delta&apos; 移动到上面的目录。 将delta clone为裸存储库。 这是一个有两个区别的普通clone。 配置文件指示存储库是裸的。 通常存储在.git目录中的文件存储在存储库的根目录中如下： 12345delta├── HEAD├── config├── objects└── refs Push分支到裸存储库12 ~ $ cd alpha~/alpha $ git remote add delta ../delta 返回到alpha存储库。 将delta设置为alpha上的远程存储库。 1234~/alpha $ printf &apos;14&apos; &gt; data/number.txt~/alpha $ git add data/number.txt~/alpha $ git commit -m &apos;14&apos; [master cb51da8] 14 将data/number.txt的内容设置为14，并将更改提交到alpha上的master 1234~/alpha $ git push delta master Writing objects: 100% To ../delta 3238468..cb51da8 master -&gt; master push master到delta，有3个步骤 master分支上的14提交所需的所有对象都从alpha/.git/objects/复制到delta/objects /。 delta/refs/heads/master被更新为指向14提交。 alpha/.git/refs/remotes/delta/master设置为指向14提交。 alpha具有delta的状态的最新记录.","categories":[{"name":"git","slug":"git","permalink":"https://plpcm.github.io/blog/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://plpcm.github.io/blog/tags/git/"}]},{"title":"virtualenv 和 virtualenvwrapper 实践","slug":"python-virtualenv-virtualenvwrapper-practice","date":"2016-02-05T08:39:16.000Z","updated":"2016-12-05T08:32:12.000Z","comments":true,"path":"2016/02/05/python-virtualenv-virtualenvwrapper-practice/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/02/05/python-virtualenv-virtualenvwrapper-practice/","excerpt":"","text":"各位 Python 的小伙伴肯定多多少少接触过 virtualenv。本文将介绍 virtualenv 以及如何更科学更优雅地使用 virtualenv。 virtualenv首先来聊一下 virtualenv 是个什么鬼。 在使用 Python 开发的过程中，工程一多，难免会碰到不同的工程依赖不同版本的库的问题；亦或者是在开发过程中不想让物理环境里充斥各种各样的库，引发未来的依赖灾难。此时，我们需要对于不同的工程使用不同的虚拟环境来保持开发环境以及宿主环境的清洁。这里，就要隆重介绍 virtualenv，一个可以帮助我们管理不同 Python 环境的绝好工具。virtualenv 可以在系统中建立多个不同并且相互不干扰的虚拟环境。另外，值得一提的是，在 virtualenv 的虚拟环境中使用 pip 安装依赖还可以绕过某些系统的权限设置，因为毕竟不需要向系统目录写入数据嘛~~ 那么，virtualenv 是怎么运行的呢？ 安装首先从安装讲起，这里假设已经安装了 pip，如果没有安装 pip 的话，请自行出门谷歌(好吧，我是好人，附上pip官方文档链接)。之后就可以用 pip 来直接安装 virtualenv 了。当然，这里可能是需要使用 sudo 提升权限的，毕竟是在宿主物理环境里安装。如下命令中 sudo 省略，如有需求请自行添加。 1pip install virtualenv 好了现在你拥有了 virtualenv 虚拟环境管理器。 使用接下来说使用。 比如我们想要做一点奇怪的事情，写一个脚本去抓取某个网站的信息，我们暂且把这个工程叫做 spider 吧。这个工程里需要访问网络，我们打算使用为人类编写的网络访问库 requests，但是我们又不想在宿主环境中安装这个包。让我们开始吧。 假设我们把这个工程放在 /path/to/project/spider/ 目录下，并且这里我们把虚拟环境直接放在工程目录下。首先，我们在这个目录下建立一个虚拟环境。 12cd /path/to/project/spidervirtualenv --no-site-packages venv 命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数--no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。 这样，虚拟环境就建立好了。此时可以看到，在这个目录下面会有三个目录被建立: bin include lib 其中，bin 目录中包含一些在这个虚拟环境中可用的命令，以及开启虚拟环境的脚本 activate；include 中包含虚拟环境中的头文件，包括 Python 的头文件；lib 中就是一些依赖库啦~~ 当然，现在我们还没有进入到虚拟环境中。激活虚拟环境只需要一条命令。 12source venv/bin/activate(vv) plpcm:spider docker$ 注意到命令提示符变了，有个(venv)前缀，表示当前环境是一个名为venv的Python环境。 接下来安装工程需要的 requests 库。 1pip install requests 搞定！ 这时候在虚拟环境里就有了 requests 库，宿主环境中则不会被干扰。 那么如何退出虚拟环境嘞？退出就更简单啦，只需要下面一个命令就搞定啦。 1deactivate 此时就回到了进入虚拟环境之前，一切都好像没发生过。多年以后，如果你忘记了虚拟环境的位置，一切就真的没发生过了 = = 补充一句，如果想要删除虚拟环境，只要把这个spider目录下的 venv目录删掉就好了。 virtualenvwrapper为神马需要 virtualenvwrapper？这要从 virtualenv 说起。 上一节结束的时候说，如果忘记了虚拟环境的位置，一切就真的没发生过了。虽然是句玩笑，不过真的会发生哦~ virtualenv 的一个最大的缺点就是，每次开启虚拟环境之前要去虚拟环境所在目录下的 bin 目录下 source 一下 activate，这就需要我们记住每个虚拟环境所在的目录。 一种可行的解决方案是，将所有的虚拟环境目录全都集中起来，比如放到 ~/virtualenvs/，并对不同的虚拟环境使用不同的目录来管理。virtualenvwrapper 正是这样做的。并且，它还省去了每次开启虚拟环境时候的 source 操作，使得虚拟环境更加好用。 安装同样，从安装开始。 安装 virtualenvwrapper 也可以使用 pip 的方式。需要加入 sudo 的话请自行加入哦~ 1pip install virtualenvwrapper 不过，在 Mac OS X El Capitan 上可能会出现安装报错的情况，主要问题出在一个叫做 six 的包上。因此安装的时候，可以采用如下方式。 1pip install virtualenvwrapper --ignore-installed six 现在，我们就拥有了一个可以管理虚拟环境的神器。 使用首先，需要对 virtualenvwrapper 进行配置。它需要指定一个环境变量，叫做 WORKON_HOME，并且需要运行一下它的初始化工具 virtualenvwrapper.sh，这个脚本在 /usr/local/bin/ 目录下。WORKON_HOME 就是它将要用来存放各种虚拟环境目录的目录，这里我们可以设置为 ~/.virtualenvs。 12export WORKON_HOME='~/.virtualenvs'source /usr/local/bin/virtualenvwrapper.sh 由于每次都需要执行这两部操作，我们可以将其写入终端的配置文件中。例如，如果使用 bash，则添加到 ~/.bashrc 中；如果使用 zsh，则添加到 ~/.zshrc 中。这样每次启动终端的时候都会自动运行，终端其中之后 virtualenvwrapper 就可以用啦。 利用 virtualenvwrapper，我们可以使用下面的命令轻松创建一个虚拟环境。 1mkvirtualenv spider 之后我们就有了一个叫做 spider 的虚拟环境。它被存放在 $WORKON_HOME/spider 目录下。 新建虚拟环境之后会自动激活虚拟环境。如果我们平时想要进入某个虚拟环境，可以用下面的命令。 1workon spider 这也就是为什么环境变量中存放虚拟环境的目录为啥叫做 WORKON_HOME。顺便说一句，workon 后面可是可以支持用 tab 自动补全的哟。 同样，离开虚拟环境，可以使用。 1deactivate 另外，删除虚拟环境也一样简单。 1rmvirtualenv spider 结束到这里，virtualenv 和 virtualenvwrapper 的基本使用就介绍完了，需要了解更多用法，可以参考官方文档哟。希望这两个工具能够帮助小伙伴们在工作中提高效率哟~~","categories":[{"name":"python","slug":"python","permalink":"https://plpcm.github.io/blog/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://plpcm.github.io/blog/tags/python/"},{"name":"virtualenv","slug":"virtualenv","permalink":"https://plpcm.github.io/blog/tags/virtualenv/"}]},{"title":"pip安装使用详解","slug":"python-pip","date":"2016-02-05T02:30:16.000Z","updated":"2016-12-05T08:32:03.000Z","comments":true,"path":"2016/02/05/python-pip/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/02/05/python-pip/","excerpt":"","text":"pip类似RedHat里面的yum，安装Python包非常方便。本节详细介绍pip的安装、以及使用方法。 1、pip下载安装12curl -O https://bootstrap.pypa.io/get-pip.pysudo python get-pip.py 2. pip使用详解2.1 pip安装包 123pip install SomePackage[...]Successfully installed SomePackage 2.2 pip查看已安装的包 1234567show --files SomePackage Name: SomePackage Version: 1.0 Location: /my/env/lib/pythonx.x/site-packages Files: ../somepackage/__init__.py [...] 2.3 pip检查哪些包需要更新 12pip list --outdated SomePackage (Current: 1.0 Latest: 2.0) 2.4 pip升级包 1234567pip install --upgrade SomePackage [...] Found existing installation: SomePackage 1.0 Uninstalling SomePackage: Successfully uninstalled SomePackage Running setup.py install for SomePackage Successfully installed SomePackage 2.5 pip卸载包 12345pip uninstall SomePackage Uninstalling SomePackage: /my/env/lib/pythonx.x/site-packages/somepackage Proceed (y/n)? y Successfully uninstalled SomePackage 3. pip使用实例3.1 安装redis 1pip install redis 3.2 卸载redis 123456pip uninstall redisUninstalling redis: /usr/lib/python2.6/site-packages/redis-2.9.1-py2.6.egg-info.....省略一些内容....Proceed (y/n)? y Successfully uninstalled redis 3.3 查看待更新包 1234pip list --outdatepygpgme (Current: 0.1 Latest: 0.3)pycurl (Current: 7.19.0 Latest: 7.19.3.1)iniparse (Current: 0.3.1 Latest: 0.4) 4. 常见错误4.1 ImportError No module named setuptools请参考《ImportError No module named setuptools解决》 5. pip参数解释12345678910111213141516171819202122232425262728293031323334353637pip --helpUsage: pip &lt;command&gt; [options]Commands: install Install packages. download Download packages. uninstall Uninstall packages. freeze Output installed packages in requirements format. list List installed packages. show Show information about installed packages. check Verify installed packages have compatible dependencies. search Search PyPI for packages. wheel Build wheels from your requirements. hash Compute hashes of package archives. completion A helper command used for command completion. help Show help for commands.General Options: -h, --help Show help. --isolated Run pip in an isolated mode, ignoring environment variables and user configuration. -v, --verbose Give more output. Option is additive, and can be used up to 3 times. -V, --version Show version and exit. -q, --quiet Give less output. Option is additive, and can be used up to 3 times (corresponding to WARNING, ERROR, and CRITICAL logging levels). --log &lt;path&gt; Path to a verbose appending log. --proxy &lt;proxy&gt; Specify a proxy in the form [user:passwd@]proxy.server:port. --retries &lt;retries&gt; Maximum number of retries each connection should attempt (default 5 times). --timeout &lt;sec&gt; Set the socket timeout (default 15 seconds). --exists-action &lt;action&gt; Default action when a path already exists: (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort. --trusted-host &lt;hostname&gt; Mark this host as trusted, even though it does not have valid or any HTTPS. --cert &lt;path&gt; Path to alternate CA bundle. --client-cert &lt;path&gt; Path to SSL client certificate, a single file containing the private key and the certificate in PEM format. --cache-dir &lt;dir&gt; Store the cache data in &lt;dir&gt;. --no-cache-dir Disable the cache. --disable-pip-version-check Don't periodically check PyPI to determine whether a new version of pip is available for download. Implied with --no-index. 6. 结束安装使用一目了然，太简单了。","categories":[{"name":"python","slug":"python","permalink":"https://plpcm.github.io/blog/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://plpcm.github.io/blog/tags/python/"},{"name":"pip","slug":"pip","permalink":"https://plpcm.github.io/blog/tags/pip/"}]},{"title":"Macdown 编辑器","slug":"macdown-introduce","date":"2016-02-02T08:38:10.000Z","updated":"2016-11-30T07:50:28.000Z","comments":true,"path":"2016/02/02/macdown-introduce/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/02/02/macdown-introduce/","excerpt":"","text":"Hello there! I’m MacDown, the open source Markdown editor for OS X. Let me introduce myself. Markdown and IMarkdown is a plain text formatting syntax created by John Gruber, aiming to provide a easy-to-read and feasible markup. The original Markdown syntax specification can be found here. MacDown is created as a simple-to-use editor for Markdown documents. I render your Markdown contents real-time into HTML, and display them in a preview panel. I support all the original Markdown syntaxes. But I can do so much more! Various popular but non-standard syntaxes can be turned on/off from the Markdown preference pane. You can specify extra HTML rendering options through the Rendering preference pane. You can customize the editor window to you liking in the Editor preferences pane: You can configure various application (that’s me!) behaviors in the General preference pane. The BasicsBefore I tell you about all the extra syntaxes and capabilities I have, I’ll introduce you to the basics of standard markdown. If you already know markdown, and want to jump straight to learning about the fancier things I can do, I suggest you skip to the Markdown preference pane. Lets jump right in. Line BreaksTo force a line break, put two spaces and a newline (return) at the end of the line. This two-line bulletwon’t break This two-line bulletwill break Here is the code: 12345* This two-line bullet won&apos;t break* This two-line bullet will break Strong and EmphasizeStrong: **Strong** or __Strong__ (Command-B)Emphasize: *Emphasize* or _Emphasize_[^emphasize] (Command-I) Headers (like this one!)Header 1 ======== Header 2 -------- or # Header 1 ## Header 2 ### Header 3 #### Header 4 ##### Header 5 ###### Header 6 Links and EmailInlineJust put angle brackets around an email and it becomes clickable: &#117;&#x72;&#x61;&#110;&#x75;&#x73;&#106;&#114;&#64;&#103;&#x6d;&#97;&#105;&#108;&#x2e;&#x63;&#x6f;&#109;&lt;uranusjr@gmail.com&gt; Same thing with urls: http://macdown.uranusjr.com&lt;http://macdown.uranusjr.com&gt; Perhaps you want to some link text like this: Macdown Website[Macdown Website](http://macdown.uranusjr.com &quot;Title&quot;) (The title is optional) Reference styleSometimes it looks too messy to include big long urls inline, or you want to keep all your urls together. Make a link [a link][arbitrary_id] then on it’s own line anywhere else in the file:[arbitrary_id]: http://macdown.uranusjr.com &quot;Title&quot; If the link text itself would make a good id, you can link like this [like this][], then on it’s own line anywhere else in the file:[like this]: http://macdown.uranusjr.com ImagesInline![Alt Image Text](path/or/url/to.jpg &quot;Optional Title&quot;) Reference style![Alt Image Text][image-id]on it’s own line elsewhere:[image-id]: path/or/url/to.jpg &quot;Optional Title&quot; Lists Lists must be preceded by a blank line (or block element) Unordered lists start each item with a * - works too Indent a level to make a nested list Ordered lists are supported. Start each item (number-period-space) like 1. It doesn’t matter what number you use, I will render them sequentially So you might want to start each line with 1. and let me sort it out Here is the code: 12345678* Lists must be preceded by a blank line (or block element)* Unordered lists start each item with a `*`- `-` works too * Indent a level to make a nested list 1. Ordered lists are supported. 2. Start each item (number-period-space) like `1. ` 42. It doesn&apos;t matter what number you use, I will render them sequentially 1. So you might want to start each line with `1.` and let me sort it out Block Quote Angle brackets &gt; are used for block quotes.Technically not every line needs to start with a &gt; as long asthere are no empty lines between paragraphs.Looks kinda ugly though. Block quotes can be nested. Multiple Levels Most markdown syntaxes work inside block quotes. Lists Links Etc. Here is the code: 123456789101112&gt; Angle brackets `&gt;` are used for block quotes. Technically not every line needs to start with a `&gt;` as long asthere are no empty lines between paragraphs. &gt; Looks kinda ugly though.&gt; &gt; Block quotes can be nested. &gt; &gt; &gt; Multiple Levels&gt;&gt; Most markdown syntaxes work inside block quotes.&gt;&gt; * Lists&gt; * [Links][arbitrary_id]&gt; * Etc. Inline CodeInline code is indicated by surrounding it with backticks:`Inline code` If your code has `backticks` that need to be displayed, you can use double backticks:``Code with `backticks` `` ```` (mind the spaces preceding the final set of backticks)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950### Block CodeIf you indent at least four spaces or one tab, I&apos;ll display a code block. print(&apos;This is a code block&apos;) print(&apos;The block must be preceded by a blank line&apos;) print(&apos;Then indent at least 4 spaces or 1 tab&apos;) print(&apos;Nesting does nothing. Your code is displayed Literally&apos;)I also know how to do something called [Fenced Code Blocks](#fenced-code-block) which I will tell you about later.### Horizontal RulesIf you type three asterisks `***` or three dashes `---` on a line, I&apos;ll display a horizontal rule:***## &lt;a name=&quot;markdown-pane&quot;&gt;&lt;/a&gt;The Markdown Preference PaneThis is where I keep all preferences related to how I parse markdown into html. ![Markdown preferences pane](http://d.pr/i/RQEi+)### Document FormattingThe ***Smartypants*** extension automatically transforms straight quotes (`&quot;` and `&apos;`) in your text into typographer’s quotes (`“`, `”`, `‘`, and `’`) according to the context. Very useful if you’re a typography freak like I am. Quote and Smartypants are syntactically incompatible. If both are enabled, Quote takes precedence.### Block Formatting#### TableThis is a table:First Header | Second Header------------- | -------------Content Cell | Content CellContent Cell | Content CellYou can align cell contents with syntax like this:| Left Aligned | Center Aligned | Right Aligned ||:------------- |:---------------:| -------------:|| col 3 is | some wordy text | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 |The left- and right-most pipes (`|`) are only aesthetic, and can be omitted. The spaces don’t matter, either. Alignment depends solely on `:` marks.#### &lt;a name=&quot;fenced-code-block&quot;&gt;Fenced Code Block&lt;/a&gt;This is a fenced code block: print(‘Hello world!’)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071You can also use waves (`~`) instead of back ticks (`` ` ``):~~~print(&apos;Hello world!&apos;)~~~You can add an optional language ID at the end of the first line. The language ID will only be used to highlight the code inside if you tick the ***Enable highlighting in code blocks*** option. This is what happens if you enable it:![Syntax highlighting example](http://d.pr/i/9HM6+)I support many popular languages as well as some generic syntax descriptions that can be used if your language of choice is not supported. See [relevant sections on the official site](http://macdown.uranusjr.com/features/) for a full list of supported syntaxes.### Inline FormattingThe following is a list of optional inline markups supported:Option name | Markup | Result if enabled |--------------------|------------------|-----------------------|Intra-word emphasis | So A\\*maz\\*ing | So A&lt;em&gt;maz&lt;/em&gt;ing |Strikethrough | \\~~Much wow\\~~ | &lt;del&gt;Much wow&lt;/del&gt; |Underline [^under] | \\_So doge\\_ | &lt;u&gt;So doge&lt;/u&gt; |Quote [^quote] | \\&quot;Such editor\\&quot; | &lt;q&gt;Such editor&lt;/q&gt; |Highlight | \\==So good\\== | &lt;mark&gt;So good&lt;/mark&gt; |Superscript | hoge\\^(fuga) | hoge&lt;sup&gt;fuga&lt;/sup&gt; |Autolink | http://t.co | &lt;http://t.co&gt; |Footnotes | [\\^4] and [\\^4]: | [^4] and footnote 4 |[^4]: You don&apos;t have to use a number. Arbitrary things like `[^footy note4]` and `[^footy note4]:` will also work. But they will *render* as numbered footnotes. Also, no need to keep your footnotes in order, I will sort out the order for you so they appear in the same order they were referenced in the text body. You can even keep some footnotes near where you referenced them, and collect others at the bottom of the file in the traditional place for footnotes. ## &lt;a name=&quot;rendering-pane&quot;&gt;&lt;/a&gt;The Rendering Preference PaneThis is where I keep preferences relating to how I render and style the parsed markdown in the preview window. ![Rendering preferences pane](http://d.pr/i/rT4d+)### CSSYou can choose different css files for me to use to render your html. You can even customize or add your own custom css files.### Syntax HighlightingYou have already seen how I can syntax highlight your fenced code blocks. See the [Fenced Code Block](#fenced-code-block) section if you haven’t! You can also choose different themes for syntax highlighting.### TeX-like Math SyntaxI can also render TeX-like math syntaxes, if you allow me to.[^math] I can do inline math like this: \\\\( 1 + 1 \\\\) or this (in MathML): &lt;math&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;, and block math:\\\\[ A^T_S = B\\\\]or (in MathML)&lt;math display=&quot;block&quot;&gt; &lt;msubsup&gt;&lt;mi&gt;A&lt;/mi&gt; &lt;mi&gt;S&lt;/mi&gt; &lt;mi&gt;T&lt;/mi&gt;&lt;/msubsup&gt; &lt;mo&gt;=&lt;/mo&gt; &lt;mi&gt;B&lt;/mi&gt;&lt;/math&gt;### Task List Syntax1. [x] I can render checkbox list syntax * [x] I support nesting * [x] I support ordered *and* unordered lists2. [ ] I don&apos;t support clicking checkboxes directly in the html window### Jekyll front-matterIf you like, I can display Jekyll front-matter in a nice table. Just make sure you put the front-matter at the very beginning of the file, and fence it with `---`. For example: title: “Macdown is my friend” date: 2014-06-06 20:00:00``` Render newline literallyNormally I require you to put two spaces and a newline (aka return) at the end of a line in order to create a line break. If you like, I can render a newline any time you end a line with a newline. However, if you enable this, markdown that looks lovely when I render it might look pretty funky when you let some other program render it. The General Preferences PaneThis is where I keep preferences related to application behavior. The General Preferences Pane allows you to tell me how you want me to behave. For example, do you want me to make sure there is a document open when I launch? You can also tell me if I should constantly update the preview window as you type, or wait for you to hit command-R instead. Maybe you prefer your editor window on the right? Or to see the word-count as you type. This is also the place to tell me if you are interested in pre-releases of me, or just want to stick to better-tested official releases. The Editor Preference PaneThis is where I keep preferences related to the behavior and styling of the editing window. StylingMy editor provides syntax highlighting. You can edit the base font and the coloring/sizing theme. I provided some default themes (courtesy of Mou’s creator, Chen Luo) if you don’t know where to start. You can also edit, or even add new themes if you want to! Just click the Reveal button, and start moving things around. Remember to use the correct file extension (.styles), though. I’m picky about that. I offer auto-completion and other functions to ease your editing experience. If you don’t like it, however, you can turn them off. Hack OnThat’s about it. Thanks for listening. I’ll be quiet from now on (unless there’s an update about the app—I’ll remind you for that!). Happy writing! [^emphasize]: If Underlines is turned on, _this notation_ will render as underlined instead of emphasized [^under]: If Underline is disabled _this_ will be rendered as emphasized instead of being underlined. [^quote]: Quote replaces literal &quot; characters with html &lt;q&gt; tags. Quote and Smartypants are syntactically incompatible. If both are enabled, Quote takes precedence. Note that Quote is different from blockquote, which is part of standard Markdown. [^math]: Internet connection required.","categories":[{"name":"mac","slug":"mac","permalink":"https://plpcm.github.io/blog/categories/mac/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://plpcm.github.io/blog/tags/markdown/"},{"name":"mac","slug":"mac","permalink":"https://plpcm.github.io/blog/tags/mac/"}]},{"title":"Mac 下两款 Markdown 编辑器 Mou/MacDown 大 PK","slug":"markdown-editor-Mou-MacDown-pk","date":"2016-02-02T07:30:16.000Z","updated":"2016-11-30T08:18:31.000Z","comments":true,"path":"2016/02/02/markdown-editor-Mou-MacDown-pk/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/02/02/markdown-editor-Mou-MacDown-pk/","excerpt":"","text":"转载自 http://www.jianshu.com/p/6c157af09e84 Mou 和 MacDown 是我在 Mac 下用过的两款优秀的 Markdown 编辑器。之前一直使用的是 Mou，但不知怎的最近 Mou 在保存时总有 4s 以上的卡顿，这让我很不爽，没找到有效的解决方法，于是我被迫去寻找其它的 MD 编辑器。我尝试过很多种，但总觉得没有 Mou 体验好，最终让我找到了 MacDown——OS X下开放源代码 Markdown 编辑器。 背后的故事很有兴趣关注了这两款软件的作者及背后的故事，发现很有趣，在评测两款软件之前我们先八一八故事吧。 Mou 的作者罗晨，个人主页：http://chenluois.com/，现居住天津，自由职业者。MacDown 的作者Tzu-ping Chung，个人主页：https://uranusjr.com/，现居住台北市，应该是台湾同胞吧。 根据 MacDown 作者的介绍，他曾经一度是 Markdown 的重度用户，而使用的编辑器基本是 Mou，但 Mou 可以处理fenced code blocks，却对代码高亮不支持，同时在渲染 Markdown 时也有 bug，这让他很苦恼。Mou 的作者当时正准备转手该软件，一直没有更新，所以，他就开始从头开始模仿 Mou 写一个，因为是 Markdown editor for Macs，所以取名为 MacDown。 MacDown 作者 Chung 在征得 Mou 作者 Luo 的同意使用了 Mou 的几款主题，发布了 MacDown 的原始版本。Luo 最后发现 MacDown 时，很气愤，并指责 Chung 是 copycat，意思是 MacDown 山寨了 Mou。Chung 也意识到确实是自己抄袭了 Mou 很多东西，根据某条推文的建议（并不是Luo发布的），将之前 github 中项目描述 改成了： MacDown is an open source Markdown editor for OS X, released under the MIT License. The author stole the idea from Chen Luo’s Mou so that people can make crappy clones. ^1 比较详细的情节可以参见 Chung 的博客。至于 MacDown 和 Mou 的关系是怎样的，是不是 MacDown 就是不道德地克隆了 Mou 呢？这个每个人都有自己的看法，这里就不讨论了。 欣喜的是，目前两款软件都找到自己的发展模式，Mou 已经完成了众筹，即将发布 1.0 版本，如果有对 Mou 有情怀的同学可以支持作者；MacDown 依旧会走自己开源的道路。 Chung 的一句话也道出了我的心声： Let’s focus on making better software for everyone. 好了，八卦完了，最后我要对两位作者表示由衷的谢意，贡献给我们好用的软件！下面我会根据我体验，分别提一下两款软件各自的特色地方。 共同功能 提供丰富的简洁大方好看的主题，同时支持自定义 提供丰富的渲染 Markdown 之后的 CSS 样式，同时支持自定义样式 英文单词的自动补全功能，按下 Esc 键列出补全的列表 字符、单词统计功能 支持 fenced code blocks TeX 数学公式的支持 支持导出 HTML 和 PDF 两种格式 便捷的快捷键操作 … Mou 特色功能集成 Tumblr 和 Scriptogr.am 发布博文可以配置 Tumblr 和 Scriptogr.am 的邮箱，在 Mou 上写文章通过 File-&gt;Post-&gt; 可以发布到这两个平台上，非常方便。 Mou 支持集成 Tumblr 和 Scriptor.am 语言支持Mou 内置 CJK 字符支持，你可以很容易使用中文、日文、韩文等来写文章，同时还支持竖排的风格。 Mou 支持 CJK 及竖排 MacDown 特色代码高亮Mou 和 MacDown 都支持 fenced code blocks（前后三个反引号可以表示代码块），但 MacDown 支持加语言标识符实现代码高亮，这对程序员来说简直是福音啊，非常棒的功能。 MacDown 支持代码高亮 GFM Task List 支持MacDown 支持 Task list，有了这个功能，你可以将你的 MD 编辑器立马变成 TODO list，是不是很赞？ MacDown 对 Task list 的支持 Jekyll Front-matter 支持很多人使用 Jekyll 作为博客引擎，这时 Jekyll 的前面那段该怎么去渲染呢？MacDown 和 github 一样可以支持。 MacDown 对 Jekyll front-matter 的支持 总结OK，总结完了，如果不是 Mou 在我的 Mac 上有卡顿，我也没想着要换一款编辑器，目前我在用 MacDown 感觉还是很不错的，因为有代码高亮支持就足以把我留下了。至于你选哪一款，你可以下载下来自己体验体验，反正软件都很小。也许你跟我一样，因为某个小瑕疵放弃某个软件，又因为某个小功能的惊喜而喜欢上某个软件。","categories":[{"name":"mac","slug":"mac","permalink":"https://plpcm.github.io/blog/categories/mac/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://plpcm.github.io/blog/tags/markdown/"},{"name":"mac","slug":"mac","permalink":"https://plpcm.github.io/blog/tags/mac/"}]},{"title":"开始使用Ubuntu作为工作环境","slug":"ubuntu-dev-env","date":"2016-01-02T02:30:16.000Z","updated":"2016-12-07T03:00:51.000Z","comments":true,"path":"2016/01/02/ubuntu-dev-env/","link":"","permalink":"https://plpcm.github.io/blog/blog/2016/01/02/ubuntu-dev-env/","excerpt":"","text":"转载自:http://blog.codinglabs.org/articles/getting-started-with-ubuntu.html Ubuntu 2012年3月，我自购了一台13寸的Macbook Air，从那时开始至今近两年时间，我一直用它作为工作本。但是最近越来越觉得4G的内存和128G的SSD力不从心，苦于Air无法升级硬件，于是终于下决心拿出入职时公司给配的Dell E6410，自己买了内存和SSD，升级成了8G内存+370G混合硬盘（120G SSD做主盘，250G硬盘做从盘）。 硬件升级事小，关键是系统的迁移代价比较大。我在Dell本上装的是Ubuntu 13.10，由于我平时习惯使用Dropbox等云端服务，浏览器配置也都通过Google账号漫游，所以这部分迁移几乎没有成本，主要的成本在开发环境配置和常用软件迁移。虽然都是Unix系，但是Mac OSX下很多软件Linux下并没有。 花了大约一个周末，总算把我的Ubuntu配置的比较顺手了，目前也已经正式投入工作。其中的重头戏便是开发环境（主要是terminal和vim）的配置，另外就是一些常用工具。这篇文章记录了我一些主要的工作，算是给自己留一个文档，也希望能给打算从Mac迁移到Linux的同学做一个借鉴。 开发环境配置之前在Mac下，我直接使用的是maximum-awesome，开发环境这块完全不用自己操心。可惜maximum-awesome只能在Mac下使用，并没有Linux版。于是需要自己做一些工作，以便让开发环境够顺手。 使用terminator作为终端安装terminatorUbuntu自带的终端是gnome-terminal，虽然也还不错，但是不能支持屏幕分割、选择复制等功能让我很不爽，于是我换用terminator作为终端，terminator可以支持屏幕分割，并且默认快捷键和gnome-terminal无异，熟悉gnome-terminal的话可以快速上手。 Ubuntu下可以这样安装terminator： 1sudo apt-get install terminator terminator常用快捷键 Ctrl-Shift-c 拷贝 Ctrl-Shift-v 粘贴 Ctrl-Shift-t 开新Tab窗口 Ctrl-Shift-o 上下拆分屏幕 Ctrl-Shift-e 左右拆分屏幕 Ctrl-Shift-w 关闭当前窗口 Ctrl-Shift-q 关闭整个终端 配置terminator使用solarized配色使用terminator-solarizedmaximum-awesome所使用的solarized配色是相当不错的，所以自然希望继续使用。针对terminator的solarized配色已经有人专门做好了：terminator-solarized，只要按如下操作就可以使用： 12mkdir -p ~/.config/terminator/curl https://raw.github.com/ghuntley/terminator-solarized/master/config &gt; ~/.config/terminator/config 然后重新打开terminator就已经是solarized配色了。 对terminator更多的配置接下来，可以在terminator-solarized配置文件的基础上进行更多的配置，例如背景透明、启用选择复制等。 关于terminator的详细配置选项可以参考terminator manpage，下面贴出我的~/.config/terminator/config供参考： 12345678910111213141516171819202122232425262728293031323334353637383940[global_config] title_transmit_bg_color = \"#d30102\" focus = system suppress_multiple_term_dialog = True[keybindings][profiles] [[default]] palette = \"#073642:#dc322f:#859900:#b58900:#268bd2:#d33682:#2aa198:#eee8d5:#002b36:#cb4b16:#586e75:#657b83:#839496:#6c71c4:#93a1a1:#fdf6e3\" copy_on_selection = True background_image = None background_darkness = 0.95 background_type = transparent use_system_font = False cursor_color = \"#eee8d5\" foreground_color = \"#839496\" show_titlebar = False font = Monospace 11 background_color = \"#002b36\" [[solarized-dark]] palette = \"#073642:#dc322f:#859900:#b58900:#268bd2:#d33682:#2aa198:#eee8d5:#002b36:#cb4b16:#586e75:#657b83:#839496:#6c71c4:#93a1a1:#fdf6e3\" background_color = \"#002b36\" background_image = None cursor_color = \"#eee8d5\" foreground_color = \"#839496\" [[solarized-light]] palette = \"#073642:#dc322f:#859900:#b58900:#268bd2:#d33682:#2aa198:#eee8d5:#002b36:#cb4b16:#586e75:#657b83:#839496:#6c71c4:#93a1a1:#fdf6e3\" background_color = \"#fdf6e3\" background_image = None cursor_color = \"#002b36\" foreground_color = \"#657b83\"[layouts] [[default]] [[[child1]]] type = Terminal parent = window0 profile = default [[[window0]]] type = Window parent = \"\"[plugins] 配置dircolors完成上述配置后，你会发现用ls命令查看目录和文件时是一片灰色。这是因为默认情况下solarized各种bright方案基本都是灰色，而系统默认显示目录和文件时多用bright色，此时需要配置dircolors才能显示出彩色的文件和目录。 dircolors-solarized项目提供了适合于solarized的dircolors配色方案，只要选择合适的方案使用就可以了。例如我是用的solarized dark配色，所以可以选择适合这个配色的dircolors.ansi-dark： 1curl https://raw.github.com/seebi/dircolors-solarized/master/dircolors.ansi-dark &gt; ~/.dircolors 然后在~/.bashrc中加入如下配置： 12345678910111213141516# enable color support of ls and also add handy aliasesif [ -x /usr/bin/dircolors ]; then test -r ~/.dircolors &amp;&amp; eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\" alias ls='ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' alias grep='grep --color=auto' alias fgrep='fgrep --color=auto' alias egrep='egrep --color=auto'fi # some more ls aliasesalias ll='ls -alF'alias la='ls -A'alias l='ls -CF' 执行 1source ~/.bashrc 后，再执行ls或ll就可以看到彩色的目录或文件了。 配置完的terminator效果如下： 配置VIMvim作为我日常使用频率最高的代码编辑器，自然要好好配置一番。之前的maximum-awesome自带了很多vim插件，这里我没有精力完全按照maximum-awesome的插件配置，只选取了日常比较常用的几个插件先配上，后面需要的话可以再加。 插件我目前安装的插件有： NERDTree：可以在单独的window中浏览目录和文件，方便打开的选取文件。 taglist：可以通过ctags生成的tag文件索引定位代码中的常量、函数、类等结构，阅读代码和写代码必备。 powerline：在底部显示一个非常漂亮的状态条，还可以通过不同的颜色提醒用户当前处于什么状态（如normal、insert或visual）。 vim-colors-solarized：vim的solarized配色插件。 如果所有插件都按vim标准方法安装，各种插件会非常分散，不便于管理，于是我选用pathogen安装和管理vim插件。pathogen允许将各个插件放在.vim/bundle/下各自的目录中，通过启动时自动加载所有插件。 自动配置工具整个配置过程过于繁琐不再赘述，我已经将配置过程写成了一个自动配置脚本并放到了github：https://github.com/ericzhang-cn/vim-conf，需要的朋友只要clone下来并运行init.sh脚本就可以自动完成整个配置： 1git clone https://github.com/ericzhang-cn/vim-conf.gitcd vim-conf &amp;&amp; ./init.sh 最终配置效果如下： （更新：当前我已经换用maximum-awesome-linux，不再维护之前那个配置脚本） 快捷键其中并没有对vim默认的快捷键做过多重设，只有两个： ,-d：打开或关闭NERDTree ,-t：打开或关闭taglist （更新：换用maximum-awesome-linux后快捷键会不一样，具体请参考README） 常用工具浏览器Ubuntu自带的是Firefox，我平常使用的是Chromium，这点在Ubuntu下没任何问题，可以直接安装： 1sudo apt-get install chromium-browser 用Google账号登录后，书签、插件等会自动同步，非常方便。 搜狗输入法&amp;谷歌输入法Mac下有搜狗输入法或百度输入法。不过目前搜狗也基于fcitx做了linux版的搜狗输入法。 Ubuntu自带的ibus直接卸掉，然后安装fcitx： 1sudo add-apt-repository ppa:fcitx-team/nightly &amp;&amp; sudo apt-get updatesudo apt-get install fcitx-sogoupinyin 当然谷歌拼音也不错： 1sudo apt-get install fcitx-googlepinyin 邮件Mac下是使用Foxmail for Mac，linux下可以选择ThunderBird，用起来很顺手。 DropboxDropbox有官方linux客户端，可以到其官网下载安装。不过安装后也许会发现dropbox的icon没有出现在上面的indicator上，可以这样修复： 1sudo apt-get install libappindicator1dropbox stop &amp;&amp; dropbox start Evernote很不幸，我平常用来做笔记的evernote没有linux官方客户端，不过可以选择使用web版，或者安装第三方linux客户端everpad： 1sudo add-apt-repository ppa:nvbn-rm/ppasudo apt-get updatesudo apt-get install everpad 当然功能和美观程度都没法和Mac下官方的客户端相比，不过日常使用还是足够了。 办公OfficeUbuntu自带的LibreOffice可以很好的满足需求，试用了WPS for linux，无法正常打开Office 2010的文件，故而弃用之。LibreOffice打开Office 2010的文件没有问题。 PDF及论文管理平常使用的Mendeley有官方linux客户端，可以到官网下载。 绘图及图像处理平常工程文档做图一般用yEd，是java开发的，所以在linux下可以直接使用。 图像处理可以用gimp： 1sudo apt-get install gimp 影音播放平常很少离线看视频，如果需要的话，vlc应该够了： 1sudo apt-get install vlc 截图工具截图工具非shutter莫属： 1sudo apt-get install shutter 阿里旺旺因为工作关系，平常必须使用旺旺交流。Mac下有非常好用的官方版，linux下并没有官方旺旺，有个内部版本巨烂无比。不过之前参加活动获赠一个CrossOver正版授权序列号。 目前CrossOver运行阿里旺旺2013非常流畅。 QQ这个对我来说不是刚需。CrossOver可以运行TM2013，另外WebQQ或开VirtualBox在虚拟机中运行QQ都可以。 专业软件其它常用软件特别是如R或Octave等专业软件，本身就有linux版，所以可以按需安装。如Git等开发工具本来就是linux下的软件，当然更不在话下。 目前已经用Ubuntu工作了一段时间，总体来说从Mac转过来肯定需要一点适应，不过目前感觉没有遇到特别大的问题，毕竟同属Unix系，对码农来说大多数使用习惯几乎是无缝切换。 另外，重新回到OSS的感觉不错！最后上张图吧：","categories":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://plpcm.github.io/blog/categories/ubuntu/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://plpcm.github.io/blog/tags/ubuntu/"}]},{"title":"Hexo搭建个人博客","slug":"hexo-init","date":"2015-12-22T16:00:00.000Z","updated":"2016-12-05T08:32:30.000Z","comments":true,"path":"2015/12/23/hexo-init/","link":"","permalink":"https://plpcm.github.io/blog/blog/2015/12/23/hexo-init/","excerpt":"","text":"安装Hexo 安装 1234mkdir hexo #创建一个文件夹cd hexonpm install -g hexo-clinpm install hexo --save 部署Hexo：在Git shell 中输入 1hexo init 安装Hexo 插件：自动生成sitemap,Rss，部署到git等，建议安装 12345678910111213npm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked@0.2 --savenpm install hexo-renderer-stylus@0.2 --savenpm install hexo-generator-feed@1 --savenpm install hexo-generator-sitemap@1 --save Hexo常用的几个命令创建新博文执行new命令，生成指定名称的文章至hexo\\source_posts\\postName.md。 1hexo new [layout] &quot;postName&quot; #新建文章 其中layout是可选参数，默认值为post。有哪些layout呢，请到scaffolds目录下查看，这些文件名称就是layout名称。当然你可以添加自己的layout，方法就是添加一个文件即可，同时你也可以编辑现有的layout，比如post的layout默认是hexo\\scaffolds\\post.md 1234title: &#123; &#123; title &#125; &#125;date: &#123; &#123; date &#125; &#125;tags:--- 请注意，大括号与大括号之间我多加了个空格，否则会被转义，不能正常显示。 我想添加categories，以免每次手工输入，只需要修改这个文件添加一行，如下： 12345title: &#123; &#123; title &#125; &#125;date: &#123; &#123; date &#125; &#125;categories: tags: --- 更多信息参考: Writing 运行服务器1$ hexo server 参考: Server 生成静态站点文件1$ hexo generate 参考: Generating 部署到Git部署到Github前需要配置_config.yml文件 添加如下内容： 1234deploy: type: git repository: git@github.com:EZLippi/EZLippi.github.io.git branch: master 然后输入： 1$ hexo deploy 参考: Deployment fancybox可能有人对这个Reading页面中图片的fancybox效果感兴趣，这个是怎么做的呢。很简单，只需要在你的文章*.md文件的头上添加photos项即可，然后一行行添加你要展示的照片: 12345title: Hexo建立个人博客photos:- http://bruce.u.qiniudn.com/2013/11/27/reading/photos-0.jpg- http://bruce.u.qiniudn.com/2013/11/27/reading/photos-1.jpg--- 主题设置本博客采用了iissnan的Next主题，他的博客有详细的安装教程，这里贴下链接next，有需要的朋友直接参考他写的教程，一气呵成~ 下载主题12$ cd hexo目录$ git clone https://github.com/iissnan/hexo-theme-next themes/next 应用Hexo主题在hexo目录下找到_config.yml配置文件，找到 theme 字段，并将其值更改为 next，如下所示： 1theme: next 设置RSS在上面的步骤中已经安装了Rss插件，只要要在themes\\next_config.yml配置文件中添加如下一行即可： 1rss： 添加标签tags页面定位到 Hexo 站点目录下，使用 hexo new page 新建一个页面，命名为 tags，布局格式为page： 12$ cd hexo目录$ hexo new page tags 内容如下所示，如果要关闭tags页面的评论可以设置comments为false： 12345title: 标签date: 2014-12-22 12:39:04type: &quot;tags&quot;comments: false--- 这样以后tags页面在每次执行hexo generate后自动更新。 添加分类页面和上面的一样，在hexo目录下执行下面命令： 1$ hexo new page categories 内容为： 12345title: 分类date: 2014-12-22 12:39:04type: &quot;categories&quot;comments: false--- 添加404页面新建一个404.html文件，放到themes\\next\\source目录下，内容你自己定。 代码高亮以前jekyll代码高亮需要用到pygments插件，Hexo下更加简单，只需要按照下面的格式：效果如下： 1System.out.println(&quot;hello hexo!&quot;); 你也可以更改代码高亮的主题，一共有五种，可选的值有 normal，night， night blue， night bright， night eighties，修改themes\\next_config.yml文件，如下所示： 1highlight_theme: normal 第三方服务多说评论登录多说官网，登录后点我要安装，然后填写站点相关信息，最主要的是duoshuo_shortname这个字段，设置后之后修改themes\\next_config.yml文件，把duoshuo_shortname改成你的，如下所示： 1duoshuo_shortname: ezlippi 百度统计登录百度统计，转到获取代码截面，找到百度统计脚本id，然后把themes\\next_config.yml文件下的baidu_analytics字段改成你的id，如下所示： 1baidu_analytics: 340874ba9357cbe81570aa4ac1185941 站内搜索next主题集成了swiftype搜索，你需要到swiftype配置一个搜索引擎， 而后编辑 站点配置文件， 新增 swiftype_key 字段，值为你的 swiftype 搜索引擎的 key。 详细的配置请参考：swfitype教程 其他设置其他设置比如侧边栏、友情链接、菜单栏等请参考next主题配置教程 最后附上我的站点配置文件，如果有不懂的可以给我留言或者发邮件。_config.yml配置文件内容如下： 站点配置文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# Hexo Configuration## Docs: http://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: Lippi-浮生志subtitle:description: Easy Lippiauthor: EZLippi language: zh-Hanstimezone: Asia/Shanghai# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://www.ezlippi.comroot: /permalink: /blog/:year/:month/:title.htmlpermalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :year-:month-:day-:title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: true tab_replace:# Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/theme: next #since: 2014# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:EZLippi/EZLippi.github.io.git coding.net: git@git.coding.net:ezlippi/ezlippi.git,coding-pages 主题配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259# ---------------------------------------------------------------# Site Information Settings# ---------------------------------------------------------------# Place your favicon.ico to /source directory.favicon: /favicon.ico# Set default keywords (Use a comma to separate)keywords: &quot;Hexo, NexT&quot;# Set rss to false to disable feed link.# Leave rss as empty to use site&apos;s feed link.# Set rss to specific value if you have burned your feed already.rss:# Specify the date when the site was setupsince: 2014# ---------------------------------------------------------------# Menu Settings# ---------------------------------------------------------------# When running hexo in a subdirectory (e.g. domain.tld/blog)# Remove leading slashes ( &quot;/archives&quot; -&gt; &quot;archives&quot; )menu: home: / categories: /categories archives: /archives tags: /tags about: /about# commonweal: /404.html# Enable/Disable menu icons.# Icon Mapping:# Map a menu item to a specific FontAwesome icon name.# Key is the name of menu item and value is the name of FontAwsome icon.# When an question mask icon presenting up means that the item has no mapping icon.menu_icons: enable: true # Icon Mapping. home: home about: user categories: th tags: tags archives: archive commonweal: heartbeat# ---------------------------------------------------------------# Scheme Settings# ---------------------------------------------------------------# Schemes#scheme: Musescheme: Mist#scheme: Pisces# ---------------------------------------------------------------# Sidebar Settings# ---------------------------------------------------------------# Social linkssocial: GitHub: https://github.com/EZLippi weibo: http://weibo.com/ouyanglip zhihu: http://www.zhihu.com/people/lippi-ouyang #Others: # Social Iconssocial_icons: enable: true # Icon Mappings GitHub: github Twitter: twitter weibo: weibo zhihu: weibo # Sidebar Avatar# in theme directory(source/images): /images/avatar.jpg# in site directory(source/uploads): /uploads/avatar.jpg# default : /images/default_avatar.jpgavatar: /images/avatar.jpg# TOC in the Sidebartoc: enable: true # Automatically add list number to toc. number: true# Creative Commons 4.0 International License.# http://creativecommons.org/# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero#creative_commons: by-nc-sa#creative_commons:sidebar: # Sidebar Position, available value: left | right position: left #position: right # Sidebar Display, available value: # - post expand on posts automatically. Default. # - always expand for all pages automatically # - hide expand only when click on the sidebar toggle icon. # - remove Totally remove sidebar including sidebar toggle icon. display: post #display: always #display: hide #display: remove# ---------------------------------------------------------------# Misc Theme Settings# ---------------------------------------------------------------# Custom Logo.# !!Only available for Default Scheme currently.# Options:# enabled: [true/false] - Replace with specific image# image: url-of-image - Images&apos;s urlcustom_logo: enabled: false image:# Code Highlight theme# Available value:# normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: night # Automatically scroll page to section which is under &lt;!-- more --&gt; mark.scroll_to_more: true# Automatically Excerptauto_excerpt: enable: false length: 150# Use Lato fontuse_font_lato: true# ---------------------------------------------------------------# Third Party Services Settings# ---------------------------------------------------------------# MathJax Supportmathjax:# Swiftype Search API Keyswiftype_key: fLM9qfxyerC6njvM7usy# Baidu Analytics IDbaidu_analytics: 340874ba9357cbe81570aa4ac1185941# Duoshuo ShortNameduoshuo_shortname: ezlippi # Disqus#disqus_shortname:# Share#jiathis:#add_this_id:# Shareduoshuo_share: true# 多说热评文章 true 或者 falseduoshuo_hotartical: true# Google Webmaster tools verification setting# See: https://www.google.com/webmasters/#google_site_verification:# Google Analytics#google_analytics:# Make duoshuo show UA# user_id must NOT be null when admin_enable is true!# you can visit http://dev.duoshuo.com get duoshuo user id.duoshuo_info: ua_enable: true admin_enable: false user_id: 0 #admin_nickname: ROOT# Facebook SDK Support.# https://github.com/iissnan/hexo-theme-next/pull/410facebook_sdk: enable: false app_id: #&lt;app_id&gt; fb_admin: #&lt;user_id&gt; like_button: #true webmaster: #true# Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.leancloud_visitors: enable: false app_id: #&lt;app_id&gt; app_key: #&lt;app_key&gt;# Tencent analytics ID# tencent_analytics:#! ---------------------------------------------------------------#! DO NOT EDIT THE FOLLOWING SETTINGS#! UNLESS YOU KNOW WHAT YOU ARE DOING#! ---------------------------------------------------------------# Motionuse_motion: true# Fancyboxfancybox: true# Static filesvendors: vendorscss: cssjs: jsimages: images# Theme versionversion: 0.5.0# title, chinese availablelinks_title: 友情链接 # # linkslinks: MacTalk: http://macshuo.com/ 参考文献： Hexo如何利用GitHub Pages和Hexo快速搭建个人博客Next主题","categories":[{"name":"hexo","slug":"hexo","permalink":"https://plpcm.github.io/blog/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://plpcm.github.io/blog/tags/hexo/"},{"name":"next","slug":"next","permalink":"https://plpcm.github.io/blog/tags/next/"}]},{"title":"Hello World","slug":"hello-world","date":"2015-12-22T11:08:10.000Z","updated":"2016-11-30T07:50:28.000Z","comments":true,"path":"2015/12/22/hello-world/","link":"","permalink":"https://plpcm.github.io/blog/blog/2015/12/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"hexo","slug":"hexo","permalink":"https://plpcm.github.io/blog/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://plpcm.github.io/blog/tags/hexo/"}]}]}